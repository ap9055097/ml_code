{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79608, 43)"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score , precision_score , recall_score , accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('data_test/trainM1_15.csv', delimiter = ',').reset_index(drop=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv('data_test/testM16', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\n",
    "#  'Normalised_Last1_Month_FQ',\n",
    " 'Normalised_Last1_Month_Sum',\n",
    "#  'Normalised_Last2_Month_FQ',\n",
    "#  'Normalised_Last2_Month_Sum',\n",
    "#  'Normalised_Last3_Month_FQ',\n",
    "#  'Normalised_Last3_Month_Sum',\n",
    "#  'Normalised_Last4_Month_FQ',\n",
    "#  'Normalised_Last4_Month_Sum',\n",
    "#  'Normalised_RunningTime',\n",
    " 'Target Amount',\n",
    "#  'New_cat_cd',\n",
    "#  'New_gnd_cd',\n",
    "#  'New_idv_incm_seg_cd',\n",
    "#  'New_ip_tp_cd',\n",
    "#  'New_ocp_cd',\n",
    "#  'New_mar_st_cd',\n",
    "#  'New_SmartTile_Name',\n",
    "#  'New_SmartTile_Name2',\n",
    "#  'New_SmartTile_Name3',\n",
    "#  'New_SmartTile_Name4',\n",
    "#  'New_SmartTile_Name5',\n",
    "#  'New_SmartTile_Name6',\n",
    "#  'New_SmartTile_Name7',\n",
    "#  'New_SmartTile_Name8',\n",
    "#  'New_SmartTile_Name9',\n",
    "#  'New_SmartTile_Name9_2',\n",
    "#  'New_SmartTile_Name9_3',\n",
    "#  'New_Year_Cat'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list(data.drop(['Target Amount','ip_tp_cd','mrch_cd','mrch_zip_cd','New_mrch_cd','New_mrch_zip_cd','New_ip_tp_cd','New_mar_st_cd'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 1)"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data1 = data.drop(['Target Amount','ip_tp_cd','mrch_cd','mrch_zip_cd','New_mrch_cd','New_mrch_zip_cd','New_ip_tp_cd'], axis=1).fillna(0)\n",
    "data1 = data.drop(['Target Amount'], axis=1).fillna(0)\n",
    "data_ans = pd.read_csv('data_test/testM16', delimiter = ',')\n",
    "# data_ans = data_ans.sort_values(by=['mrch_cd'])\n",
    "data_ans = data_ans[list(data1)]\n",
    "data_ans.shape\n",
    "x_ans = data_ans.fillna(0)\n",
    "x_ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 1)"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ans = pd.read_csv('data_test/SolutionM16.csv', delimiter = ',')\n",
    "y_ans = y_ans[['Target Amount']].values\n",
    "y_ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[['Target Amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63686, 1) (63686, 1) (15922, 1) (15922, 1)\n"
     ]
    }
   ],
   "source": [
    "####### no train test ###########\n",
    "\n",
    "y = data[['Target Amount']].values\n",
    "y[np.argwhere(np.isnan(y))[:,0],0] = 0\n",
    "x = data1\n",
    "\n",
    "x_train_, x_test_, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "####### for concat ########\n",
    "x1 = pd.concat([x, x_ans])\n",
    "# x1 = x\n",
    "\n",
    "print(x_train_.shape,y_train.shape,x_test_.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63686, 23) (63686, 1) (15922, 23) (15922, 1) (79608, 23) (5400, 23)\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "####### for transform index category #######\n",
    "############################################\n",
    "import Encoder as en\n",
    "import numpy as np\n",
    "listcate = ['New_cat_cd',\n",
    " 'New_gnd_cd',\n",
    " 'New_idv_incm_seg_cd',\n",
    " 'New_ip_tp_cd',\n",
    " 'New_ocp_cd',\n",
    " 'New_mar_st_cd',\n",
    " 'New_SmartTile_Name',\n",
    " 'New_SmartTile_Name2',\n",
    " 'New_SmartTile_Name3',\n",
    " 'New_SmartTile_Name4',\n",
    " 'New_SmartTile_Name5',\n",
    " 'New_SmartTile_Name6',\n",
    " 'New_SmartTile_Name7',\n",
    " 'New_SmartTile_Name8',\n",
    " 'New_SmartTile_Name9',\n",
    " 'New_SmartTile_Name9_2',\n",
    " 'New_SmartTile_Name9_3',\n",
    " 'New_Year_Cat']\n",
    "mcle = en.MultiColumnLabelEncoder(columns=np.array(listcate))\n",
    "mcle.fit(x1)\n",
    "mcle.transform(x_test_)\n",
    "mcle.transform(x_train_)\n",
    "mcle.transform(x_ans)\n",
    "mcle.transform(x)\n",
    "mcle.transform(x1)\n",
    "x_train = x_train_.values\n",
    "x_test = x_test_.values\n",
    "x_ans = x_ans.values\n",
    "x = x.values\n",
    "x1 = x1.values\n",
    "\n",
    "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape,x.shape,x_ans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_.values\n",
    "x_test = x_test_.values\n",
    "x_ans = x_ans.values\n",
    "x = x.values\n",
    "x1 = x1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x_sm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.45102606e-05, 5.00843556e-03, 9.17002462e-03, ...,\n",
       "        4.00000000e+00, 4.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        1.00000000e+00, 4.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        4.00000000e+00, 4.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        4.00000000e+00, 4.00000000e+00, 1.00000000e+00],\n",
       "       [1.38572988e-03, 4.30572778e-03, 3.24935388e-03, ...,\n",
       "        5.00000000e+00, 3.00000000e+00, 1.00000000e+00],\n",
       "       [1.81378257e-05, 3.70920222e-03, 4.54049057e-03, ...,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68006, 383) (17002, 383)\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "########## for encode one hot key ##########\n",
    "############################################\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "x = data1.to_dict('records')\n",
    "x_ans = x_ans.to_dict('records')\n",
    "x_train = x_train_.to_dict('records')\n",
    "x_test = x_test_.to_dict('records')\n",
    "x1 = x1.to_dict('records')\n",
    "\n",
    "vec = DictVectorizer()\n",
    "vec.fit(x1)\n",
    "x = vec.transform(x).toarray()\n",
    "x_ans = vec.transform(x_ans).toarray()\n",
    "x1 = vec.transform(x1).toarray()\n",
    "x_train = vec.transform(x_train).toarray()\n",
    "x_test = vec.transform(x_test).toarray()\n",
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.59939347e-02, 5.77320843e-01, 8.90527102e-03, 7.11897519e-03,\n",
       "       3.35916254e-02, 1.48032200e-01, 1.58923629e-02, 9.99806503e-01,\n",
       "       1.01617109e-02, 7.53124552e-03, 4.92169175e-02, 1.82842947e-01,\n",
       "       1.89322625e-02, 6.00243337e-01, 1.20253013e-02, 4.30302566e-03,\n",
       "       4.26807444e-02, 2.25968049e-01, 1.64437528e-02, 9.99988312e-01,\n",
       "       1.11962974e-02, 6.44417862e-03, 2.03763038e-01, 2.66666667e-01,\n",
       "       1.00000000e+00, 0.00000000e+00, 1.00000000e+01, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 4.00000000e+00,\n",
       "       6.00000000e+00, 3.00000000e+00, 3.00000000e+00, 3.00000000e+00,\n",
       "       3.00000000e+00, 3.00000000e+00, 3.00000000e+00, 3.00000000e+00,\n",
       "       3.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "############## not imbalance ###############\n",
    "############################################\n",
    "x_sm = x_train \n",
    "y_sm = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "################ imbalance #################\n",
    "############################################\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# sm = SMOTE(random_state=42)\n",
    "sm = ADASYN(random_state=42)\n",
    "sm.fit(x1)\n",
    "# x_sm, y_sm = sm.fit_sample(x_train, y_train)\n",
    "x_sm, y_sm = sm.sample(x_train, y_train)\n",
    "\n",
    "print(x_sm.shape,y_sm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79608, 20) (79608, 1)\n",
      "(63686, 20) (63686, 1) (15922, 20) (15922, 1)\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "################### PCA ####################\n",
    "############################################\n",
    "x_sm = x_train \n",
    "y_sm = y_train\n",
    "from sklearn.decomposition import PCA , NMF\n",
    "n_components = 20\n",
    "pca = PCA(n_components=n_components, svd_solver='full',random_state=42)\n",
    "# pca = NMF(n_components=n_components, init='random', random_state=42)\n",
    "pca.fit(x1)\n",
    "x = pca.transform(x)\n",
    "x_sm = pca.transform(x_sm)\n",
    "x_ans = pca.transform(x_ans)\n",
    "x_train = pca.transform(x_train)\n",
    "x_test = pca.transform(x_test)\n",
    "\n",
    "\n",
    "print(x.shape,y.shape)\n",
    "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63686, 20) (40000, 20) (40000, 1) (23686, 20) (23686, 1)\n",
      "(63686, 1)\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "########## optional for val data ###########\n",
    "############################################\n",
    "split = 40000\n",
    "x_sm0 = x_sm[:split]\n",
    "x_val0 = x_sm[split:]\n",
    "y_sm0 = y_sm[:split]\n",
    "y_val0 = y_sm[split:]\n",
    "print(x_sm.shape,x_sm0.shape,y_sm0.shape,x_val0.shape,y_val0.shape)\n",
    "print(y_sm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63686, 20) (40000, 20) (40000, 1) (23686, 20) (23686, 1) (15922, 20) (79608, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x_sm.shape,x_sm0.shape,y_sm0.shape,x_val0.shape,y_val0.shape,x_test.shape,x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## take log #####################\n",
    "# np.exp(np.log(q)) \n",
    "y_sm0_log = y_sm0\n",
    "y_val0_log = y_val0\n",
    "y_test_log = y_test\n",
    "y_train_log = y_train\n",
    "y_log = y\n",
    "y_sm_log = y_sm\n",
    "# y_val_log = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from numpy import inf\n",
    "\n",
    "y_sm0_log = np.log(y_sm0_log)\n",
    "y_val0_log = np.log(y_val0_log)\n",
    "y_test_log = np.log(y_test_log)\n",
    "y_train_log = np.log(y_train_log)\n",
    "y_log = np.log(y_log)\n",
    "y_sm_log = np.log(y_sm_log)\n",
    "# y_val_log = np.log(y_val_log)\n",
    "\n",
    "y_sm0_log[y_sm0_log == -inf] = -9999\n",
    "y_val0_log[y_val0_log == -inf] = -9999\n",
    "y_test_log[y_test_log == -inf] = -9999\n",
    "y_train_log[y_train_log == -inf] = -9999\n",
    "y_log[y_log == -inf] = -9999\n",
    "y_sm_log[y_sm_log == -inf] = -9999\n",
    "# y_val_log[y_val_log == -inf] = -9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log[y_log < 0.01] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import inf\n",
    "y_train_log[y_train_log == -inf] = -9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y[18553:18958]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[np.argwhere(np.isnan(y))[:,0],0] = 0\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79608, 1)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "############### Xgboost ####################\n",
    "############################################\n",
    "# np.exp(np.log(q)) \n",
    "y_sm0_log = y_sm0\n",
    "y_val0_log = y_val0\n",
    "y_test_log = y_test\n",
    "y_train_log = y_train\n",
    "y_log = y\n",
    "y_sm_log = y_sm\n",
    "import xgboost as xgb\n",
    "dsm = xgb.DMatrix(x_sm0, label=y_sm0_log)\n",
    "dv0 = xgb.DMatrix(x_val0, label=y_val0_log)\n",
    "dt = xgb.DMatrix(x_test, label=y_test_log)\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train_log)\n",
    "evallist = [(dv0, 'eval'), (dsm, 'train')]\n",
    "                  \n",
    "dsm = xgb.DMatrix(x_sm, label=y_sm_log)                  \n",
    "evallist = [(dt, 'eval'), (dsm, 'train')]\n",
    "\n",
    "dx = xgb.DMatrix(x, label=y)\n",
    "dan = xgb.DMatrix(x_ans, label=y_ans)\n",
    "evallist = [(dan, 'eval'), (dx, 'train')]\n",
    "num_round = 100\n",
    "# binary:logistic\n",
    "param = {\n",
    " 'objective': 'reg:linear',\n",
    " 'colsample_bytree': 0.9683760122352089,\n",
    " 'gamma':0.8835260600913024,\n",
    " 'learning_rate': 0.199426498504554,\n",
    " 'max_depth': 20,\n",
    " 'min_child_weight': 10.95324500379702,\n",
    " 'n_estimators': 5,\n",
    "#  'objective': 'binary:logistic',\n",
    " 'scale_pos_weight': 1,\n",
    " 'seed': 42,\n",
    " 'eval_metric': 'mae',\n",
    " 'lambda': 15,\n",
    " 'alpha': 20,\n",
    "#  'rate_drop':0.950292864879127905,\n",
    "#  'tree_method':'exact',\n",
    " 'normalize_type':'forest',\n",
    " 'subsample': 0.9035691355661921}\n",
    " \n",
    "evals_result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:21:50] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=18\n",
      "[0]\teval-mae:2.20012e+06\ttrain-mae:2.09311e+06\n",
      "Multiple eval metrics have been passed: 'train-mae' will be used for early stopping.\n",
      "\n",
      "Will train until train-mae hasn't improved in 100 rounds.\n",
      "[19:21:51] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 166 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[1]\teval-mae:1.84638e+06\ttrain-mae:1.79269e+06\n",
      "[19:21:51] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 202 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[2]\teval-mae:1.56761e+06\ttrain-mae:1.55741e+06\n",
      "[19:21:51] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 334 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[3]\teval-mae:1.33805e+06\ttrain-mae:1.36459e+06\n",
      "[19:21:51] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 388 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[4]\teval-mae:1.15007e+06\ttrain-mae:1.20383e+06\n",
      "[19:21:51] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 468 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[5]\teval-mae:1.01285e+06\ttrain-mae:1.08381e+06\n",
      "[19:21:51] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 488 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[6]\teval-mae:906138\ttrain-mae:986780\n",
      "[19:21:51] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 746 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[7]\teval-mae:829498\ttrain-mae:912024\n",
      "[19:21:51] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 810 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[8]\teval-mae:768962\ttrain-mae:853934\n",
      "[19:21:51] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 1102 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[9]\teval-mae:737012\ttrain-mae:809372\n",
      "[19:21:51] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 1016 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[10]\teval-mae:703843\ttrain-mae:776489\n",
      "[19:21:51] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 1306 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[11]\teval-mae:676443\ttrain-mae:750845\n",
      "[19:21:51] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 952 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[12]\teval-mae:660475\ttrain-mae:736584\n",
      "[19:21:51] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 1296 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[13]\teval-mae:643663\ttrain-mae:722607\n",
      "[19:21:51] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 1248 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[14]\teval-mae:627886\ttrain-mae:707705\n",
      "[19:21:51] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 1166 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[15]\teval-mae:617056\ttrain-mae:699629\n",
      "[19:21:52] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 892 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[16]\teval-mae:608964\ttrain-mae:693450\n",
      "[19:21:52] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 1030 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[17]\teval-mae:600241\ttrain-mae:689168\n",
      "[19:21:52] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 750 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[18]\teval-mae:596220\ttrain-mae:684541\n",
      "[19:21:52] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 536 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[19]\teval-mae:596981\ttrain-mae:682238\n",
      "[19:21:52] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 846 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[20]\teval-mae:601461\ttrain-mae:681989\n",
      "[19:21:52] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 676 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[21]\teval-mae:599389\ttrain-mae:676964\n",
      "[19:21:52] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 542 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[22]\teval-mae:604153\ttrain-mae:677781\n",
      "[19:21:52] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 496 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[23]\teval-mae:606634\ttrain-mae:678377\n",
      "[19:21:52] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 610 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[24]\teval-mae:608020\ttrain-mae:679074\n",
      "[19:21:52] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 416 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[25]\teval-mae:611064\ttrain-mae:678030\n",
      "[19:21:52] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 268 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[26]\teval-mae:612800\ttrain-mae:674297\n",
      "[19:21:52] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 362 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[27]\teval-mae:619188\ttrain-mae:675628\n",
      "[19:21:52] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[28]\teval-mae:618186\ttrain-mae:674707\n",
      "[19:21:52] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 140 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[29]\teval-mae:615638\ttrain-mae:673693\n",
      "[19:21:52] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 184 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[30]\teval-mae:617016\ttrain-mae:674073\n",
      "[19:21:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 352 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[31]\teval-mae:621957\ttrain-mae:674823\n",
      "[19:21:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[32]\teval-mae:620652\ttrain-mae:673240\n",
      "[19:21:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 182 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[33]\teval-mae:616418\ttrain-mae:669330\n",
      "[19:21:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 132 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[34]\teval-mae:619900\ttrain-mae:669912\n",
      "[19:21:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[35]\teval-mae:622740\ttrain-mae:670455\n",
      "[19:21:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 168 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[36]\teval-mae:620336\ttrain-mae:667279\n",
      "[19:21:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[37]\teval-mae:621952\ttrain-mae:664283\n",
      "[19:21:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 80 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[38]\teval-mae:626825\ttrain-mae:665671\n",
      "[19:21:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[39]\teval-mae:627342\ttrain-mae:665671\n",
      "[19:21:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 166 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[40]\teval-mae:631821\ttrain-mae:667327\n",
      "[19:21:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[41]\teval-mae:632000\ttrain-mae:667320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:21:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[42]\teval-mae:628608\ttrain-mae:662530\n",
      "[19:21:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 228 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[43]\teval-mae:629430\ttrain-mae:663128\n",
      "[19:21:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 86 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[44]\teval-mae:626940\ttrain-mae:658386\n",
      "[19:21:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[45]\teval-mae:627149\ttrain-mae:656512\n",
      "[19:21:54] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[46]\teval-mae:631918\ttrain-mae:656605\n",
      "[19:21:54] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 76 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[47]\teval-mae:635488\ttrain-mae:658519\n",
      "[19:21:54] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 166 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[48]\teval-mae:632872\ttrain-mae:657362\n",
      "[19:21:54] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 142 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[49]\teval-mae:636037\ttrain-mae:658605\n",
      "[19:21:54] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[50]\teval-mae:635230\ttrain-mae:654439\n",
      "[19:21:54] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 186 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[51]\teval-mae:641809\ttrain-mae:657520\n",
      "[19:21:54] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[52]\teval-mae:641207\ttrain-mae:657582\n",
      "[19:21:54] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 172 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[53]\teval-mae:643645\ttrain-mae:656703\n",
      "[19:21:54] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 84 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[54]\teval-mae:644094\ttrain-mae:656640\n",
      "[19:21:54] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[55]\teval-mae:638073\ttrain-mae:648935\n",
      "[19:21:54] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 66 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[56]\teval-mae:644650\ttrain-mae:652133\n",
      "[19:21:54] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[57]\teval-mae:640436\ttrain-mae:646847\n",
      "[19:21:54] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[58]\teval-mae:640183\ttrain-mae:646561\n",
      "[19:21:54] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 224 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[59]\teval-mae:645080\ttrain-mae:647532\n",
      "[19:21:55] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[60]\teval-mae:652112\ttrain-mae:651182\n",
      "[19:21:55] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[61]\teval-mae:653383\ttrain-mae:652070\n",
      "[19:21:55] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 104 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[62]\teval-mae:647932\ttrain-mae:647673\n",
      "[19:21:55] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 244 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[63]\teval-mae:645733\ttrain-mae:643607\n",
      "[19:21:55] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[64]\teval-mae:651528\ttrain-mae:644604\n",
      "[19:21:55] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 242 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[65]\teval-mae:652131\ttrain-mae:645277\n",
      "[19:21:55] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[66]\teval-mae:653886\ttrain-mae:645531\n",
      "[19:21:55] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[67]\teval-mae:655801\ttrain-mae:643010\n",
      "[19:21:55] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 92 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[68]\teval-mae:652731\ttrain-mae:642439\n",
      "[19:21:55] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[69]\teval-mae:658425\ttrain-mae:643804\n",
      "[19:21:55] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 262 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[70]\teval-mae:664429\ttrain-mae:645918\n",
      "[19:21:55] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 310 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[71]\teval-mae:668169\ttrain-mae:647078\n",
      "[19:21:55] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 76 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[72]\teval-mae:667826\ttrain-mae:647268\n",
      "[19:21:55] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 194 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[73]\teval-mae:670825\ttrain-mae:647726\n",
      "[19:21:55] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 96 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[74]\teval-mae:669703\ttrain-mae:647616\n",
      "[19:21:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 166 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[75]\teval-mae:673454\ttrain-mae:646789\n",
      "[19:21:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 156 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[76]\teval-mae:674713\ttrain-mae:644671\n",
      "[19:21:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[77]\teval-mae:675470\ttrain-mae:645008\n",
      "[19:21:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 128 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[78]\teval-mae:678835\ttrain-mae:645960\n",
      "[19:21:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[79]\teval-mae:673749\ttrain-mae:641472\n",
      "[19:21:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 92 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[80]\teval-mae:676359\ttrain-mae:642780\n",
      "[19:21:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 208 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[81]\teval-mae:679529\ttrain-mae:643974\n",
      "[19:21:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[82]\teval-mae:682268\ttrain-mae:645231\n",
      "[19:21:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[83]\teval-mae:682344\ttrain-mae:645108\n",
      "[19:21:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 66 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[84]\teval-mae:681655\ttrain-mae:644591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:21:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 76 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[85]\teval-mae:685881\ttrain-mae:645277\n",
      "[19:21:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 228 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[86]\teval-mae:685152\ttrain-mae:645006\n",
      "[19:21:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 86 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[87]\teval-mae:683977\ttrain-mae:643643\n",
      "[19:21:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 132 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[88]\teval-mae:681472\ttrain-mae:638278\n",
      "[19:21:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 84 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[89]\teval-mae:686473\ttrain-mae:640131\n",
      "[19:21:57] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[90]\teval-mae:688116\ttrain-mae:640702\n",
      "[19:21:57] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 122 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[91]\teval-mae:688674\ttrain-mae:641388\n",
      "[19:21:57] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[92]\teval-mae:689787\ttrain-mae:641343\n",
      "[19:21:57] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[93]\teval-mae:686600\ttrain-mae:639379\n",
      "[19:21:57] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[94]\teval-mae:687688\ttrain-mae:637922\n",
      "[19:21:57] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 180 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[95]\teval-mae:691338\ttrain-mae:638169\n",
      "[19:21:57] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 84 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[96]\teval-mae:693696\ttrain-mae:638019\n",
      "[19:21:57] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[97]\teval-mae:697014\ttrain-mae:638363\n",
      "[19:21:57] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 80 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[98]\teval-mae:698279\ttrain-mae:638288\n",
      "[19:21:57] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 98 extra nodes, 0 pruned nodes, max_depth=20\n",
      "[99]\teval-mae:694128\ttrain-mae:633904\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(param, dx, num_round, evallist, evals_result=evals_result,early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error , precision_score , recall_score , accuracy_score , roc_curve , auc , classification_report,fbeta_score\n",
    "def smape(A, F):\n",
    "#     F[F <= 0] = 0.01\n",
    "#     F = np.exp(F)\n",
    "    b = np.abs(A) + np.abs(F)\n",
    "    b[b == 0] = 0.0000001\n",
    "    smape_s = 100/len(A) * np.sum(2 * np.abs(F - A) / (b))\n",
    "#     smape_s = 1-(smape_s/200)\n",
    "    return smape_s\n",
    "\n",
    "def score1(y_true,y_pre,thresholds = 0.5):\n",
    "    mae = mean_absolute_error(y_true, y_pre)\n",
    "#     mae = smape(y_true, y_pre)\n",
    "    print(mae,'mean_absolute_error')\n",
    "    \n",
    "\n",
    "#     y_pre[y_pre >= threshold] = 1\n",
    "#     y_pre[y_pre < threshold] = 0\n",
    "#     print(fbeta_score(y_test, y_pre, pos_label=1 , average='binary', beta=0.5),'f2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601447.8410914895 mean_absolute_error\n"
     ]
    }
   ],
   "source": [
    "#### evaluate ###\n",
    "from sklearn.metrics import f1_score , precision_score , recall_score , accuracy_score , roc_curve , auc , classification_report,fbeta_score\n",
    "threshold = 0.3907732\n",
    "treee = bst.best_ntree_limit\n",
    "# treee = 21\n",
    "y_pre = np.array(bst.predict(dan, ntree_limit=treee))\n",
    "y_pre[y_pre < 0] = 0\n",
    "score1(y_ans,y_pre)\n",
    "\n",
    "\n",
    "# y_pre_1 = np.array(bst.predict(dv0, ntree_limit=treee))\n",
    "# score1(y_val0,y_pre_1)\n",
    "# fpr, tpr, thresholds = roc_curve(y_val0, y_pre_1, pos_label=1)\n",
    "# y_pre_1[y_pre_1 >= threshold] = 1\n",
    "# y_pre_1[y_pre_1 < threshold] = 0\n",
    "# f_11 = fbeta_score(y_val0, y_pre_1, pos_label=1 , average='binary', beta=0.5)\n",
    "# roc1_11  = auc(fpr, tpr)\n",
    "\n",
    "# y_pre_2 = np.array(bst.predict(dtrain, ntree_limit=treee))\n",
    "# score1(y_train,y_pre_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.9995386e+08, 3.4326505e+06, 8.5431120e+06, ..., 1.1079185e+05,\n",
       "       1.3440816e+05, 8.0324859e+04], dtype=float32)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.98549736e+08],\n",
       "       [3.74624553e+06],\n",
       "       [1.53919859e+06],\n",
       "       ...,\n",
       "       [1.35344700e+04],\n",
       "       [1.03929100e+04],\n",
       "       [2.19875400e+04]])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b8ac20df98>"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### feature important ######\n",
    "xgb.plot_importance(bst,max_num_features =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:11:00] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 94 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[0]\teval-mae:1.91567e+06\ttrain-mae:1.88316e+06\n",
      "Multiple eval metrics have been passed: 'train-mae' will be used for early stopping.\n",
      "\n",
      "Will train until train-mae hasn't improved in 10 rounds.\n",
      "[18:11:00] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 104 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[1]\teval-mae:1.54436e+06\ttrain-mae:1.46595e+06\n",
      "[18:11:00] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 136 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[2]\teval-mae:1.27082e+06\ttrain-mae:1.15505e+06\n",
      "[18:11:00] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 158 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[3]\teval-mae:1.08151e+06\ttrain-mae:952956\n",
      "[18:11:00] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 176 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[4]\teval-mae:948290\ttrain-mae:818978\n",
      "[18:11:00] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 174 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[5]\teval-mae:864305\ttrain-mae:730559\n",
      "[18:11:00] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 182 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[6]\teval-mae:796571\ttrain-mae:671797\n",
      "[18:11:01] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 202 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[7]\teval-mae:743085\ttrain-mae:613943\n",
      "[18:11:01] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 206 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[8]\teval-mae:708093\ttrain-mae:583571\n",
      "[18:11:01] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 220 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[9]\teval-mae:689275\ttrain-mae:558213\n",
      "[18:11:01] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 142 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[10]\teval-mae:679963\ttrain-mae:547978\n",
      "[18:11:01] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 86 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[11]\teval-mae:667162\ttrain-mae:543778\n",
      "[18:11:01] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[12]\teval-mae:659190\ttrain-mae:539104\n",
      "[18:11:01] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 84 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[13]\teval-mae:654961\ttrain-mae:535326\n",
      "[18:11:01] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[14]\teval-mae:651428\ttrain-mae:531057\n",
      "[18:11:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[15]\teval-mae:652937\ttrain-mae:531046\n",
      "[18:11:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[16]\teval-mae:643113\ttrain-mae:524639\n",
      "[18:11:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[17]\teval-mae:644459\ttrain-mae:525516\n",
      "[18:11:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[18]\teval-mae:640051\ttrain-mae:520981\n",
      "[18:11:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[19]\teval-mae:641123\ttrain-mae:520729\n",
      "[18:11:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[20]\teval-mae:642447\ttrain-mae:524058\n",
      "[18:11:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[21]\teval-mae:641861\ttrain-mae:525380\n",
      "[18:11:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[22]\teval-mae:640710\ttrain-mae:523270\n",
      "[18:11:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[23]\teval-mae:638889\ttrain-mae:522669\n",
      "[18:11:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[24]\teval-mae:634327\ttrain-mae:519635\n",
      "[18:11:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[25]\teval-mae:633604\ttrain-mae:519738\n",
      "[18:11:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[26]\teval-mae:630905\ttrain-mae:517418\n",
      "[18:11:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[27]\teval-mae:624977\ttrain-mae:515383\n",
      "[18:11:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[28]\teval-mae:623072\ttrain-mae:509895\n",
      "[18:11:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[29]\teval-mae:619552\ttrain-mae:508463\n",
      "[18:11:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[30]\teval-mae:615374\ttrain-mae:507552\n",
      "[18:11:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[31]\teval-mae:608584\ttrain-mae:504054\n",
      "[18:11:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[32]\teval-mae:606235\ttrain-mae:503531\n",
      "[18:11:03] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 98 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[33]\teval-mae:603369\ttrain-mae:496727\n",
      "[18:11:04] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[34]\teval-mae:602113\ttrain-mae:498685\n",
      "[18:11:04] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[35]\teval-mae:600977\ttrain-mae:498565\n",
      "[18:11:04] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[36]\teval-mae:596118\ttrain-mae:498703\n",
      "[18:11:04] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[37]\teval-mae:595491\ttrain-mae:497806\n",
      "[18:11:04] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[38]\teval-mae:593161\ttrain-mae:500110\n",
      "[18:11:04] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[39]\teval-mae:590841\ttrain-mae:500437\n",
      "[18:11:04] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[40]\teval-mae:587060\ttrain-mae:499988\n",
      "[18:11:04] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[41]\teval-mae:582204\ttrain-mae:499000\n",
      "[18:11:04] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[42]\teval-mae:579189\ttrain-mae:497616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:11:04] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=10\n",
      "[43]\teval-mae:578866\ttrain-mae:499174\n",
      "Stopping. Best iteration:\n",
      "[33]\teval-mae:603369\ttrain-mae:496727\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(param, dx, num_round, evallist, evals_result=evals_result,early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655415.5520777636 mean_absolute_error\n"
     ]
    }
   ],
   "source": [
    "dans = xgb.DMatrix(x_ans)\n",
    "treee = bst.best_ntree_limit\n",
    "sv = np.array(bst.predict(dans, ntree_limit=treee))\n",
    "sv[sv < 0] = 0\n",
    "score1(y_ans,sv)\n",
    "# sv = y_a\n",
    "# sv = model2.predict(x_ans)\n",
    "# sv[sv < 0] = 0\n",
    "# sv[sv > 2952646748] = 2952646748\n",
    "# np.savetxt(\"sub1.csv\", sv, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 85)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treee = bst.best_ntree_limit\n",
    "np.array(bst.predict(dans, ntree_limit=treee)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 601533.56   279951.16   789052.56  1094893.     166813.14   335277.8\n",
      "  200353.47    73563.89   900441.06    63980.555  748805.6    158665.38\n",
      "  101399.69   676551.8     82080.625   28821.59    63338.004  148801.67\n",
      "   48469.5    219916.39 ]\n",
      "[ 663095.33  157859.19   40611.47 1155263.61  725202.63  430350.06\n",
      "   39591.34  105374.95  280170.    126397.57  938628.     88660.33\n",
      "  113809.    837102.05  119852.52    1900.     22750.06   28551.2\n",
      "    7000.    292953.1 ]\n"
     ]
    }
   ],
   "source": [
    "print(y_pre[:20])\n",
    "print(y_test[:20,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "treee = bst.best_ntree_limit\n",
    "# sv = np.array(bst.predict(dans, ntree_limit=treee))\n",
    "sv = y_a\n",
    "# sv = model2.predict(x_ans)\n",
    "sv[sv < 0] = 0\n",
    "sv[sv > 2952646748] = 2952646748\n",
    "np.savetxt(\"sub1.csv\", sv, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "from sklearn.ensemble.partial_dependence import partial_dependence\n",
    "from sklearn import linear_model\n",
    "from sklearn import grid_search\n",
    "import scipy.stats as st\n",
    "from sklearn.model_selection import RandomizedSearchCV , GridSearchCV\n",
    "\n",
    "# clf = GradientBoostingRegressor(n_estimators=20, max_depth=8,\n",
    "#                                     learning_rate=0.1, loss='lad',\n",
    "#                                     random_state=1)\n",
    "clf = linear_model.ElasticNetCV(cv=5, random_state=0,l1_ratio=[0.05,.1,0.15,.2, .5, .9,0.95, 1],n_jobs=-1\n",
    "                                 ,normalize=True, positive=False)\n",
    "estimator = SVR()\n",
    "# Parameter for SVC\n",
    "params = {  \n",
    "    'C':[0.001, 0.01, 0.1, 1, 10], \n",
    "    'degree': st.randint(1, 10),\n",
    "    'shrinking': [True, False],\n",
    "#     'probability': [True],\n",
    "    'tol': [1e-3],\n",
    "#     'random_state': [seed],\n",
    "}\n",
    "clf = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=10, scoring = 'neg_mean_absolute_error')\n",
    "\n",
    "\n",
    "clf.fit(x, y)\n",
    "# y_a = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00000000e+00,  1.17727978e+08,  0.00000000e+00, -8.79282755e+06,\n",
       "       -1.39358593e+08,  1.53863810e+09,  1.79890178e+09, -1.42938319e+07,\n",
       "       -0.00000000e+00,  0.00000000e+00, -3.79832937e+06,  1.10427109e+09,\n",
       "       -9.30395448e+08, -6.55983616e+07,  5.59404249e+06,  0.00000000e+00,\n",
       "        3.64594284e+07,  0.00000000e+00, -6.47047033e+08,  5.61983198e+07,\n",
       "       -2.55366249e+07,  0.00000000e+00,  0.00000000e+00, -3.74138707e+05,\n",
       "       -2.61974893e+03,  0.00000000e+00,  0.00000000e+00,  1.75977214e+05,\n",
       "        0.00000000e+00,  0.00000000e+00, -8.82505697e+04, -0.00000000e+00,\n",
       "        0.00000000e+00,  6.62067293e+04,  1.82010931e+04,  0.00000000e+00,\n",
       "        1.55182127e+03, -0.00000000e+00,  1.02713955e+05,  2.24063092e+03,\n",
       "       -0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = clf.coef_\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2673070.65336112"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ans.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_last = pd.read_csv('data_test/SolutionWithLastMonthM16.csv', delimiter = ',')\n",
    "y_last = y_last[['Last1_Month_Sum']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405182.968161113 mean_absolute_error\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros(5400)\n",
    "a[a==0] = y_ans.mean()\n",
    "# a.shape\n",
    "score1(y_ans,y_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(406,)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[y == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79608, 1)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592273.5705195959 mean_absolute_error\n"
     ]
    }
   ],
   "source": [
    "y_clf = clf.predict(x_ans)\n",
    "y_clf[y_clf < 0] = 0\n",
    "y_clf[y_clf > 2952646748] = 2952646748\n",
    "score1(y_ans,y_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.33590221e+08, 4.49661849e+05, 8.76943800e+06, ...,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[249510.86],\n",
       "       [136614.15],\n",
       "       [482370.12],\n",
       "       ...,\n",
       "       [470026.46],\n",
       "       [310401.12],\n",
       "       [ 45437.82]])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2298914.302561571 mean_absolute_error\n"
     ]
    }
   ],
   "source": [
    "score1(y_ans,y_clf*0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_a = clf.predict(x_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10739100.28572203,   606619.0745281 , -2706059.7737538 , ...,\n",
       "         473413.95383687,  -648524.23839719,   710813.2556031 ])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = list(range(2,10))+list(range(12,20))\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x**2 for x in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.58075978, -0.45968727, -1.36470559, -0.6232293 , -3.88481152,\n",
       "       -1.06205063, -0.76884534, -0.70764543, -0.78996336, -1.34929036])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(data1)best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe4AAAEJCAYAAABSVsRsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzsnXecXUX5/9+zvYT03iGUQOiJIipWLBQRAn4VEAsaFRQFhJ+FYkBsQIKFDiJNQQQUUDoCQXoWSEjvIXWTbLLZ3u4+vz+eZ/acvbl7czfs3WyS+bxe93XvPWdmzpyZz/TPPONEhICAgICAgIBdAzk7OwIBAQEBAQEBmSM03AEBAQEBAbsQQsMdEBAQEBCwCyE03AEBAQEBAbsQQsMdEBAQEBCwCyE03AEBAQEBAbsQQsMdEBAQEBCwCyGjhts5N8Y5d6z9LnbO7ZXdaAXsKgjcCEiHwI+AgK7Hdhtu59wU4EHgFrs0EvhXNiMVsGsgcCMgHQI/AgKyg0xG3N8HPgJUAYjIYmBwNiMVsMsgcCMgHQI/AgKygEwa7kYRafJ/nHN5QLCTGgCBGwHpEfgREJAFZNJwv+ic+zlQ7Jz7DPAP4LHsRitgF0HgRkA6BH4EBGQBbnuHjDjncoBvAZ8FHPAUcLuE00n2eARuBKRD4EdAQHaQScNdiq5LjRORZ+1/qYhs6I4IBvRcBG4EpEPgR0BAdpCXgZt3gS1AX2AcsC/wov0P2LMRuBGQDoEfAQFZQCZr3MOAo4mUobOAwmxGKmCXQeBGQDoEfgQEZAGZNNwtwMH+j3Pug0Br1mIUsCshcCMgHQI/AgKygEymyv8JPIMqQ98F9gbuz2qsAnYVBG4EpEPgR0BAFpCpqvw7wCmoMvRh4JagDA0I3AhIh8CPgIDsIJOp8mJgI1AG3ItOf52bzUgF7DII3AhIh8CPgIAsIJMRdzXaW04AdwMDgckiEkQmezgCNwLSIfAjICA7yKThbgWKgNdF5Ai7Vi8ixd0Qv4AejMCNgHQI/AgIyA4ymSpPAJ/wf4IyNCCGwI2AdAj8CAjIAjIZca9HrR8JUAuUAGtEZEz2oxfQkxG4EZAOgR8BAdlBJtvBvgKcCHwMXa96kXBQQIAicCMgHQI/AgKygEwa7jeBA4DhwJNAL2ASWggD9mwEbgSkQ+BHQEAWkMlUeQOQb39vBMYCJ4hIJuvjAbsxAjcC0iHwIyAgO8ik4Ra0p7xRRErsWmsofAGBGwHpEPgREJAdZFKABPiI/+OcOzp70QnYxRC4EZAOgR8BAVlAJiPuGlQN6oA61BpStYj0yX70AnoyAjcC0iHwIyAgO8hkxP0F4Fn0XN1G+31SNiMVsMsgcCMgHQI/AgKygExU5W8ADwGbCMrQgPYI3AhIh8CPgIAsoMOpcjuGT9DzdJ1drkAb+z4i4lJ6DNjtEbgRkA6BHwEB2UW6qfIT0akuB1yHTnV9Eri5G+IV0LMRuBGQDoEfAQFZRIcNt4isFJGV9vdJoFVE3gUe6ZaYBfRYBG4EpEPgR0BAdpGJqjxB1MDXoSrRhIhksj4esBsjcCMgHQI/AgKyg0xU5ecC1eipPkX2+3vZjFTALoPAjYB0CPwICMgCMun53mvfnwaeA3KBsA8zAAI3AtIj8CMgIAvorKq8Di18hUEZuucicCMgHQI/AgKyi0xV5QuAFvSggJe7IV4BPRuBGwHpEPgREJBFZHrIyOeAf4lIidkbfiX0mgMCNwLSIfAjICA7yKThbqX9dFdQhgYAgRsB6RH4ERCQHWSiKl+PrleBFTxgXdZiFLArIXAjIB0CPwICsoBMer6fAk4BPgr8D23si7IZqYBdBoEbAekQ+BEQkAUEVXlApxG4EZAOgR8BAdlFpqryGrt2IzAz25EK6PEI3AhIh8CPgIAsojOq8idFJCcoQwM8AjcC0iHwIyAgO8i04fbwylBC4QsI3AhIh8CPgIDsIBNVeVXsdwm6dlWZnegE7GII3AhIh8CPgIAsIJOG+1qgHGgCXgIeBDZvz5NzbpRz7nnn3Hzn3Fzn3I/s+lTn3Brn3Dv2OT7m52fOuSXOuYXOuc/Frn/eri1xzv00dn1v59zrzrnFzrm/O+cK7Hqh/V9i98du7xkBO4TAjYB0CPwICMgGRCTlB3gXmI32klvtu8E+0pG/mP9hwJH2ey9gEXAQMBW4KIX7g4BZQCGwN7AUVaHm2u99gAJzc5D5eQD4iv2+GTjHfp8L3Gy/vwL8Pd0ztvcu4RO4ET6BH4Ef4dNTPpmoyuNYksZ9O4jIOhF5y35XA/OBEWm8fBG4X0QaRWS5PeuD9lkiIstEpAm4H/iic86h+0QfNP93ASfHwrrLfj8IfNrcd/SMgM4hcCMgHQI/AgKyiA4NsIjISgDlLPcBpwMXAL8APtKZh9h00xHA6+b3B865r6HbQ34sIlvQgvlazNtqosK6Kun6UcAAoFJEWlK4H+H9iEiLc26ruU/3jJQYOHCgjB07NsM33TMwceJEAMrKyujbt6+rrKxkv/32m7B27Vpqa2uZNGlSesVjDI2NjeTn5zNhwoSTysvLqaiooKSk5JqSkhJGjhxJXl4e6EhtSsxb4EYPRnfyY9asWZuAvxPqjoAklJWVbRKRQTs7HtlApjaDz7Dvx9Hpp4zhnOsFPAScLyJVzrmbgF+i02e/BKYBZxMZaohDSL0OL2nck+aeszh9HvgDOiVXSNTz9nH+DvAdgNGjRzNzZth+mgrOOSorVWu0fPlyEokEQMbpVVNTw8c//nHuv/9+Jk+eTHl5OQMHDsQ5x2WXXca6deu44447cM5Vp/AeuNHD0R38mDVr1kq6r+441Dm3EK0Dt6D1YTsEfvQcOOdW7uw4ZAuZiNOaYr/zUAI3OecudM5dmM6jcy4fbbT/KiIPA4hIuYgkRKQVuI1oumk1MCrmfSSwNs31TUBf51xe0vV2Ydn9PqgoZjUwGrgBOA7tQR/lnDsoHm8RuVVEJonIpEGDdssO2w6hsaWRmqaatk9OTkSflpYWRITc3Fx+c/Vv+M3Vv2nnNvmzpXYLJ59yMqd9+TQ+e+JnqWmqobRfKfWJegRhypQpvPHGGz74JgI3djl0xI/p06czffr0tH6bm5s59dRTOfPMM5k8eTIAQ4YMITc3l5ycnGR+dEfdsQb4FsqNg4AD0HXzdgj8COgOZDLirgeaURvDq4FaYH9UNNIhnHOjgDdRco90ziVE5A/OuWvRafeNwCCita9HgWedc99COxTFwBtEPd1lqNClFDhWRMQ59zow36bzHTpSAu0J32PXBXjN3D8KvIhuTXnWnvEndP1q3vYSYn3Neq588cq2/yLaSRfrrItI2+/3i8ZEI1WNVdt3mAZbG7ZSUV/RJfFpSjSxqGIRrdIaXcxHc6QFZUMeJLYk+PkTPwfg5/U/Tx1YJdplS8Bzs57j58//HD4EPAXMgf1H70/NlhrGjRsX9/HDnswNgMNuPoxVW1dt36HB4tAt8FztTrTmt0b86I3yY3OCS564BICrmq9K6S+xJUH1DdXKj3ee47IXLqPoo0XU/ruWwvmF7D1ibzZu3BjnR3fUHSvM/9NEA569M02Ly5+/nPvm3Jep8w7zq135S0JjopGGloadktc9AUePOpr/nPGfnR2NbkGHDbeL7A33IZoqGur9icgV2wn7SGAIqjAF+J1zrgH4DEr8HKAM+K7dT56qkhTXk+/F3cdrQR/f5GkxQae5WmL/V5OhyKS6sZoH57WbOW2rfJ09xjnX9vv9IC8nj75Ffd9X5V6aX8refffukgbC4Tj1wFPpW9SXaWdNAwfrG9e33c+tzwWBhCS45lfXpA1rzow53FV7F0PHDUVE2PTcJk46+CRe3fAqtfm15JLLxIkTueWWW7aNhqLHcQPglPGnsLl+u7udNPCdULl2V0fhb+f8TVO2MbqWU6ttXau0MuXCKak9Gpa+upTHax5nwNgBiAiVT1TygVEfYM6qObTSSmtraxs/hg8fDt1TdwxGG39/rZXtrHHHMbbvWD44onNatlT1SLr6pSC3gOK84jZ3exrG9Ru3fUe7CdIdMjLGfq6IXZ6LjrbzpZPWj5xzjwDXo+K0GhG5Nun+zwBE5Df2/yl0+wfAVBH5XNwd8Ft01D7URCRHe3fer4i8atNd69HR/U/Rgw/qReTb5u41oL+InBeLS9s6FToltjDpdQai023vBz0hjB3176cID4ldq0dnZRzaIesMDkIbyV7o0Y/lSffHA7/ag7jRE8PpTFjb48fKTsZpHJqfyfwYiI6Cp0PW6457gf1F5AMW1mxgoYh8KR7R7fCjK/MiW2H29PA6E+aYPU6clqQqr0InuwSdNs/vzEN6mKp8MXB0zM++wJyO4l5aWtpr/PjxE1PcGpPiWmfRE8LYYf9lZWXk5OTQ2tpKUVFRcWNjIyLCRC8rzgCNjY0sXLiQCRMm7OdVw7m5uSPjqvKysrIGtuXA7s6NnhhOp8JKw48xmYYT40ffVPwwVXl31B2F9mmLGu31P9ugA350ZV5kK8yeHl5GYZaVlXV1h6HHIFNVeal9j0rrKgV6oKp8GfBdW/caiPbgf93OocitwK0AkyZNkqAMTY34dFxhYSHOOerr63dlVXngRheiO/jRjaryDeiebr9ePhz46zYOAz96DHZnVXkmDXcr0RawPv6aV5SLSIfy0I5U5bH7twH/tr8dKUDp4HqbMtR6zqmUoatTKIdH+sej799E+3WvDiEiacUh3YmesIblR1MAW7duBTRe06ZNA+CCCy/o0G9zczOTT53MGWecwcmnnEyrtDJosM5qORxTpkzhxBNP9M47UpXTwfVu5wZAojWRqdM9Ah3x49ppukp2wQXb4cfkyZx+xul88eQvkmhNMHCQNto5LieZH91Vd+QSrZfnsu2STkAn0ZRoYmXlyi4R9RbnFTOqT6fHlrskMmm4E0RkbUXXqorZ9VXl9cBWOqEcXrBpAQfdeND2nO1Z8DKeYiAXpFa46N8XAXBRzUWp/cRU5c+8/QwXPXtRT1OVd5obAOP+OI6VW3fbTv6OIQU/Lv73xQBcXHNxaj9xfrzzDBc/e3EbP3ov7r0zVeUFGity0KnyjFXlt8y8haeWPoUGmnkj1VkRY6qw/W6X+uZ66lvqOxVeV0FE2FS3icqG9mfMVDdV09DS0CXPOGb0Mcz45owuCaunIxNVeT6qtM1D17oFKN0TVeWDSgdR+Iouc13y80sy8dJp3HHHHQCcffbZHV7/81/+rL+/eTZ3/OWOlL+3CTfNvYzjZmHUz6jHOUd5a3lb6hblFiEiNEojV0xNT435L83n/tr7GbLPEESEiucqOO7A43ij/A3q8ut2WVV5+b/KKSwsZNjQYSnv+zztKI+3d68zbnYUXRH29d+8Pi0/rpx6ZVr/81+az321923DjzfL36TZNe+SqvIf/fxHNO6rMvvS0tK26+PGjWPp0qVtv+Pw1/cdt2+mjwFSz8bluBwKcwspLShtW6qYNGlSp8J9vxjRewSDStprxYrzijl0yKHk53ZKNpUSyWHvzkinKr8TJe83Ypc3o1NHuUFV3qMUv90djheGDIxd85070A5ZZ+LUkWrYP2Mge5aqvCfxYkfCSMWPBNGSW2d3HXh+DAaqac+PMQRV+e6iAu/qMPc8VTnwvH1/I3athE6aPIVdVlXeGxhdWlpauIcphzulGvbIycnJ8+uZMVX5dsPanmp4J6vKjwEOcc4dB9wuIr+Nx30X2HHQVeHsUBhJ/MhNwY/tIgU/+iSpyjcD3wcGOudGiMgPiPL7CmCEc+4dC+424EC6TlU+wEUmUDPlx56oKt8pYZaVlSWcc/cB3xSRrpmP7yFItx3sLmgbeS9BG7j30FHR8EwfsCuqyoE/Az8BDho/fvzSoAxNDecc48aNY9myZYwbN47q6mrWr1+/O6nKS4Hj0U7sm865R4NqOHN0Bz9MVb4CXRmPw+f3CyJyssXnLLpWVV6LdhRXE/jR42Adtlz0eNY7d25suhaZbgfziyz7+wvbU5WbOO0eYBJQQ6TuPAc96WkjKvYoseurga8656aijWk1cLvdOzzWs12Ciog2Af1NZNIfNeqwztyvAe60kX4F0I9IGXomOvXVap8atlUOtx0HmK11oERrgqrGKuqa67ISfncgNze3bR1u8eLFgFbWv/j1LwD4zg++k9Lf2tVr+eF3fsjst2dT2quUdxe/y1FVRzHt99P4211/Y8jgITQ3NVNbW+u9NNH93MCetUpEmpxz97MdodrG2o3b3XXQVSZxdwV0xI+pv5kKwPfO+15Kf2tWr+G8Kecx661ZlPYqZe6SuXy45sNc+4dr+dtdf2PwoME0NTV5frSiItgzgFHOuc8Q8aMROKAL+VGMDlx8479WRJbZe6XlR6I1sQ03EqJ1QE/ZqbKrIz8nnwElA5IvlxDtGNhtkOl2MD+yEaKRTlpVObrmWYMWoMuAMufcMyjxrxORa51zF6A9VtDp6svRdazDgf+iU+kOOAz4NLo2tgm4wZSetajq80fOubnAbAtrM3CIiOzrnPsDMMzcz0HXvp4HrrRnXMe2Ba5tuiyORRWLmHTrtg25IDS0NNDS2rLNPY9kM4W7RQUer2+KgRxVDV/5jIqPrmzuQIRUha5SHgJ1n6pj6tVTmfreVHgbOBievPtJnr/veV5//XXvox74ON3LjefRGHlu+Gn4DvGB2z4QVOVxdMCPK55W8eIVTR2IGKvQlWXjx+W/u5zLV14Ob8NxXzyOx298nOuuu47XX3+d9957D7TuOAC4A91b7flRjS7RLUGPJr6IHeeHNzzVF+Xgi7Q3wJKWHz94/AfcXHZzJqkWsINIoSo/DNUhPL2TopQ1ZKIqz0F7ngOAOpSs/TJQlY8DTkBV5Z9AFeanoKrywbbGvYJIVX4wMAN4B230Z6Ojdez37WiveQZwsHPu3+hU5tHOuSVor9l3twYA6+36ZqCXU6nlwcB8tIDdbuEWxPy1vX6qF+pT2IfqF3XWtqCgoG3fMcB5p59Hfk6kjLzrrrsA+PrXv56ykc51ufQp6kNJfklGts2vvVa1fBdd1MEWq27E1C9PxTnHGllD8V7F1FfXU5xbTE5uDrXUcuu1t6b1v/idxVwz/RpGMAL3kGNT4yY+J59j5saZVC+q5sxjz2TcPuPiqvJiup8bKy3MuHI4bW9rw/0bKCooYvq0bSehrrvuOkD3LvvfHhdeqIfs+ROz/H+Pjq5nen9H8H7C/OVXfpmWHzddc1Na/0veWcK06dOUHw8qPz4rn2Xmxpm88eAbHPq/Qxk7diy33HILf//730HzbiG6zfSTRPy4Fh0o9AZ+jDbgO8qPw9FRuefgJratNzrkx92X3k3h4EIuu/SytmvOOfoU9uEPv9edaF2df6tWr2LUyFFceOGFKfMz0zzuSn5lg6sew3pts5tjNlDqnPuqiNzb5Q/ciegWVblNO81AC9iFFmYVMXGac+56tAd8r/n5M/CEBfF5Efm2XT8LrVynmvt97foo4AkROdhGT58XkdV2b2nMTytQYsrhP6PrVC5JOfxbdEp/MdqT32q3/KkaA9EptLXmH7R3Nyv22qXoOthi++8PaFlPe8TVkYejFUNnwhhtcaiwsPqjvf+6ToQRRw6aT95QRRwFwH7oTIqPu0dcVT6HdkdMtLndFAtjbizMA+z/ULQyTFj890Ib0wOAKd3MjceAQ4FHReS8mCK5gkg1fDiarnEOrImlg0/j8fa9Cs2L5DX79ZYma9FOyiYiPsXzqxRdtlpiz4zfG2bx721ptyYWp3ThNKL5vd4+vVBONZOa35nEp9DiET/2MnnXgccArE6hPUcHoevW5Wj+N6CDht4oP4osPiOBv6Oj4WYR+UEqfjjnvoEuhSxkx/hxD1AkIp+0628Bo7xqOUN+HIHO4iSXwf3Q87295maxudkL5UrcXao8GWfXksPrR6RPErTcxst9R+ENRfN2aZK7QWj90ozWE7lovsRnKzsT5hYLrxAd4A213/lE9j3ShefTMF4fF6AcWYmK134MfEhEzmU3QmdV5XvRSVV5DxSnbUYrAo8JqJGGuHJ4BVoxFJgytJe5Td632Tvpfyq1bPK1VHs/4+rIHQljEDA29v/AHYxHcpw6Um0WQXvVsFMrVPqgiRMPThNmW3wSiQSLFi1i6NCh9OvX74jm5mby8pSSa9euLW5ubmbs2LGHlZWVNQG/dM79BK28y4m4cYKtYdajhfcZuoYbG9FKpd45V4AKXM5Ad0UAUFpamjt+/PjxSWHF3zE5jb3bZN6MSLruw5iYwk08nI6e05uoYss0nBFJ94pTxDPT+ABp+dGRqrzd9UQiMXjRokWDjR8FSfygubn58IqKik2kzlOHLec5teB4Itqh3dG6o5b279wKFDnn9kY7SXF++B0pqfjRURr27sBN7zTu4m77duDuyNi1PnSuDkuOh0e8Q1bMtnXLjoSZHEZH7pLvdZQ2A81W+afRAeLuBRFJ+0FJOxcl6ma0tyzb82d+81F7WBd2cH8sMMd+/wz4WezeU+jWnKOBp2LXf2Yfh45MfIXQ5s77td955s6Zv0vQKa9l6MikBfgcSsZZwEHm73hg0cSJEyUgNQA58MADJScnR/r27SuHH364GDe2i6amJvnsZz8r06ZNS3l/+fLlMmHCBP+ccuDX+pOD0V6+58ZmYJJkhxtb0U7cUuAS83MlcJLoYRnvPxF3Y3QHP9BKeYvlVw3aOP8PnTJfgI5Y56KW0X7+PvhxCTpLuIxopuJ3wKIkfvzSOLRP4MfOBdqZvwcolAzaq13pk26Nu3/sr7fz2RfrwWWoKu+JJk+ftef6EVsLKZTDIvI48PikSZPa1hIaWhpYXOFn8wJy83KZP38+AJWVlbzzzjs457j4CjVl+bXvfS2lv3Wr13HGcWfQ3NzM0hVLKa8r56tTvsq1U6/lyX89yZDBQ6jYVBG3JLUR+KZz7v/QPMtHlxSaUT78y6lVvq7khkMb7uNFpG0qUEQu7yg9FmxaQHOiuRMpuHsjG/x4+pGnGTJ4SLLJ04+ieVeL8mMc0dLcKrQuOYH3z48rLSzsOfeIyE+Sov848EFJ2pFS2VBJbVMtnUW2Rax1zXWs2rpqtxDL9i3qy6Th7cTDc0XkrJ0Vn2wi3VT5erYVW8SnkbanKu+pJk/z0enW9URrQBkph1dUruDQmw/t6PaegxvtOy6it9QWEa59QYV013Jtsk/FfNrsYFVtqeLqqVdz9WtXazevDvr065PO5GmJPTmu6PUqweRDQd4PN4pQS38Z2yr//L2fD6pyyCo/erX0YlDroJ1h8vRge6PVdn0gcBLbGm9KuSPlZ8/+LKjKs4xgq1yxn32vQNV5hwBvoZXbobIdVbmIPEKM+E5Nni4D/kkKk6doBflHaW+20NuJni3tzRZ+0TnnFcDtzBaiB0OcAHxVYmYLTRn6RXQqzJu19Bv02ymHXcxs4ejRo9tujNhrBCWP6bbzsXuPBeDKK9LbXX6/uPwXl2/znORr8f+p3HcUzo7G5by/qo7vnM+cw5gDxrBy0UqO+OgRVG6qZPn85Tx4w4MZBBb9/O0PfstxJx/HgjELKCop4o+//CN9i/rGXfcF/ojOyjyKTk96brwqIp9wzu2F8nOqc+7LvH9uPIUKZdophzviBsCqm1aRk5/DAw880JZWHqnyapskySCPuiIfsx32xo9sBLLDj7GDx3L1L65Odt0ddceJFlbc5Gl8/djjM/aMw+P8uPW8W6E/FBcXM2pUdILVRRdd1OGOEX/94os7OIxlB3HNNde0hZufk8+YvmPIy8nUpEfPRe/C5KXw3RfpVOV/Qnud58Uub0FH2nmye6jKUyqHfQVgfpvQNax0yuG4uhb01KBNds+LhPYiM0WoF7MssG/vP4fIjndHSkvQkYDQXqmbjy53lNtz+lt8CtKEA6pByGFbxW9f8zM45tafmuTQkYkPJx8VfNWiaZYcn832uxJVNPvlizp7h1mogPD/oVz8JipmTMWNW9FzpD5FlnYcxOGc24iqV+PK/YFsqyrvDOKq+x218exQPvod811hK9qr1hMZhOVbpsEd3PeqtUzilWrXgT+dazGRqjzbdUeyqvwFoE5Ejo9H1rW3e76RaHeFVz9vIn35TYXknSHJdUYuWrf6nfP+YKglRLtLksMbS7SzI9VOkwloB9mv/RyCzoXE51GS8y95x0gyii3ui2m/6yQdD9KFORTlwloiS4dVaDsFe6it8lRKvD6kVnl3iB6qKv+wKZGHoaOqdsphG1VdhCpD8zuhHE6n0oXMFaHxe8nwZ0ZnomhPvt6ZOKULB6A0STWc6zuBEydOzEvh3tt5brueSCRGLFq0aISphgfEVMP5MVX5RLNVfhEqcnzZOXc2mp95PlxTDh+Obsd5P9z4vHXWctGK7Pq4Q+fcucBVQInZsY9vieuscj8dMrb3nga9ifjSlbaiMworiR/E+BFPpw7D2s6ug7yYqvxA4GvOOT9krUbXmruy7qilvRW2ImCh29ZW+WHAJ5xzs0tLSwfGqg7PBf++mZa7jtykqjPiyCf17pJ0z0wOL3ld8LAUYaTKv+29S6pdJ9vjVLow4xu428qjqcpxaujr22g+vsvuYLt8e+o1ItIK2tuuYddWlV+K9iI/hgpamtARdFCGdhLOOSkuLhZ0eUFKSkokPz8/I7+dVJVvtXx6xz5VqOr/k3ZvNtojfxlVDu8oNy4znn8ZeA4dwZwr7Tl7LnCzBFX5dtEd/EAHGP9Al0yyWXdcavXfx9CRXQJdid+HsCOlR8K4MQJYDhTrJR4AviE9QBn+fj6Zqsq9PfEm/3sXVpW/aIXuWXvOc+hBBG3T43SgDAU4/8nzeWf9OwSA5Ar19fX6Jxfq6urAwbjTVe076nOjUvqrr6jn7SvfRhLC/+b8jxtn3sjIz45kyf1LqJxZyb4j901WDa9Cp0j9VHotWsE6dCqwF8qNfYBH3gc3XrZw7rHnLEEFSF5uBbqeOjXVe72y6hUaWnbtjnxXIi8/r40fefl51NXV4XId51xyDgBf+vaXUvorX1PO90/5Pi3NLSxcvpCllUs59ZunctOvbuKlx19i6OChyfx4GzjeqbWzbNUdy4jqDWe/t0gYpv1bAAAgAElEQVQKW+WSYkfKwk0LWVPtbeIEZAN9CvswcXi7gbk/+DwPKHZqtna3sF3eWVV5Uex3T1OVjwNORgUmgk4l5aDTn8T85aIdkE32Pn8lErJ4pFSGBihmXjozWsk2SItliUCiPpHWf+3KWpqrmikdWYqIsOwfy3B5ji1zt0ArtLa2JqvKvXW4TLjxF+fcB4gU5lvQmZ9TnHPHoqOrfkTW5oiFlYdWyKtRbjxPdMynR4fcOOOhM4KqHKJuTkz339ykS6WSEG5+RdXVNxd0oLKej5bOwVBdWc2Nv76RG9+6sU1VHueHqcpB82sUOlCw3iSCVt5FRPXAjqrKB6OMX2fXhxCt/0JsR4pTq5P/jq8I/P613wdVeZaRQlVeICJrbLD4HsqLp6WTtsudHm5UI3q+xpXADBF5tqvivSNIJ07zaw4rULIORYtUITBOOiFOs/AeQdcLP0IKVXmyMMyUoVPt9lRprwwF+C06avfK0Ea00h2NNsaL0Ir5KrQTMgj4Kbq+ElcOv4aKtS4QO5/XOXcLMBkVHh1gzyklqrAHogU3Lt44GG0MKonEER79iMzwYc8rRYmUSpTR39yvIDKTmCqsAnRdvcHi4uFNHC5DG63x6FRycovaD62Q6lFi97d0WmX3WtAKbzSa79V2fRE6gjkkFlY92lEqtGc3WBxHJMUNtNM3GhXgJdBO10Z7rwFoA/qeXdvL3ufSDLkxxZ6ZBwwXkXITWk5Bzdh+Bd2PezaaX2cQceN4+30w8B90NL+PiLSt7Tnn1lq8mlFu5KPlYgS6jOQ7tHuhXHD2Xl5c09/efaG99xx73lILr4JoVqGUSHC0CuVCg73bAotDHpq/S+27Dj2CsjfaYJVbeJ5Peegpf7kWxgR0+eFgczva/OegS0hj0FFKk8XZoWufLUT893HIt/h64VEpUQMYFy+WodxpQIVKh1t4883d4fa+e1kYDUSW7PwoaqPFcwxwM9AoIlfZqCoHVYdvRY9zvE9EpqapO+KCsqeBX0hMVY5y4l5gf4lU5SuBhIjsY//PQgcA76LHBG/FlgKJ6ojD7L/niu9MjDH3vVAdkefKaLs2j6geONTSKV7veO68lyLMSrTM9kFnItbZ71bad0APRZegVtj/Q+z3SEv/5UnhDkLrn7loPu1PdI6AoHzb197Tl39/HoB//xy0/vNhFtk9z+0J9uz59owhaP0Sr3fTpWmhfT+ELn9VossqD0onbJfHG+5M/WQb6YRmP0PtvIIu/vsKKPX8ZxqYqvwIwB/39APn3Gzn3B3OuX52LXkk4w+37+j6AKDSN7YoaaqAC+x+JYDdr0WnyH+MjqD8Vre9gf9DK+zfOeemOufuQiuOXmgBvAmtuLaia1+TiPb79kK3IH0IJc1jwE/MTQ3wPbQXvgAlZSHaqbgNuBstUA5t9L5q/r6EVqB9UWVsvYhM8h/gq8Bb9vsklKhVSW5moZ0Hr+J+Gd3C9DuLRz5awX/D3Dj7fg3YKiIHAbcAfxCRw0Skn4iUoA3NBtQy1Qu0Rx3RCCWBFupGtKJYjXZ2DiIyz1pn3/uihfI2tAL2I+XhaIPyXQvvFOfcAufcX0nPjUJzXwn80K73BXJE5C/2zN9Zvpxj8RgAfM3c7WP3B6HrmSOccyucc5Odc1dbXOuJRu4JlHutaCW0CeVEBbqF7WF7H8+FLUS2tlvQjmwd2ilqsXsLLZz55rcZXRoQdB3+BeB7lteeayegXKjFOGJx+oflRTPakfowcLWF38ue6U/yyyU6DXCtiByOTjm3AC/Z8/zJaTNSxKEePYs6B61wIeJEfMakwMKcaf59B8c3CBXAFfY+Dm2snwD+jXLX20JfjnY8+xE1OI2WTlOAR+wdv+Wcm2n5fLnFrTcw3MSz/0TP2q5By/KXnB5EsgVt5KYApwGHOOeeNCFkHTDQOfemKdHPszS71eL5E3RaPWF5/2FLX9+5mWfv/mWi+asqoCFWD+RbvrXVA5bGPt19vXOC5edtsTrgLct7seftBVwpqqTPIbJbUGdxS1j88lDBcDXaGXsVeD0p3LMsXn4/ex9L+wrgN+buNXSpabb9P87ce/vmj1mc/215VmX3mkXkQLSz4mdIn0frgXeMI33QMvIhe+6R6CmP8ff3+foa2gkZZc862vITAOfcxZaHs51zV8SuX+KcW+ice5aYiWzn3J3OudPs9+U+/51ztzq/7uLcC8653znn3nDOLXLOHUMXI92I+x00Me5MdT/TEbcVjBeBX4nIw865IWiGeVX5MBE52zl3AyowiW/p8MrQz0n7LR0fRCuQVyXa0lGLFl4/kn0Q7RFPtXsXoz24QrRiW4v2Jh1a4SeIbJT/Dfg9kFdaWuq2FZUHQFrVcEb+k1TDpLBFzdixY/1zfgjcgHZCKoC/kJobv0EbfV+x7I92Qj4qIqXOuWrgMhH5vY2aBqM8+B/RgRtr0d59PlphL0UrsFPRSutUYFVpaem4wI2O0R38qKio2IpW0M+JyL3OuXpMQIvmfw1wF1rZfw/Nx3PRhuFRNH//gdq03hftCN6A1jEz0Aa5CG2EhqKdjioLrx7ttKxBR+aXoby7Bii2HSmdS7SALoOdcfAxtB1Zi3ZQbgNOEJG9nHOfRfP/uyhXHkU7tbVou3cU2pF5CxWkXuuXQUTkQedcfxHZDOCcuwd4QEQec7pVsExEfuycOx4VZx/ble/W4Rq39bbjp4T5hjp+PndaWM/0IeCvIvKwhVseu38b2gsCbTzjo/mRRCKCVNc3AX2dHl7QQtQAv46K3/oCFTbdVYxm2EVEvV5HNHX3XXQU8x5wv4jcaJX6Y+PHj2fmzN3PRn1XwDqYgO5O8JVzJunV3NzMiSeeyFlnnZXyiL8VK1Zw4oknMnPmTJxzrUAvEWm1DuVH6JgbTWiPvg6dLTkLrXj91Foh0VbHLeZ/s7lfhk5PDiUa7SxAp9fzgSfR3v/hwKDAjfToDn5UVFRsRmfOpjnnLkbzaSE6nXoa2siCTmHnoWLUhWiddgxa/o8wf0+bmyHoKHc6aj8gB50q94fc5BMdIzuPaIbBT+3nA+ePHz/+hsCPnQfn3AIRed059z/g42in7W1gi3OuL/BZ+/ilyF7obOxewD9FpM7CebSDR3zSOff/0BnZ/uiywWN272H7LqP9AVBdgkxV5Y1o5bcYnUrsiaryIrQT8Ffg++japUOP8muOPWMG0VSRX8OdKCJP25TX/vZe/3HO1RGtqVHVWMXjix/X98vgDO3dHcP3Gc6GNRtobW5lyOghrF+5nn6D+vG1i9UG9QlfPyGlv03rNnHJ6ZfQ0tzCvKXzmLVhFsd/9XjuueYeXnnyFUYMGcHmis1x1XAT8EPjhrcl3hE3VqEN7+to3o9CR0bNsbDuMs6MQafmxDm3Cj1sJg/tAA4CXgK+KCKXO+cuFB0yNjjnHkBHctfE3+uxhY9R15zK3kVm2B3sRcfRET/OuljNR6fjx6WnX0pLcwtzl85l1oZZHPfV47jnmnuY+fRMhg0ZFleVO7S8P4vmv7dVfjK6/DEEna1pRhvbf1t+N6KjZr9j4R6b+atAp54/h+79bUTrIn9kpF8SagSORde9V9k6aBE6ujsbXVJqQ9naMpZtWbbdPO5oBrSrsLtxLI5BJYP49D6fjl/yL/tP9DyKHwA451YQLRH+RkTa2VZ2zp0f85sSzrkiVIY5KSn/PbzOI0F6EfgOYXuqcg8fof1i13qCqvx4dH3Mq4M/hRbCt9EeVrX52YKOmsqI1hZ9mJuJDA9U0bG1J9ZWr+X0h05P/9Z7ArxqOFY1rVuxDoAtG7dwz8x7ALin1z2p/c9Hc2ww1FbVcve1d3P3nLvbbJUPbBmYrCr3jW5ybykVNzw8N2rQnnS+c24Nui7qRS4NRGdje2M/cctQW+mEEZXznjgvqMphu/y4d6bqgu7t1YE+KA0/OlCVp6o7tqBTnr3QMu9nDd9xzr0cuzbE/JxkIsb+ROvC/dE6IR+12NcaC78Vbcg32XLgaejy3Agii2htuP2t24OqPMs4ZvQxyQ13YUdu0ZH2F4Fh1lD/Hh34NaODuzudc79F28gvoMttcfg2MTn/uwXp1rinoj3HUUSk98Khwh6iKm9F16U/gE5zrwLuQxvto83NVWgV8g5qScgBz4vI6c65zWgBf1zU5OnDaMN9NyrmOsKeNQcdgSXsuxHt3ft11Do0g/22k1y0wqi3e37rSJHFNwetECYQTb35IwMLUDFFc8zP2/bc4faeo1D15sFEQh8sHB/+UEsfP7PQiBI5rvRdjAoP8+05VRbfgXYtYWHMQQVApfb8I0ltYcpjEbpeOMf8jyVaE1xh3/ujI5kF6PT0Xva+G8ytT9+V6AjqMhH5jVPTuB/H7IWTWlU+1MJegTbgb9t7bSTaMrQVFfEdjnb2ZpqbhbbjYCm6tr3QuFEjIr2cWtWbamnTF234vbWmKpQHmy1dm2k7LoNVlu5jY2m32vwUoKP/fPO/EW26vFLXdz69haj4LgOPApQPjqijs8rCG2rfXgC3wtK00NxXmdtcVECYZ26q7X+uuWtFeefM/3tEIjSIyos31hQ/tzm+3OYFcaC8rCMy5wuqcF6Alo1xaDpXohzJRfkzD+VNMSoixfhRg+ogpqIjrSGoVmc2OvL2CvZ81BrXq0Tl5G/oKH0ukaD002hZ3oLmywOWXl+zdCqwtFqFcnUY8HV03XuwualHRZr72nsWozxfZf59PQDKnQa0vBUQje77Wnqn2oUyGOV1fHvaKlSA19+eX2TfPm983udY+q9E+VZkv7eybd773TKt9j4FFk+x964n2nkyF51CHoLOqnpu+PqyEq3Pmixd+8Ti4N/Z2w3Zap8haEd8ANo56o3mqzerXGjvvQFVm+eISK5z7hvoyDg+4i5C9QmnonVGvqX9V0VkqXPuEjSPV6LldF6KNe6r0AHhCnvuStNUvQBcJCIznXMDURHm2BT5tsNIt1Y9FFVlxrGB9BV2SrjsqcoFVbFegGacNyM4CK3cj0GFBUXm5iGUcEc7555HiTgYNYH6NGqJawVawAqBZ9A1se+hiuf1aEFsQoUoVwL3o43IPLTA/cyeOc/c5aFWmUpQAdQGi99WtAIoQdfSqu19HkEL1veB/4lIrqkkb0ZFfvejortJ9v8jIlKAimi8MnUmWnjOMTcb7X3moY11jaVTEfCmxe0ZtMc43eJUAeSLSIGIHImqfB+w5yaItpb5nl9z7PfRaAVTihbAT6GF4hqUA81oZXg92pvNM3e5locb7T28LYGlGAes8L1BjBtOVd+/RjuavdADIbCwpqEzRS2WJsvQjllfVHzSF7gDrcB7AccaN+rQMuC5sck5NxnlRgVaMfUXkeGokKXe4tuM6imuRNe5fiIie1m+f93i9IDFoxHVfxyKdoZmmP9lKF+XoJ242Shvf03SLoPY51B0GavB8qxARMYR2dBfg1ZCLwIfE5F+Fp+lFu86S49ytGKuRqcRC0Qk197npyJypIgcYel6Z1IcfKPaiJabOOK2qXNRPvqdFovtexzauc5DO0MVaJkRy//Xibg8GK38HyVWR4hIL6I64qdombxERO5EG/AWdNfAFhF5y+Jzk6X5L+3/MAv/R/a8FSjfR6Cc7oU2Ov0srjeau1PRBmOGpf019g5NaGfiXStra9EdG5PQOqjawvw7UeO4wd7lULQsrUPrvPjuE1/m7rJ3L0jK+5PQJYSD0Y7Ir9EdKH6XyA/Reqga5cFAVMNxi73XfJR7zxJpSvqgQsDDJdp9Ml1EnMR2nojIESJygIj0lUgNfzO6NNXL8nKDhX0g2nCOJbKzvlFEBlj+FqL6Fd8R8J1TPw39NPB5ojLcBy1jq5xzA0XkTt9oG45E274KEfmDiBxscT0auMw5d5qI/EpEDgA+LCJnAzOdcy9aHH5to/H5aL02BLhKRKZaPnxCRGba701d3WjDrq8q99umZqMjq+dQIn0JJdq9InKXc24DOhG7Ai0IH6C9Yfp5aKW1EC2cVWjjVlpaWto3KENTo5tV5auBE0VklnHjC2hl0Ms+56N5diE6EjgQrUR84/eCPXYjyr3BaIO+2Pz/A234/LGufmvUu3btILRiuAPVT/QpLS3NCdzoGN2kKm9B6wk/+vbb865E644/ohXrVqJZkv3QWaGBaONxA7qEtwLt8P8BXVI5CeXOVqLR8hYLow+6U+U5bMeBiDzhnHvb/CRKS0sLAj92HsrKygTIlRSNnHPudjR/n0OnyO8z8eud2Ija3PmZtk8A/0Lrlc1oR+92EfmFc+5HwN4icn53vBdkripvd4sMR93doCr30y53oxW3V5B6K0bHm6o8x/7/D93710C0d7nFwnwX7U01oyPBM4H7xo8ff05QhqZGTk5OW2Xsv51z2VCV16IF5VY0H0ei06bVRDsEfoD24peiletB6CisBlUGV5uf1cBH0SWVWpQbfjqzFG2w16Kjm0LUln6zc+5duzcP7c1vGD9+/GWBGx2jO/hRUVGxBZ3yLELz26FTz59BR6Kb0FHkm2hD69AGuhmtM0BnQdaiM0Ub0Yb5HnRrEOioeQPa2Yuvo69D641cdMcBaH22D7B5/PjxYwM/dh6cc+tTNdoAthx2CCowvAjlyze2E+SbIrLOwl6KjvRBOfDJLol0hshUVe7RihG3h6jKE+h0RQ7a4/YJ+Ti6NuUNWLyOjtIfBX5BJErbik55NqGj/6no1POl1li0Uzpsqd/CX9/96zbv2tGsxe6OCR+dwOK3F+PEUVRaRENtA/2H9+eUH50CwKfO+FRKf5vXb2ba2dNINCeYvXg2L69+mU98+RP88w//5K1n32Lk0JFsqdgSV5U3omuTpcaDYnS25cOodqEY7XQdh5q8HY6Ojubb9TNRhfjBKDeORWdlPo5y41jUUIM/pa4Z5UYtZg7XeuPNRLbKP5f8Xne+cyfVjdXJl/dYZIMfc56fw/Ahw5Ntld+ALhV5W/aN6HLVm2infzSajznouqfYFqFL0UZ3MlovTERnYE5HudQXbZDHo52CkURLRC3oKKvVOdccayCGoUsPhxGZXuX55c8zZ8OcHU7L3RnxbYPvB8P3Gs7kAyfHLzV25BZARN4F3nW6B3s52nC3YEvITiMW12nEw4tbCGwlC8rxdMhUVe4RXxPvCapyf93bmf4UWli9AGOovccIorUyb37Rh+OV5KnW0tsdvVdeW855T6Q8mnnPQgrVcENdAwisXbyWf434FwD/6v+v1P79ytBgqKup4+E/PszDix7WnKuHwS2Dk1Xle6F55vdaiX2eIDqf2ePb6L5e0ErbN8Qftt+X2HeJ+RthsfHciCuHt7CtqrxDW+VTX5gaVOWQVX6ksVUOmn97o3n3XzSPi4nElxDlbzM6G9M35v8VouMl90Jn5oaief4GsYGLPSPVjgMvCPu/+MUH5j4QVOVZxjGjj0luuFPClm8nicgLdulwInPUK9AO3ANoJz3fhNpDzO+VqBZlpyJTVbmHN4uX8Rp3LLxsqcrzJbJVXoAKQg5Dp7H8lrDx6BrVmWjFvlxEjrVnFKKN/p/QTsVX0HXSn6INej7a+RiOFmJvurEKLaC15r/C0mo9KlopJuqRVZmfcrRi8Gtxm82NV4DH1cNeST4aVWc3Etkw72/ufU9vBZovwy2MCnT0UYlWXiX2HrXoOr5XqIu58basvYJUUMW1F+EsRSu6AiL73NB+ySS+hNJkYXr1qlfL90FHsuX2joMsDQZZ3IqJOnVeObwXuiZZg45wKizfrkenQX+NcupUdER9AVFj7vdz/w/N+2p0PXIRyu16e+8ZFseTLM5jUFvlo4C+JkDDFMtVRLNFXiBZia6XesFMk4XrR+6llg5L7PoQS2vsWhWqvfDr6mLpsRkd5fmOaLH58SrlSnRa2J9ctb89J975qLVwiy1eTeZmDlomfOe0AuXVZnuvBvOz2uLr970mUE1JX5QfXkHcQnRmshdSxUcrcTQRdZ5ziNafvUrbC9cWonnhG90GIl55W+kT0Onpt9Cy788sOAlN/0ctvfxSXD9Lj42W5muAP9u976Kc8weVbEL5/ziav0Ui8gGrG7+Like/5NdBAZyaVj0MVYCPJLIZ4XccLEEbitUWvldDLyPqaIKWkaHoDMAYNJ8aLH8SFt5YCzPP3ikSFbRHMbp01EI06Fll4Xq+erOosyzcYqL8Xo3WQ16Yu472Ow6w92y29F9IdBZ8guj0vrftHRPo0oS3P47583lfQKTK9yaC/e6cPmjXrg7tpHnVeXXMfbPdqzdhaDs45/ZChYDj0HyuBX4kqgIfggqE/cmR5wHX2rNHiciJFsYLRMrxT9jvE5OflS1kqir3FYFPxE4hi6rypdLeVnk5mmnez12mtl2HWj76MUpG3/Dsja5HfRC4HTXa8BC6J68fKka4Hq3g+hBtA9mKEsv35EvRgj0bbTh8fCvQhqXA4rsvKnzxW7n89qBctGFahxqQecPu9bJwfoU2nn2wgy/QKeL90XFNEdoQbrR0uBQl5BA0j19GC30CLWy+Qp5HdLBHjvlfh04dr7NnF6JLEEvRQuJV68kHqSSSftcRqdeH2HN62e+D7JlNaAPoD9XYSLTlMN/SsZRoK+LLLrJVXojm81JL4wPsuq88NgM/NEWnoGrW3pbeR6BTY33QjtZX0B0IvkH2tsqHAAWmWp+MjiW9rfIpaIfJ2wHfhHbwFqAGPFrQSrfF0u0+VLRUjvLCb6PKQYVz3jznapRzqywNfeP3qD1nCbqjYQZambagndGT7N4WtGK7FBXS+VGnoMsB09AdArejFbEv238jsorYivJ4k73zR4hmI46xXQbe5GyD5dV/0Hy/G+0U3EZ7NMee1YSWgRNRPhXbe2yyMFegDd8iorKasGf4hqcXmocllqarUA1EAm18pliaV6L51YIKbR2RrfI8ND9PRJfF5pi7P6KC2oEWnyfQOuIQ59yTaHlcDezvnHsTWOGce9w5txCtN+vQ3QR+e9KtaINVjHLAAf81tfVEe8Y+dr8aFdadZe/aaPFpsvetQDtNJ4hILxEpwmx8o3XKgeghGpNQoa7fDrrWwpqH1l1FFo95qHrel7ODgScs3OloOSpCeejzOwGMje048J2TPNTCobdVfoV9r0TLUz+ig42uMdX27y29Btt7NaFl2m953IDupPkHWuZb0DJcDgwUkWKLkz8IZZCIeHsjtzvnXnXOzXTOHemce8rWps8UkePt+X+1d7vDOXeFiJSLyIfQtm+yxf8AtK050ZmtchH5BKqhehMtr2ttaj3YKqd7bJXnoYr0F9FCMx8l/LVAQbBV3jG6WVU+D83Dy9DK+F60kJ+AdmCuRCuH7rJV7oIt6vToRlvlf0U7cQlUe/Awuj3IoXXBHWgn7Vy0gj+KrrFV/kvRveO5KCcvQOuX64F1paWlwwI/dh7KyspqRG2SX4fm70fQvJwrIoPdHmCrfBtsT5xmbnYFW+WtwHsiUu/U5Ol+aAG8Crhs/PjxBUEZmhq5ubm0tuogylfKeXl5nHHGGQAp1cAenVSVC9oY/5Noz6tXNrWieyiftGWU7rBVfjQwItgqT4/u4EdFRUU12pCeS2Rk6Ey0wfY7R3yDnY9yoqtslQ92anbZGywaKCK/dWqJa0jgx86Fc26Zc+6f6KxGKSpQ9ff2CFvlfv0yLhRLK07rJlX5+7VVnkB72F9Ee+DL0PX3j9o7/JTYOt3G2o386Y0/WQJ0jRKys9iereEcl5M2bh0pOFPNvGxP7TnxpImsnL2SreVbKSwppKhXEYWlhTz2rnK35sWalP4qyyu59Xu3kmhJ8Pait3lm+TMcfdrRPHnjk8z57xxGDxudrCqvQfPeW7xqQKfaHZp/33LOfZPus1X+JjqF98H4e01/dTqVDZVp02xPwhFfOIL33n2PqvIqCkoK2vjxyGxdgat8PnVaVZZXcse5d5BoSfDWwrd4atlTHHXqUTx909MsnbGUEUNHxFXlLWij+g10pLQPmjeHEBnwESLzl3+x/O4KW+XfRpd9jgJ+TrQWvw6t1z7v3+mxhY8xc+22jXhPsh2+q++OGdN3DN8+8tvxSyIip7jUltO8ZmO3tlXukr4RkSu2E/auYKsctBHIyB51RX0FV824aqcXto4a5m6LVwrVcGNDI1UbdRv9qtN0if+FF15I7X8+bTbrGmobePKmJ3ly+ZPazWuAppamZFV5R0jFDY9ut1X+pzf+xMrKoCqXGy1bkvhRvVGTes1pawB4acZLyV7V/3yJ+FHXwNM3P83TK57usbbK0YZ9bPJrxP88vvjxDlXlPenAoq7amrUzcMzoY5Ib7nTYpW2VIyIpP+hU8RaiHqsXOYh6S+0vTXiPoI32VFSBl3z/Z8DPYv+fQqckj0ZNhrZzRzQDsBydqqpDp8CmotOZDfbb247+L9oTXo9ayYFIjPUn+/8suq7+HXQ61atX56M97lVoxlbada+O9XvC64ns6lajo/hG81NnnxYLeyuRqCJh3/OJzhJutetiz5lv/t61az4M79YrQ/3+44TFodyeucU+deanzsJYRDSaXWrx8PdbiJTR/vkzkziR6uOtk81EO1E+nvXodJJP21X225t7rbVrVbG0X2jf96GF53pLg464sSz2jstRsY5X4y6MvVcFyonNKJfK0BH27RaWN7DguVFj39+x9/ON/loLrwGtxCvtnZrsfZYS2Qifa9d8ni8yt+uJpvfrUfGQz/Ma89NCZGrW58Nsc+9/+50GTUQn31UQ2X3eanH04kJvI7w6lleer0uJ+Bf/NMSeH/+sIeKsf35H/KgjEqt5FXirxXWmvdNsonLklfvef5O522D32+oOSy9fd/gR93R0RP5WLH0EHVw0Ep0pcLvdexvl2z9RLvq4LUC1FBdZ/OahI+s37f2novyoNffVRPVADVE94PPS571Pg3pL3w123ef9aru/0Ny8g+p5fNoviaWL50gFKrajtf8AACAASURBVAprtHC8+M/nvS+P9fa/yp7VTHvO+Xqr0eJVh/JyvqWTr0PE0sTXIzMtvr48eG540arP/yb7X0W0hOHNQVcQmRJeaGnZgJb/TUQ8mEVUb1WidUgjUZn9BnB9rJ5YYWGORIV5cyz8V4Fx5uYSu/Y0qpG4yK7fCZwWayOXoO3GX9DdT6Bi00n2eyCworPt5fY+6VTlXyEy+u+nGXuaqlx4f7bK16O96k86555BD11/ChWp+C0xW1Ai3YwSxVc6k4imzWqJtrR8FyXcU+jUbQFK0CvRLWYbidbetqKNi++9N1tY9SKSgwoq3rA4DEd7dLei9oYnWbrMRon4uIXrt/osREcTt6MjyT4oqadYvP02tl/Y82tQsvuKYzra2SpErUgNQ3UDiyyNN9t3/GADj1qUO/0szCVEI9nX0TWhenT7ztmWTgm7PhwttL5SLkQrgoOARyT7tsq/4PQ415HodGuyrXK/Ha7A4vVxtBLxCvJe6DLSk+auhGhNvTda2P9u7zsc3To0GK2MX6K9jfu+6Jpsrn38tsJiy5OT7H2KLH0azO/JFvfNlrZ+TrrY3I5Dy5Fv6JdZfqwkOuhkCDDFRKhrLC98Y3IpWsYOsXfIJ+Javb1bct3SFPvttxo1E21ra7X3PdLSdiDaKfLh9CZqfPJREaF343lQgopMj0L34c60NLnEwtjXvjcDddJ1tsp/Z9e/ggoXy9G8aoq92zuoffQSdL+4N53ay9L3PXTAkYPyxzeSa4jK82jgZNMfJdBtZQeZe0GtQi5DufgxERmDlntf/spRZf7ZaDn8ocXNbxn1W822Wrr6TnZf85uH8qdORA4UtVn/GbSeTaDLUjn23jdLe1vljZaO30PLr9cXvRXLU3+Izl4oR9ago99CC7sXUZ3Qx+IzAd3ue7u9kz/adQZQZCLr82l/zOpubau8Hk3kO1Pdl56hKu8KW+WFFpc19rxvoT26I4D60tLS3kEZmhrdrCp/EzjK1ifbcQPdvvY7usZW+UfQRq0vWgksIKogX0UrhwlASWlpaWngRsfoJlV5K9rBfNg+R6G7Rp5GR8C9iPZJl6IdrwPoelvlv0GFkKPRRmhuaWnpIYEfOw9lZWViA6Bt4HZXW+XAfGv07kx1s4eoyrvKVvltInK+cy4Hneo6Hy30rwd71B2jG1XltajRHN/LHImOFoahQrQiusZWuT+61QtKEugoKW6rvAldGzsucCM9uklV3oh25D+ETmGDdsDeJbKX8BV0Ov0kNA9X0PW2yq8SkV865+5AR2mHTpo0SQI/dh5sN0pKyO5qqxw4zDlXleZ+T1CVx22V74P2kkFHY58hMnaxPVvl+wNxe9R+et6LUQBYU7WGnz73U1qlte0jIvqNkOtyyc3JJcflRL/JwTlHjstpU3w751IKUrpCGJKtcFNhwnETWDt3LVUbqygsLqSgtICCkgIeeOsBAFY+kVqoVbWhigfOf4BES4KZC2byyMJHOPzkw3nptpdYNGMRY4aPobKiMq4qzwU+55xbQsSNkUSq8rit8iIiM5beathZaMXcFx09l6Cjsk+wra1yv+NgK8qdkbB9bgBc8twlbK7fnHx5j8WBxx3I2rlrqdlYQ0FxAfml+RSUFHBf2X0ALP734pT+qjdU8/CPH6a1pZU357/JQwse4tCTDuWVP7/CmlfXMHLoyGRb5TcS2Sofh+b73WjnbhA649dMZJnvH+gUcDZslfcCBjjnTo/PLNz37n289F5qMd6uio5ma3cW9u2/Lz/+8I/jl5xzbhZa9i8Skbnxm5KhrXIbvC4HGm2kPp0ebKs8QXt5eztIz1CV++v+/xiitRpvotORga3y2H7weBzaoaGlgVdWvdKuEfa/ARKSoFVaSbQmSEiCRGsCQdo18L6RT0ZXFIJshZuMrddtBQet66O2q7mhWZs5gYavq1GwhbMXpvTfNLeJuso6cobmsKVxCzP+PIM3N7xJ42uNSKPQ3NLckaq8I24kw5vm9UZ2fINbhVq9ugadzuzDtrbK42HXoxqIVHHYBk8tfYpVVSnNmO9RqJimmzwS6yM5TJwfnK3X3lvwXkr/DXMaqK+sJ3doLlVNVbxyxyvM3jSb+tfqKWku2Z6tckHrrQfQZbPLiWbmtqJ5/iyqNciGrXKP/Pift9a9xYPzuk903F3oSSr0D438UHLD/Z6IHGZGUP6FLo112lZ5PMDYkm12XiJTpFGBv0Gk1PMfb0dZOquCI3uq8jy7Xm/xm2F+70R7SbPRivt/6NRWHWpjGHRdexUqIJlmcWtG1y9a0QrdK6u9crgK7Wm1EqnCvS3vZgtvLtGUq68w/H2vYG2O+W8lEoytI1JYey2AV4+utvtejdls9338fB7VxsJvJVKP+v3MXkBUF89T2qtbZ6KzGY0W/3gcJMlf8qeFSOiWQCtInz9rLZxN5q429uxm2nPtPSLx3np0NHQ1SdxAC9tAlBe1sXB+bfdetf8b0NGX3x3Qat/Pomue1Zau04hsiNdbGJOJjLvUEJmQ9Cpq/9416GySz4fVMTfzYung33Mx0U4BLxZLoNz0auH4M4RIje93FsxHed4QC8crlzckxW8Dkeq5JfbMxpib+G6GWiKu+7jVxJ6/ye55hbt3k44fiZi7uWg583FuJNoJ4ePh8yn+u4Fod8c/aK8q32ppXUekcPc7LDzXBNW6eJV7XH2dSHp+GVG5eRLV16xDRWNvmrtb0TrpJSJlta8nGolU0D6NvNra2yjwZdLXD8uT0t53JNegfJxNpP72dcY7tFf6r7D79bH8jL+f34nir/l6yH/XW5ptIuKJ/zTEwvDvVGHp7neerEb55neRVJu7KpSzTbH/8V0TXh3v6zQv4vXi6Ea0Pqgm4rhPo5VEKvZGy7tn0fL6Mlq3fxmdlV1IJIJdjA4ih6Czb/69W8ztL9Bl3RdQYfILqFh4psVtUayNWoGae30LLdvju0pN7j/pxGlvomQ9mvYjmGGoqC3jLoepymeg600XolMS3ub1j0Vki3PueuC1JHHaExbE55PEaUehjexr0t7k6Up0xF2Hrq3HTZ7+P1RYMAr4kIgMcc4tQpWhoORYgfbWj0UrzQEDBgwoGjt2bKavukehrKyMsWPHsmLFCiZOnEhlZSVLly7NWHwE0NjYyMKFC5kwYQLl5eVUVFSQm5tLSUkJI0eOJC8vj7KyMkELlZ/SKkYri7eBtUncuAFdTvGzJ4PRxn2CqPnDKuByUZOnteZmDFrh5qIj9Amo0OlgdBrWq85PRZdkLgLuHjBgwOWBGx2jO/gxa9asVrTi3YSW20VoQ1aMTpMvRG1dfxAVHs5E1du/RAcTZ6C8+gzakL+Dqsw/iNYnx6Nr4IuJ7GjfhSrVV4jIlwCcc8+horcGtI65YMCAATcEfuw8lJWVtaJLYX4XQm+0ju+P8qIvKjC7yjlXiDbsX0KFyeegBnSGoJ2Rb4uaOX2B6HCR/iKy2anJ2+fQsxFmm4GXaSLyJ+fcucCRvo7qKqSbKj9ARHrbAr8/AWZ4GvcpYdMSDwHni0iVc+4mtNB4Vfk0onOQkyGkPgjFT2smwx9y8N2k60Vo7+hydMrkRFszH4m+2/FoYX4PLeRfQxuGotLS0mC2sAM451ixYgUA8+bNo75ejx/ONL1qamr4+Mc/zv3338/kyZMpLy9n4MCBOOe47LLLWLduHXfccYeflqoXkQbnXDE60rkOXaNMxQ+/9/Nv6DpnnCslKAdAO6Z+Kw1oL/o0tFB7cdqtaA/dmzw9B50+vTxwIz26gx+zZs3yItPX0cM4/BKIz1Nv+bA3mteHEu0k+ai5n4jWEX8nsrD2BNpp22j//4uufY9Ctz+VoOujfnvjgeja53LU1sAfAj92LpxzTURLHXeayLQZaBKRw51zDwJfc86dZl76oNPpH0NV5gn08JD/dvCI/3POfQfl3zBUEDvb7sVNnm7/rNFOIt0+7iVp7uGcu9Ary9O4SakqF5GEiLSi9sO92ciOVOUdXW+zVe4fZ9d/jxbSoRYHb9puM9EecO/eC5FWiUgT2iDsLyK3ip4wUzto0KB0r7hHIycnoo+vlPPy8pg+fTrTp3e42QBQ1fCpp57KmWeeyeTJyushQ4aQm5tLTk4OU6ZM4Y033oh7GeucexytfI9Et98MJTpKEtqLh/qiR7V+i2hqFHQKbaRzbh+inQneVnkvc7uG2PS0iFwONIriRtSs7qLAjfToJn6sQnULh6MdcH/CmdcteCHGs+gszO+JbJQLat8hgY6qJpnb3igPRhN1+tYQDWAgErWdhu5EWYHub74JHbU/EPix0zEXzdc8dLD2Djr49J05B5wnIofbZ28R8UrxtOIg59ze6Mzbp0VPoPwPPcTk6a6gKh8AbHTObUITrRYdYb2MTsdXo/aqN6BbQh5F1y/ia21xW+VV6NRqSqyuWs2PnvxRutfe7ZDOHOPYT49l44KN1FfUk1ecR35xPvkl+dz+6u0AvPLAKyn91W6s5flLnqe1pZVX573KXbPvYr/j92PW3bNY/cpq9h6xN1s3b42rhhOo/XnfKNejI5xjgCeTuFGH9pwHEFl0OhrAOTcfHU0/hDbSLUC5cWkVarjFbw1rwGyVo9yIozeRUZM2PL30aeqb6ztMr+6A38HQEVItja2rWcf6GrVwnGhNsL5mPRvrNtIq7YXzyeLH7QkfR31qFBULKqjfXE9+UT65xbkUlBRwyysqOnxh2Avt4u1Rt6mOly59Sfkx91X+Musv7HPcPsy5Zw5bZm5h9LDRybbKH0XLvZ+hq0V3itSjR/deakHnoKI0P8Lqj65dCtrQ/wGtb75p165GO3f90NFU3FZ5E9p4b0L3fsdFjLVJ/7nj7Tt4bvlzadNrT4TnUEtrCwnptG2vdjhw4IFc9amrki+/gDbWfxM93Ws5MNqms/sAx1rZvwRdd/dGX77rnLsbbQ8+ic7exdEbM7xltkmOI7IVkXXs6qryVrQC3hJzAzrt/anYtbloYbzU3ileu2Zsq7w50cyiikXbd7iboKOKecmvtK/VuLax7VpLYwsNmxtAYNiP1ADSgk0LUvrfOmsrjVsbKRxeSFOiiXfvfZeNDRvZ/PZmWhItJP4/e2cenmdR9f/PZG/TlqZputMGSqEssi+yva8CLyAiggiviAr8XsAFcQNRBKRgAQHZBApWRRZBQFAU2UFWWbrRvXRv0zZd0rRJ0+zL/P74nsncefIkbSkNpeRcV648z/3cy9wzZ86cOfM932lpTkWVJ3cr8Wk+p+MqD7oR0sCWoLbvjQb1ZrsmDMrB6H9orvILn76QpZWffK7yop5FDOw1kEyX2e63VDRtOsduzrVzwEHdirrWYy31Lfj1nmpfTfElxYAcYWjvEFTMqqC+sp68oXk0+AZmPTKLisYK1k5bS05zTmdc5UHC97ApTSWRnbAnwjB4tBY+GFr3Gg/0pmFnsQY0weiP1s+TNqmZCCysQQN4ujIAsKRiCRNWTKBb2kvIzsnOzN70yZ1I75x2c8neKOKW3N3rSNRuoAjsVDRW3YRsxamI6vYY1LbzEKC1jXjvpznn3kdjyyI0Wewy6QycNoG4HhQkhKE2mzktcb9/oLWfIxGH7G9Sfr/c7nuDfX8BAdBAHLAnJM8Dfm3luRJ1xn8hJPlf0AzrXkTKUYTyMHdDs+/ziR1ttL3fajTzPgSFPIrQbK4RzeLmIw+rrz0rIFdBg0OgK81CIZJwTj7ROQq0g8OJobiAil1n5cuzz/1ou6FBhp2bhQzJUKQw+yEPMcueFTa8DzSW/e14iDA4NEsIbddo77+MaHiK7fmBDnKQ/c9Dxmo1YpPqTJbbdWH2swSBQ2qJm370QE7TUrSuFJYuApK1AHW84IZfjdr3VbtmDHICL7Bz70a52bUIcPQecuheRuvhj9nzFqP2OZzYVmOQkU7qxi5W7oFWP7sjYOW30Qwr0+4318rfg7b86qNQnZdbOQ5ELGw1Vse90KCyAkWEhiH9CujeDagdlqClokBn64jbECYlx8rokW4E6Y9mFgGwF5DwQX+H0HYg2p+IvF5JdIr727lZRF1vsbYI0Ycce+8s2upZqiQdrtn2XsWJY2EgzUgcg0gJ3Ju4tNGAELwZKOxdhLAIY6w+7gQKvPfNZjvG2N9VSI/fQn1+ZxTynmvvPBvpw0SrtybUb3+PInk/JGZO3Iv0YqOVNaSYFRHzgjORLqywdy1A7RiY2UqQDdiJyAseyIF6pNR3f6KuYNcPpK1e7IbaYzaRSXA1bTePKibSz9ZbvU61uigk0tSG5UZQ21UROTNA9qgvEdVdTVsJehGWMELZc1FdL0d6F5YvQqYM9r8nbXUg6FawF2vtfgVIJwISvQDY03vfZrblnDsQAU7/AVQlx6IU8Fl/YJL3vthph7FT7dn7IGxWDuKIqAdO8rY3d1fIJx1Vvob0lKdfRUYnSXk6CQ1mRyJFG4w64dloMNwdKf5wtHblgb8WFhb26kaGppcuRJUD3Oy9v8z0ciUCIf4C6cAJqP37I70oQYPrUSh8tT8Ke5cjY9QDGcF9kCHtg7iODyfqxnjkyPVBRidQnp4OvARsLCwszO3WjY6li1DloD2QS4AB3vszE7Yjg0iW8QoaJL6P+vp85Ey9iJz949FgdAxyAJqIlKdNSCeWeO/3ddrC8RJ77o1ILyqBI5CT+FmgtrCwsLhbPz4+MVT5Id446Z1zgce8BmWaHI1m03d675+2c16j44H7SoQ4z0MTsZ957+91zt0GLPXe395V7/aJR5XbPR9EofDWxyLQ0kn2vQoN9ouRV5yDOm5/+z0fhUX+hDzxi1BHXp+fn9+rGxmaXroQVe6RZ3sZQnW/iFI1alEql0dgtcfQ4Pw2GrjfRUY7VTeGANd77+udc5W0jaQkdSMbGO/bUp7ubPfN7kYNdy5dhCpvQtsu1gOLDIC0MwKaLkez7/Fow54foTasRjbh3MTjAhYizPQC5WmITKwBdjY8RV80W5xApDz9PzQYDEWGfVa3fny8Ysyabzrn5nhtdDIQhcFBY999yOG7zTl3kLdNQjqRV733VUCV2Y2n7fgMFJ3uMukMVb7YOZfKGtUq2wmq3Blq/HYUJg0hmuVE2rosFH5qseM9iQN/kqt8pPd+LOq416GQ7D3dyNCOpQtR5fVAD+fcYK9ddyaigflEFEmp8doxCRTJWU8MpTUh3QgLrsvtt/qEboDCiKm60UpraPra6L0fj+g1F3frRufSRfoRdua71Xu/l+nBJORcLQd29t5PsCW4v6K2DcRG/4t0JHCVh/sFh94j/diJiCoPE4wMBGwMevGs9353NHtfABzarR8fuyxGOvAlAO/9Iu/9fva3t/f+u6YXYVc3SFCe0h7jVZ/4vN1Snu5Le8BFUrYHVHngKgetqQbj/CzioV6PwqrLUSMmucrDdp2zUMg0KalbiQIC03z/2e939to7tLT4Fuqa6lrBRIM/P5j1c9dTX15PVo8sMntkktUzi7vevAuAZ/o/g/eeZt/cBuhWV17H1F9NxTd53pr5FuMmjWPo8UNZ+OhCyt4rY9dhu7Jh3YZUrvKewETLzWyjG0BPJx7zfPs71q6rRrPmsFZYgIxwDor2XIh0Iwethf+QTesGRPrUNnLWk2exeuPqNKdHSUdLu7nivd+q67taBn5uIBXzKmgobyCzR2arfvz2jd8C8I9+/0h7XV15He9f+z6+ub1+1EypYfiQ4alc5SuAC5xzZxK5yiegyMqRzrl1aG21P9BituNdtJTSh8hVXo+WRH6AdKEHwhgMR8txh5HCVZ6m+H0QNuHM5MFb37mVf8xN/747knSy9LrNn73vgH2586Q7Uw+HFOCVibIMAQb5uK1rOsrTCVj2gRNX+Ub7HLjKP1bpbOCehYzYXoljraCS7QRVnnp+LpGrPIBXhiMje4p9/9Bc5Y3NjSypWLKJ196xpUd2D6ZfPR0c1CyvaT3e0iDUMB72vVxRo4ZmYVvChitBapfV0rihkfxh+XjvWfTXRWRkZ1AxqwI8+Bafjqs8lUc8+T/8HqQJ6XYpCqXXoUF7DQp//go5nsVE5y7MtNvpRppqSKsfzS3NNLU0pfup7cVbYcTCJjXbs0y8ciIA1csjRqmlsYWG9Q3g4aArOl/jri6p7lA/slqyOuIqD/bBo5lSIXH/6B7IoYO2+4JvQANtkB8A0+xYAOyFjUZ6sWVc5TXJLwE5vcOLa59p0FXOZif1m1qAbOA3NoDXoUnkd+y33wCPG5aqHfGK3064yrcUVZ5cW94eUOVlyHNqcs7VIO/qr4hIYR5a7xyLDPb7yAlxaK3iLOdc2MB+Z7Q+WoW86KORUV9EJGEIvMoeefW9iRzISxHCu9L+1iP6w7XI+w7o9Cw0G1iA6nU4Ea2dgVDHYaczR0SLbiSmMASU9yraongDCjeTttzO9USa0BFE4xZyUPvbdYFLfZ39lm/vuIa2SNR8IkK0M9Rw4FPPoC3qPpQr5H6E8oapajC4DqGVK1H7hKWOJ6yux9j5qbpxmd3bAXd473/hREd5iGE2XkfOXW/U1tX2zEl2fCcU7vyy1XtA+P8EgY6+TkTFZiDjX5Qob+CY3zdRd3tY/U9FepWfaIdZSBdCndYjfepl9x5lv6+x56QiyvPRzDKg88vteGizXYko59B/A2d5IdGoNSJdDKREATk8wL4PQXoddgbZ3dojDFAB1Z5BRAx3pB919rwlVjeBXz4ftd1yOxbStkB6mW33DVv1riXib35vbR145N9Gs95aVKez7fgZxH4SkP9T7NkNqM2fQX18X6u7CxANagsCM30JTToCqrmHPe/bCGvxExSxG2D1ElDjo+25OVb2ZfY+exP5vpcSqXeDM9KM9CHMEIMMQ/q6GOnyrJTfhyKdabA6qCHahJBNkEfckAk7Vor0J7R9iFKF1MmkDcJ+2wu1a4k9Z3/7H471Rbof+NKDMx1S9cK6QuApzyOm5AU9Cm0dvqfWR7aVI2wuVI/aaAIiS7kJ2dwfee//6URV+msUnc0F7vbe/85pVL4TARUX2/Pu8+0pT+9BANYewBPe+6sBLEf8AaQn2cAZ3vv0ubEfUjYXVR4kKOkWDdzbEFX+UXCV9wTGee+vN7Tocfa3DHGVu25kaHr5MKhhj6ehqYGqhipqm2pZU7lGJqyI1u0QcrNz6ZXfKxVVXoqM6VyE4g1bLaXqxtZwlWcg5PAJzrkpqPPfgVIN3wFO994/55x7CvivwsLCgm7d6Fi6CFVehwaO5cixGI12djqRtlzl+yFDPAltEvIyGqC7ucp3UDG7MREtpZyKoil5wGDv/U5OdKUD/A7MVR6kQ0KWjmRbo8pT5MNwlTeifL4gzwHnIC/TdSNDO5bNRQ2XVJbwlxl/YcoqbW3YyshVD33+0odbHryFU087ldWrVlPYv5B+PftxzdXXpKLKw2ynALEUHWa3T/W64cNzlb8OfMl0YyjSp6cQjiITsbRdiIx6n27d6Fy6CFWehSJjoY2zgS8iu9FCRIXPQHrzAWrPDLq5yndoMQxU4GwIfbyOqCvHI/zUJ46rvLOBOx2qvNUABkS5977DhfqOUOWJ33+PZjPQMXqcDo63cpXb2rQjcpX/FIVzVrhNc5WHrfuC1KPKfxU4sqioKJ9uSSsZGRm0tGgQTkUNA/zkJz9hTtkcDvvDYVQ1VFGQV8B3DvoOexXtxeeGf46fnPMTTrj4BM4/W85o/137t977ggsu4OSTTw5fa5BhPRVlIgxA4CGIIXOIXOUZRK7yiShUl2TbG+acC6HWPrTFREBbRLr33rc45xq9wlPjnXOHAkcXFRXt/qEr71Mgm6MfHUlHqPIgCf1Ya3//9N7fYKHySWhC8DxaDoC4lFSKBuOwJJDKVd5ARJmn4yoPGIjAVf4ZpHcPYVzlzrnzgQ+Kioq+vgXV1S0fvSzy3u9jkdTLQ+aJ6QjQylX+QvIip/27O12Yd5Gr/BCLGN/PdsJV/klAlW8tV3kDchxS+ajTosq7pa1897vf5c0336SkpIRevXvRu09v8nvlM2fFHFZuXMm0p6bx3Pzn6JHdg8kXTmZU4SgASkpKOHT/Q2loaGD58uVkZmbywx/+kEsuuYRHH32UoqKiVNRwPTKmE9GMu46OdeNj4yo//fHTWzm/twdpbG6kqqHqY3t+n6P6UD2/mqb1TWTkZeB6OLJ6ZHHDKzcA8Pvc37c5PwDvGtY1sPimxfhmz+vTX+emd26i8POFrHpyFS0zWhgxZESqfuwGXOucuwLNsPZFocuA/P7Yucqvee0aHp316Iepxm7ZTDl4yME8dNpDyUPJzI8s59wkpBOZzrn/h6J2OxxXeTpUeaDhzNhOUOUfBVd5Oe3RoWnX7xeuW8hxDx2X7qcdUpLpR977VsR02W/K8HiaV8VNASqqKlpdnUlfmAR9YPDCwRw27DDGfn5s66ANMGXKFFavXs1nPvMZvPdcdtll5Obm8tJLL9HS0tIGNZxapA6+J3UjSJdzlffI6kHP7J6be/o2l8ycTIr7Fnc5AvaFn7wADipLKluP+SZP8wah7k+58ZS014UllBVLVrCgagE7Dd8J7z1lT5UxpO8QmhY0keEzUlHlG9FA/DyR+jfoxXbDVT60z1D2HdilHB2fOtm1766d/Xyd9/6XTrsCLkAO2z4I+/RldiCu8slIwXdkrvJdSM9HfRkCqmy0961EBj+gWZvs2aV2/0oUVquz+2wJH/VK5J2PIPKXJ3mHA2o4oMqHIkMyzb4H7tyA8g5o5bnIIyyw6wOpyDQ7P+w3vQw5PgPs3FDe9bRHDmPlH0nnUk/kQa+z/3OIoeyAHg7I1YACb0F1XmFlDmHv0Ab7eu9XpuoG0qlPGlf5ppDlQTdyEDI8F0WQdmLLkeXFVr5Mq+tZ9r5BN8JAtMLesxm1Xy0R7eztOS1EZDkIPTzVPocsh2zaboGZKkke8pBtENDTQYdDlkNAuoc0rpCRa1hOMwAAIABJREFUUEPk5f+V/XYTmjm/y47NVd7LytKTyDufajNGEvt2qs0IUkzkKs9D7TiAmD6XbfW9wMrmiBz2G1BkI4lDarJzk/YiZKE0IXsUtssN7HOBLKkwcU1wmlYgmxFsQMiIaCKOS3W05yrPsPu2eO/bseA45/6J6n03W8dO/vYan3Cu8vXI2CZR5R8qHWwbosq3lqs8lY/6fDQArEKKMamwsPD4bmRoeulCrnKP9kwfAe11A9FNdgVX+XvISNQBwwsLC7O7daNj6UKu8gakA9UIFLQO2Ze1qC27gqu8DjmcA6w8RxcWFs7s1o+PTyZPnrzee9/POVeA8Af1Nhi/g9JPhyO9+JvfgbjKl3vvj0hBldciL2+zZVujyv3Wc5VnIyPdgsAGjVau24Fju5GhHUtXoIYNVQ4ysEm5HrVdIMvY1lzlYVY8DtEjZnTrRufSRajyEA6/D818gr36LYoWnUDXcJXXE6MFOwGPdevHxys2YQMh/n/nnAuRnl8jfTkE6cUOxVXekgZV3jpoux2Hqzxwzh6KvKhG7/09aOb2WjffcMeSjos6MzNzW3GVJx3IYShl7+t0EVc56uTN3vvrvfcH0a0bm5Qu0g+Hoi9Xe+/Ddp9dzVXeDEz33u8C3Ix4Ax7r1o+PXcLk7m3v/We8OMo/473/o5cEvejmKg/SRajyJFd5HnHd41kUJl2ODHmhPSdwlWcR92wNfNQTaIskX05bOkTml8/niPuO6Oy1dzhJpS9MSkZxBi3LWqAJXB8H2dC8sZmrnr8KgBuahR5OXY5pWt/Ehrs2QDO8MvUVrnrtKnoc1YPqf1VTP62e3Xfenar1VUnUcCNwunPuGNLoBm25ykP+ZNCNnsQ9fIcQnbqrEJahCRn7TXGVD6Wt89COq3y/e/djWWV3MkIQN8KptsPqsOnHFc9dAcDYxrGt5+Zk5pCdKTK9xnWNlN1Rhm/y/Hvav7n2zWvp/V+9qfhHBZmzMykeUpxElWcgjobrzXbkIyDZ4SjkfWDCdmwtV/l/2X1a7K2+6ZzbA+lMsuEraDvZ4NIXL+X+qfdvVX12S+dy+M6H8/RZT2/yPLeFXOXbo3Q2cK8khgvbyXaCKk+eX0ncdtQT+bjCBu+5GKkKER2f5KPuKFTfKr1ze3PmXmemOW3HlI44hh+76DFw0LQkArBdtdMA3Qzn/vDcdtckkc2L3lnEcxufo7C4EO89Fc9VcPDOBzNz2UxchsPhOkKVd6Qbyd/SnR/Q4R4xaAUGwB7IWC9n01zlm8R0nDb6NNbVdhk+ZbuVR777CDhoXhJxPxnVGcpSaPZc8JML2l1T31TfmrWwZM0S/l31bwpGFICHyn9VstfAvaheUo33PhVV3kjszw615WAi3XGYMQdd2RqucpBjUG2/t3HsU18p+eXgIQdT11TX0bnd8hHIyIJNYWZb5UNzlW8v0hk47S8IzXpo4nANhkLcTlDlSa7yw8N54Vrv/TsWDm0EfoEAKKUIIfkc8srnoDBJPUIlHoAAT7chg9ADOQHBY29ATkAJQmUGPty1CNQ2mMjluw55coPs3quIPOYBfb6f3bvZ7rGGyGOehSIW5VaOpahNcpDC5dMWYdyfGCU5wMoaEMaZaJZQYPfdYO8wCEUkStC63wF2fiCogDgrrbdn9iCixoMkkcIb7LcKO1aNIjS97NlVRKTwUoSA3QkNsBtR2DqgylcjjzisVxfZfevtugbv/UgA59xjwBH2znsAO3nvG4JuIN0rBd723p/rnLvMjucjfTrH6vZ9K+driO/6ObRmXogc0cPtXXIQ4DGgfLPt2cut/IOsnC2o3auszE3EtgyI4mJiKlPguC9HA0cSURwoPgPv/mrkIIfdj1ITyYNOFBORzIOs/sM75FqZV6NliH5ohplr5c0hOjaZ9nmV1WU4JyDa51l5Cmjr7CT1Y6mVKWQt5BHznmuRs7QU9Z/Bdr8me3YlmhXtZM9tQdiV+4yA5duor7+CuOUbvPf7O+dG2TGHsk+uAHLMdoxDGSdLkW5/K2E7ViGd+zMKqV5p9fYlq4e/o9D4r62Me1idr7fz6u14f9R2G6w+wx4GAVeRSVxfX29tFLIqgv6ssnYM+yHsY/cst/pI6k+wI3vYPcNeCHWojQusXElEetJ+hGyBYMvy7NzwbqG9QqbCBmuXoA8BkR4mh2Ffh8BBvsaeNdrOraPtfgxFqP372DNqUb8PSx1J3elNzIwJex/MR5k6eyPwYQGyIV9G9McVzrlzgIus/t8Gvm9LH9u9fNJR5Umu8p2B54wpZ6Zds9x+a0FGcjpCjX8FNebOCLzyDgrfr0VKFDaeqMnPz+81evTozX3VT5VMnjyZvn37UlFRwahRoygtLaW6unpboMpbgGe9919yzv0QAdN+iIzeH5GTMwB4GHXOXyJO6Yu99w8G3UBGrwR19H3Q5hG/QEZgIjJUPRHI7WqUKjQaDYpfQYZvERoQsvPz83O6daNj6Qr9mDZt2lpES/s6Sut6CtmWd5CN+Kf3/qvOueeRMQ9h7eu995nGkvU1FCHcFw1O3/De/wPAObcQ2Zt7gdPQADAdDSqg5bexSBfD8kk/ZDt6d+vHxyeTJ09uRs7Pld77m21pNQOYiWx9JfBVc97GA69571OJVrZL2VJUeTNtARqblG2NKk9znA5+q0I5mrsjL/4HRMKGsXZtLTLqq5C3fP3o0aOv70aGphfnHBUVIhBbvHgxzc0KjW4DVHkzMMWJF7oQOVdX2G1qkAN2FMq9DlzSPZCzFiQZXn8CtX9t4tggZISvRzPHnVFWwuvA323m/n2ENq4H6kePHt2vWzc6lq7Qj2nTpi1FkZsxaPOQYjTjOp4Y0gYNvo8gkOHfUDtj530OzfCmEPPmk+LRDNEh564Piqg8m/g9OPwhepY3evToblT5xyjOuVLUTuc65862wy1oefZQRI09yZbxevAJYsvsbOBOhypvPd9tf1zlyfPDvZa7tlzlzwEXE9fLw/t41JAzgAO89yONgCYAk7oljSS5qJuatD4ZUMPQnou6uaWZhuYG6prqaGxs5Gunf43TzjyN/T63H7PLZkMGlK8rZ9eCXVO5yj1Q6L0/zDn3ObT7U+CBfoZI4DGNGLYsQw4ZRN3YBenGcyhF6AEUaluHOnSSxz6sd3ssW8F7/6xz7k7kPOyOjH6rdBS9+rRKR/pxyy23APDjn/y4w2sbGxv5yulf4etf/zqnnnYqLb6FogFFrbSoKfqxHEVe6lGkJAeFVfOJSz8Q9aCcmJHikDN2cGKZ7V1ok5ES9jnAzg8phAHkcSjSld0tdfAKICzpAd260VXi2rIE9kPtdqL3fpkTR3kLItc5DC2vXNX1pdx66QpU+UDgoASq/DUUllrE1qPK3wPmWGM5xDUM8oQfsuOBl/x0FAL9hd0/7PW8Hq1bPY7WZ96ye7TjGy6tKuXSFy/t7LU/0eI6oMZMNToej/eejNwMXIujuaGZvH55ZGZlUlNWw91v3U1dUx3jc8azoX4DHk9FXUUE51SgRMBmeHXaq1z12lUKPr8AzITdh+/OxvUbk6hyB/yvc+5EFMrug3TjM8iwvmPnZQBXmW5MARY45xqJunEk0o1xdt0vgMV2/gTgZyii1BetN96KkMmvO+dyUCRmBlrLa+ed73LHLiytXJp6+NMr2UT8tfEONq9v5tJ/qQ9durGDvpTQj5fef4lLX760VT/6zO/DLkN3SaLKD0I25L9RGLsc6cEwFDmZYbYjF82wjkKh8cDy1QfZmiudNgfpDTxiUR6PBvE/EddXC5HdaESh86MRNgIUBRqD1ofbMMd975nvce/ke7e4Crtl8+Xo4UfzxnlvJA/lIP6HM1FktwfSjZeQs3amc+4O7/1ap30v9gSGee8fBTB92Md7/6MufI3Nkq5AlXvUGW4yVPnuxBzbzUGVZySOd4YqT446IZSeGlL3aC1qp8T3P6B198NQfaSu6bdKbWMtj735GEByUNkhZPlyTSiGDmtPzb1i+QoAhg0bBsCCaxeAA18bq6dufV0rXr+suIwjDzqSXjm9eOvlt3A4vn/69+md25uczBzmvz2f+6rvI6dvDv369GPtK2s595BzeXHti1TmVpLlstKhykP7h4f2QCHPFhTGrEdRlsedc2Vo3bsKGeh0ulFB1AOA69BMPIDyqpG3vtb+n4g89X2IqSNtpOTxElye4+pfXp22jjdH/nT/nwA479zztui3LTlnS877MOeP+3/jwMGa+jWtxzJrMxUq93DNmM5Nx5w35/Bo9aMM3HUg3nvKXynnC3t+gQmrJ9DkmlJR5R4Nnpmo/9YT828D2CkXteMghG35G5HHPAe19SVEfvtKIv1qkKArZXa8Dg36f0J27HTgv5xzMxAg7N8IPwPA+EvH44ZsnW7sqBJ0qyM579zz2ulfOn0cvtPw1EtrEN7lEQuVj0fO1tloQL8dTRYzkCP2RxRF2+53g9lSVHkTNthvLjjNwhPXIfaqi5DXi/f+eOfcCMRgU4RmUk9473/utEXa55D3PNfK8B+0Nn0ICo+WogH3FbSr08FoL+4KBCh6BTVSJhqsv4E88B+hGdrpCKiUZef8GXlc30P7c++ODHgTAukFJG8jMg69UUefRkReBkRvQKTUISMQ0NdrEKI94ASqiExORWhgCKjMJWgQGWXPDAn/1ShKMJK2u1b1R7OBfLR2m2PnBV7pUKYP7P8gZOCyiGHFvvacTCJ6uAIZs1nImBUitGZn7V9FRFg3oXWmBquf4USEe50d72l1M9jev4GItt7TyhmIUypQyLsczZiakZO5DuVdDkCh8ivtngWo/SGi/v+KZmrDUb3PsfuMQMjqgE69E82mTkWsegPQrD2E0Zvs/LAm6u17KYpYBb6AjcjIT06pp1Qe+j2JfOrY8/paWXLRoLGCqCNJfVmNIkQBpxHWXBcS0cXT7bfhqF+NTJQtM/HcZJmCbldbeRbSFn08xOq0DrV7CWqffNpmHSSd6FoiQj4wTgW9S+W7DtkRdUgPg04mdSPsv34OWh45yspXZu8WkNwj7P+zaDenBqunxag956K9vBusHPcgGuR/WV2FHQgvRQP2nghFn4uIm0Y75/6OEOcBRf+BlXlvu2cj0u3BSB+StiMf2YcF9pxUfciw33OtrjrSh1H2e4ndM0QOwxJjOD8gu0FRgoD5yLXyr0LLR6E8ybL2RhOzwF8f+Ng9MeUu6EM+sqdNxHTLwK8RbGzYp8HZvUMOfUCNLyVysC+38uxh1y62su9hdZuN+k09QssXoP4xDkVFPkATy4CIv8R7/3en3cNG2f3uQzp4oj1/VzQ+tVkCCWLLKmtRrOhY1Da/ROx7OyPE+rPOuZEoq6GX1dv3vPfvOefOAM635ZqhaKOso7z3a9o/rQtQ5TZwfxaBOopRhRyKGrQvcIPXHravoPSdg23gPgZ1kBYU0qxB26v9FLgGDcTXodDlA6gTvOi939NQ5XOB+733TzvnNiAU8kGoY65CnMX/RCk/M5E3NtPKVIMaa1l+fv6u3cjQ9DJ58uTWdcy8vDzq6+vx3m8rrvJvISO6O5oZBx7xl9EA2R8td/wBpR1ejHTj2yijIRsZocUo/HksMmjLkBN3NzLs76JB6yRklIfYs/+ODMZIjEEwPz8/s1s3Opau0I9p06aFpbA/olSfImJaVeAuPxQ5K5XIiPdGg9bZyNm/Ci2JjEfMZ/uitfL/sXu8Q0zXW4fs0gNooAhO315IP8Ie3nPy8/P37taPj08mT54c0oDPJm6e8j/Az9GAHKKsj5vTdRwaYE+F1lD5z9Ag34TswWHe+9LUZyXSjo/33r/knHva7v0llPL7OxvbeiISoDrn3GjgAe/9YXaPR9F49GW0/v7Xjt5tc1HlwaMKnmuPTVVaijyAOtB5KF/uHTT4bkSd6h5UKd9IXBO84BAqf86AH4H5KiTHz0CdajJi0HoPeaWFaI09UOkEp6POfn8Seb1fQcjhSvs9l7gTTUM3MrRjSa6J5+bm4pyjtrZ2W6DKgwe/D3EWtwJ5x0H+StvllkaUGjQZtedGNNiDZnHvo/BnHhrs+9o5uyLDnYs67EzEmPUKGuCfRA5k9ejRo3fp1o2OpSv0Y9q0aWFf9P8Qd3crRQ7d1xO3ex5F6g5FTnvYqHwDmhF5FJXKRHoT9lwPtq7Sfh+FnLhCpGdvowjdH4l57i1AZrft+HjFQuC3ee9/Y6DWl9DEcTgCTM+28zrbuvdlL35ynHMf2LXtBm6TWu/9S/Z5BlBpqWZhjALZlbucc/shZyC55noRsjdvdDZow+ajysPg2bomuClUuYHTHkJe6lCUgvNtNCAfhLyKHGQEQd5qjhN1ZREKO4QKGgT80Dl3HgrbNBFJKv4fqoxT7LyjUCfaDbjMOXea/b7RnjGQyKbUgAz8WcgzmomS8wcniF5C2ghNLU3dzFgJSaKGKyttLwYH1/76WgC+c/F30l63YvkKLjr/IqZNmUZ+r3xmL5jNUdVH8Zs7fsOf7/8zAwYMoLGhkerqQD1PC3LqAqnHfsQ91/dHxvQENFPeiIxsFtqm8ZtEAocQxmtAs65hyHAPQ6DEg4nbbUKcuZ1A3CXqGGS0wx7wrbK2Zm3rntLdsm304+EHHmZA0QAaGhqCfvRENuHrujs9kV1YhfRmfxSlKUbO2ev2mH4oMrOrXVuCZmarkFM4ELVzAwq5rkODeA6yMx7p2VtoVteM9HIZ0sMnSdiOqvoqaptCJLpbtoVkZ2RT0KOgo5/fBdZ57/dzzv0ZOXJBOoseJxnwmul8zEyy8nXEZX4J0pFvoCjgxsQ1YdvjQc455ztJRfhIUOU2K7/Ve3+Jfb8UKfdGZPxGoZnPK8AZiDjleAtpB8+3v5XnAIT+Ph4RtDjUiX6HwuRriXzD1aiTPYHWNAOrzigU4rwBGfu97RkhFD4R5ZD/HW3LNxAN3K+gWfsZxBSTVlmwbgF73r1nJ1XyKZQAFwu7PVfD1S8IgHN1fQdAnA3IPH4Gao6p4aobr+KqpVdpDrwPPPfgc7z6l1d57733whXNCDX8Agpx749myU1IX0pQBOePSE9AnSUbebQ1aAY1ibjX9wHIwNYgL7oYGeUZqO2/gJZ3hiJdvww42nt/jnPuWhRabSMHjz+4G1WeKh+xfnzhy1/g2XHPctttt/Hee+9RUlKSjTJUTkTrmEVowL0IhbEPReuj7yAMxN32FI/wKTmo/wfjXYPavBQZ0mB8D7Vz37Jzj7Q3etquv9x4KuagtelWYBrAZS9d1o0q38aSBlW+ESHK/4IGyjfSXZeQKqDIOfe1gCwH9nbO3b65yHLn3AWII2IA0GwT0S8BvZ1zs5ETuQrp69tAlnNuMdL6AGoMS7sdbhPa2cAdqP6SaQ2tocgUVHk98BXn3A3e+zDY90PryS1oL+SBqGP1Ag53zk1HoKIe9rkn6hRT0SC+FM2AsOvOQJ3hDeBzTnG4fBTm+jmaUdUjw9sHgZd+gLzxgIzfB61Z7YO87UYUNstC61sDkdd9D1qzaoOoH5g/EPes+vddd93VSdXt2HLdWdeBg9KW0lZz1yOzBx5Pna/j7pvubnfNJZdcQn19Pbm5uRTmFrJiwQpyynIoWldE6YZSCt4sIK82j43zNnL2cWczcteRSVR5Jmr3vZHxbEb7L1+BgGgj0EC+CHmzAbzj0Mw4A+2lvNrSfCpR5CcDLZc8jGZUg1CkZoR9ryOmm/UFvuicm2r3bkcMVPJACS7Hfap1AzZfP2677TYAfvzjH3Pbbbe1Zja0VLbQsKCBIQxh7T1radzYyBdbvsiUsilMeGIC+761L8XFxfzud7/jscce8ygKUoX0IgDOalFbzkWO/AAieyNEwFHgiChEduoEu1egGw7t3Avp0iHIHq1E+vKm/TbRzjsLzeba7EY0/gfjcUWfDN1Itsu2uE+645t7rLPjg3sNTi1CCXChRU9X03Z733TyPmrL3znnBhABkpsrDk0uD0Jr41Vosvg82onuFOToBWDuOqSzP0bLcnkIe3EhcIBz7lnv/by0D+oEnLaE9jH4tKjyBHK8l/f+Cptx9/LejzHkeGAsehtVzmnErfTWo5zco9HAW4u8kgXIYzoAdZ5dbY37SRQOX4dmTn1t9v048Fnv/XCbiZ+BZmh/RJ1pIRrM3yeGyw+2Z76KPPEbUacfjByPXmign2uvOsrKHPjL9yOujQdkawaKVji79wo7P8veORU5PpyYmuKISM9wTg1q5N5ohhi4hwPyczFxO9NUruGFdv9y2iLec5DTkoEUp8J+H4CctTy7tyc6bvWJZ+1DROMHSaKGA3o6154XUOKlVq51iTKstXeyZLLWZ2UTZzs90Sy4As2M86xem4jhyxpiaDPs5PSA3f8UNIsqsvJPRk5AC5G4ZR+7/3zkDVcQtwKdi4z0AKunYUQ8RH2iLr2Vo4C4kY4nLvkMIPI919uzCmjLY49dt6fVQTMyQCE7IaCHCxB6ewUySnvY70201aGAJofIP/0Zq6cMYjvOpz1yGOSw7Jp4x4D8rrR2yUAGqhz1j7V0vGlPkKV23r5W9kbSI4fXISeqP3GpI8vqJXCXb0zUeaO933J7j0PtnHIr60rUpwfaPcqsfjegPh9Ai2vt7237fpjdt8LqsM5+72HPD8x7lcgJPBPZj8DBHTLasfI3EidNqRzzo5AeFKA2Kaa9fQmZKeH+ZVYHqZkGS1Bb5FpZG5BuZNHWHiVlHyJXer3VTcgISS1fsBnB/oRzhlodJ6UJtWfY8KUW9YtkP5xH1MF+9nvAMAy330JUdXd7l4BPWGj33JcY6c1AOnAfsg2rgfO898stXF6OxqVBfDTI8kMRcv3QdJznzrnd7Pr9E8f+bMeeShx7G7jOe/9MuudA5wN3Ldox5f50v6cZuIcgA7Ef4oAOA/ezyAhdgozAGSh9648o3PSW9/48I8DYCSnOXsi4/hoZ1ZsRZepTzrnvoMa+FjXW2YYcfxwh/kYkBu7Vdo+Q1vZrZOguRkj3nyMlG4UMXCrfsMvPz8/oRoaml8mTY3ZTcj1zc1HDzc3NzJs3j0GDBlFQUEBjYyNZWbJnpaWlNDY2UlxcHLjKN3jvC5xzN6Mw6DdRtGRfZBAORCl9JyOP93VkrL6MvN6ZyON+ErjQe/97Q35+AXHnn4IiRPNR9OXXCPC0GIXZ9kOGfYP9HZCfn++6daNj6Qr9KC8vb0COw+NoEDof2ZHlKCNmJTL64xAe5g/IbtwCnOS9f87AQ6NRn5+EjPTByJE/DtmkyWjQGIkGhRKUInmI/bYfGkBClLI0Pz9/aLd+fHxiXOUeONd7/7DTnhVhM5RCFOH9OnJkPypk+fNoPHkF+Jv3/l+J3zd34L4LEUPd0tG7dRYqn+O9f8BSs1Yhr2Q+8tJSvSlsfedBEhzQTpSnxwG/8N7/zb7f5L1vNsTpvcTwxQZgvc2qZyBvKXgczURU3lFoNvU55J1/BoUf8okzlnor4zto0B6COthiNDsrQIY8eMJLUQMHMoaw527v0aNH9+xGhqYX5xwjR45k0aJFjBw5kqqqKlatWrVZSNrGxkZOPvlkvvnNb7ajRgVYsmQJJ598MpMmTQro5J7208vICSxF3nAthvx0zuUjDz0PGdc81JE+S9whqwXob9kHuxBZtqajSNAI5Cj2RKkji5ADcCvSn2IsDN+NGu5cukI/ysvLM4gRmRA5yUCGeRUCJHnn3GrUbsuJWw0HBHAl2rGwyiYsQ1FYvQeydy8QZ65hdjkE5Ywfjgb6XLtPyEhp7taPj1ecuMoHEglVaoB6r93i/gw8bQCw6VuILH/FOVefcs7XvfeznXP/gyI0xwC/dc7t770fy5bJJlOtOxu497P8Z4jhs9b0mw5Q5bcjov4/IYVfZs84z4l6chwCf4XwcUByg8KR37TF/LCuFChPBwBXOecuRobzeO/9K865ecAlhjYfiFKCQCGQa4kbUcxCs7RGtPbkiNvllVk5DkUe1SiD8I8hhW+4qaWJtTWd4fU+XZKZmcnChQsBmD9ffB3OOa66TvS/5190fivKOrm394rlK/jKcV+hoaGBeYvnUbKhhDP/70zu/NWdvPzPlxk8cDDla8uT7HQtQLbpRkB9T0CDcQHwdeswA1F7ZgHvodn0PDt/LpFZ61fIgAfShDyUrngt0tvQcSoQ+UoJWvv8jd3nWkTikZOsj3nl82hsbuSTIh3tt/5hxaXYm4zMjHb6gYPLrr0MgHO+cw7pZOXylXztxK/R2NjIwqULWVOzhm9e+E1uvvpmXvjHCwwcMDBJeQrq1xcj3EOAw/0dOWb7OFGe9kV9/p8oLO6JdMlDgFLnXB5y9DORTuQBKyz/9ilkJ4JtykATg/EoQtiEcnBPI9Jq/l8oYGlVKetr2yUidMtHKD2ze7JLwS7JQ/1I2Rc9RZK/bQmy/ALv/VvpTjRH4F3gXefcvxFeaksH7v2Jk9a00tnAHbiYO+Ikb3fce7/OQtb/h8KMA9FMei8UmjqAuJ6VjQbtr6XcJrUCk9YldJp1TruODSJSWrqUc8Pg7JHn7dHgHN65Eq3d3IXS1N5EYbWvoZBrO3awblR5iiRXcYwF2Fd7xr4sPR3b1IG+zkGrUwNgQ8UG7hh7B3dMukPwnhooaCxIpTwN6RRhXTldzlVoqyy0LhlkJzTAzks5LzA49bH/YY0+7IAXzn0aIcqfRUb9SmQQNqC111Y5/qHju1HlSUmjH1TDza/eDMDN/ub0181B7tcA2LBuAzeOuZEb370RJkKvpl4UtRQlKU+zUJsF3HoT7fXDJf57YiZL2Is8/HaBfQ90p72Acos6jrL7Bma6OrQGXk9c+z/S7rUerXO3yq9e/1U3qnwbSwdc5S8TkeU9gAbn3LtE/EqrOOd2RdG53vb9fAQqm7U5z3fODQP6e++n2qH96YAeuYPrHWL2LCRGg9JKZwN3Llqvgbbc39AeVZ6UW9Da41xFqFypMf2nAAAgAElEQVQxWlPKQOsE9yFwxc7Ajd77AM7YA613n2Qv0USkW10D3GOJ9P9GjfE+apjbvfe/dM49Q0ShF6Jwapj9n4gM7TQUYg0bSRyBEH2L0HrHO8BFzrmxyKBnlZWVtb7YwPyBuGdkA8aNG9dJ1X3ypaMdvm699VaWPruUoqIiVvgVqslmoYYzMjOopprdB+7Oz372MwBuuvEmAC7/+eU45/De4051XO+vJ7Mlk1tvuJUx3xnDKWecwuxdZ5OXn8ctY26hT26f5GMbkK5Wo45wIKItbEDRlb9573/knHsZ6cCxyFmsQTm2x9nx1+w+DyEwZCXRAT0FGeYGRMBxBtL5IoTzWExcVnkYIKkbAEvHLYVsePzxx7ewtjuWMWPGtPn/Yc/p6FzXwcYyQa6+Wilb11zTUXeXJLEyl5x2CQ5HiS+hZ++e1FTV0DOrJ/X19TTTzON3bUb9JPZsuunimzjxyyfywfAPKB5QzM1j2gz4dahNQybBBDTw9scAb977AyyCdiXCPNyC2jaA7OYj3Eyt/eUiO/EScQAuRG0/2p5ZimxYDRHk+WMU9RsCuKR+3HvhvVDw0erGjiSpujtmzJi0x1I/J4/179nGjwY5UN8H/mjI8v+gNe0ctDQ2KOX8XdGSaqZzbhrtgXubkmzgNufcYOTQrSbuxdGZ3OacuwY5Fu8Ax3jvOw3dfSSo8k2JgcUaEY9rNVoHb0ThgNtQiH0/9KJf8N6XWBh8Lgp3eQQq2gUZ7REoNHY7CnmuAL6LZkePI9BZCVqn+jZCqE9Ag/V8ZJS/hHjJP4siAxVEvuGRiFYzHxnueaiz7kHk8S4nPd8wtOUFL2brUKFDrBwNRKR6Or7ygCjfg/R85ak8yIPsOVnIscpE64NhdhuiFZX2O7RFnXcmYUvUSitHQIEupy33cECdZ6K23snqNGAMZlo5B9q1S60O9rL/7yOD2xNlBoRUrlC3861eliAQW1D2Pbz3S5xzv8R2CEOGdxZam3oGGeVZiFnvVKRr61Dn7oXapRK1x2DirG4DmtENse+Brz7oSqok+cqLaasrSa7yMNB0pisZqI+EKFSqrgS0eeArb7ayJrnKwxpuKo/6CCJnPUR9G4LaLcPKMgW1fdj0I500EvnGsXNDJkYjETW+AOmzt3cIddFCZDXLQ31jEUqjGYsc8g2ovRqIaPQRdv7dCNyYa8+ah5ZcJiBwY53VzTg0cE9Aehq4tC9Fg/+RtOcqvwJFaDYSbcf2ylU+m9iO2xNX+Vp7d9CYsDVc5ZNJjyjfYbnKNxtV3plYSLsS8T1fh2Y/p1nBs1AHugrNrrOBAd77U23g3oCAQv+DGus4hAo9AXnOFd77IU7E/v9CYYb/JuZj3oAG8ttR5ytA6w+XoIG3P6q8G+w5K5BCDEWKOLebb7hjSaKGw2wathmq/ByUIxnSvY5C7fd3ZCCPRY7YaWjgGIYGpCtQB1qGjG81cKn3/lYnZsCJSPfeRoPOF4mdKjgKZ6IOmUdM38rJz8+nWzc6lq7Qj/Ly8jBQOGT4f4KWusJGIWuJA+VPUVueiAafbxG5yn+E2rgzrvKBaPAqR05xId1c5dutGFf5eYYo/xHwX977rzjn/soOzFWeRJUvQ17DerQOvNdm1FtAlT8JNFnl7YFyqkNO5u+tYh5BnnsGmuGAvKtHkce2M+oUz6EOOMPOy7EKm4HQ5aWIQnUoSgfKQx1rJ+R9hd2q8lEHPxsh1I9ATG0hnzDkz3bzDXcizjn23HNP5s6dS58+fSguLmbq1KnbAlVejXRgKGqXdWiGOcyOr0Te81DUxs3IsE7E0vqIec91xCWYY5GhfY2YO9oDOXe72F/weOuQjj2MQqh/Gj16dFa3bnQsXaEf5eXlJai91yMD+yhaCrkFTTw+QDbjFfv/FgItBnKVDUTbEUbZZ4mRoX5EHEQBsicXIvvi6eYq327Fias8IMqnAjdbCHyrucptdp46ftZtD1zlSVR5YBcKs43N5SqfiDpIlnMuULgtRgpeg8AgYcr/T7R2XWAo0JCyNRF5wIegDtGIpZgh5PAc1Lk8mtGPQ6k730JG+BLkMWP3utI+j7NyvIo88iTf8Fzgt3ZeK99wdUM1E1ZM6KTKPl2SmZXJnDlzAKioqGDq1Kng4HtXfg+AM88/M+11q1es5runfpemxibmLp7LospFfPW8rzLuunG8+vSr6VDldWh5pQC1876o3Zrs8xGoQ/wAte9RyDsOW0t64ApL16gGvuCcW4hCp695749zzt2N8rmbkScO0peQc5mLwm7/RMsy7XiL31n2DnVN7TAvn1rpUD+ukH6ccf4ZredmuAwyMzJxONatWse5J59LU0MTC5YsoHRjKWedfxa3XXMbrzz9SjpUeW8ij/18+z8T2Yp9kX0oRtG445CdeA/hX4qIOw2OQW0cdpLKsPPmodn899Dg/hpxe9+32Ayu8rlr51Ja1dHeFN3yUUjfvL4cMPiAjn7+SLnKvfcHJ09KhMqDfGxc5c10vpa5Ka7yg1BoaQaa8d6IDHA9cd/gycggfs0+9yCuswRJ7viUeiwcd8hIh1Y7ycqeT1yzCxI84tXo/R9DnfspIt/wYhQBaAMsWLZhGcc8eEwnVfIpkYDLa0ocC9BFD/f85x4A7sm+J/31c2jl16qqqOLu6+7m7sl3d4Yqz0F6EZ6YhwzxHCITXJCN9r2eqBvpOmY41mDLOccT87+rkV6uIO4XXQNkeO+fdM4diQaBNnLWk2d1o8ph0/rxtulHTif6EVDl6zdwy7W3cMuEWzpClfchrnM3oz4PmiQEbEBSgu0IWApn14dIX2Dcyk+57ot2bb09J7AKbhZX+e3v3t6NKt/G8mniKu9sjXssmrr3JYLSmpDCZqcwp9WhcOUh3vu1LkF5ar9vRKGqu5CB/CFwvTGrFSPPN6w/HmPgtBUIRPIq8oTfQQ0R+MOvQI7AIDTLOhN13n+hMPgs5HUvQ57yvxLXHmOV+VsUDs2ye8/13p9oCMSrkCMRQBor0dpp8LrKUGh2nX0vt8+gxgF56sXEFKOedmw3YtQh7AldRQSM5NnnkP5WhwxJo/2tQ+uw/WhrHgNgp9LuUWnvt6SDsvVGYAxPBI0sIIZvWoh0ovOQYgVq1pCelZSQfdCS+B7y5RuQSR6EjOZae2YhavedEvcpSRwfYMdWW9kKiCCU8QgNHkBZ16J6Ph9FiS5B7XoP8G8DftQAz3rvv+qcuw4BGV9Fer6blTXT3rsU1fvJKC3kx8StZoNDsN7qMenoTiOC/Zy9R0+0hl6A9GY5aq9+Vh+lVgeVds/+KETb0+4dNkrxROrbAOobgfQnoJv7WjlCWdfZM1uIurjW7l2BZp2BZCm8c0gH7WN1u4wY7gsD10Irf2i7HCJAM5U4OkmJ24TaOABPwz2r7Z672r0+IFIeh+sy0eCZZXXVz65diiImv0IRlyVovfoO4iYjISXweqSPfZFOFqJ+9TYacKci23E0aoenkKENOwxeipb3Qn/tRVvbcbWVP7grK6yOA8BwPbE9yu2+oX+OILaRIzqtIBuUtB1B7wLNrEf6sIc9sw45EQE8VoP6UBGa3QVgGNYeA5Ee1Vnd9ESDSGr5At3t4MQ9wrJDPdLxBmSLyu3YUOL4UY7sZzYRnLrS6jrDrs1M3DOA83az6zdYGUcRqXvL7B67WNlrUJtOIz04rZWtzDm30XvfyzkXlteKkf2vwdLBLGvleWBsuhxum3GX23OSXOWPIZ1ZizJbAld5NYow/wyBpVO5yj3wJd8BVzne+7R/qIE/oNVPxltFeCzPPHHuRkRWcp19vxQYY59HIBh+Awox3UYcSGYiINktCDz2JvCi/f4y6jBLkdHItvs9aZUzB+MJt+OPAyX2uRrNujMRuK4edbA3kRPwBgqVrLV73YoYkN5AHXwi8nzqU97zBTsvrG+stfs/jDxukKGrtDJMR0b/cmREpto5uyFE9IF2j6ft/acjZGE4Z6rd/xfAC3b8LavHZaiTHpEo3yT7n2FlOA45MJcnznkXKdJEq//3EmX/sbV5k7VpQOQ2J5/FJnQjcb/wDgsRkQXWBguRF3wWWh8MKN46ZKSmW71MRMY0oFOnE7mTF6MBbDlS9iVEzuxXrTxfQajOD+y3PHvOBGufKnvP/xDR81OJjlzAdPzHfquy+p9N5NJfYO802cq6AOlUYOCrR+1/uZU17Gq2ADlRl9u1X020UR97z3Kk/ycn69M+f9Xq4adW3jeRTqTToUmYTtjxJUiHJtj9K4DD7bfLaasvX7Z3WGL/QyrUeKIO3Yv6xTrUl+qJRjr8tSQ+Bz19BYEOZyPwTnjm34Fp9vm/iVwMUxLlKEUOWchaqLP2eRPp1qtW341Wj+vtOSV2fYi6lSL9qET9u8meNdPecSExM2EpcQKz1u67wp7TZN9PQn09OGaz7d4rrax1dp8aot28PMXGXEDs7/fT3r782+oi9Iev0lY3kvblAaSzlXb++aTYoxQbV4XofptQn78nTfkOt7+JwFOpeoN26pti96gi6k0lQv9PQwDCkVbX9VYn7yWeczma6L2eOHYvcs6C/rxtZXwHDcRY+09AzjloIH/V3v0lYJgd/zNy6t62Mp0WbKiVcyqaOZ+Pdp98AdmbGzoZMw+16zM6+L21jRLH/gycmnLsbeCLHT3He/+p5Cp/E4HiVhNnJnOsLN1c5VsgXYwq31Ku8n8ig3s6m89V/gViyko/ZHS+g7YK7eYq30LpIlQ5aMB8HBnNH6HBbTFqs14Ip3AxW8dV/h8UxVmNBoNGFLE7h26u8u1SjKu8HsB7n++cuxD15QBQq0FtusNyldcTc/tqab/+80niKg9huLBDUAsy8J5urvItkoyMDPLy8qitVSSvZ8+eNDY2bi9c5T2RAe2Iq3wjMR/2JhR+7IEG6x5E3EQgRujmKt9C6Qr9sIE7cJU/hNqpD3F3rtVeoMSt5SofjvQlIJAdmqln0c1Vvl2K0xa8eyKnDpT6d6//FHGVB1rAVtBGB6jyTwJXeQAVhTLcSaRD7ZSrfEP9Bl5c+GInVfbpksyszFajnJmdSU1NDS7D8Y2ffgOAk751Et77Vr7yIGtXrmXMN8bQ3NjMrAWzmLJqCiecfQKP3PII7z3/HkMHDWVd+bqu4Crvg9p8POIqn4YGgUCU8Xs77042g6v8mXnPUN2YioXcPOko8rWtxW2COa3TazdhX5L6kZWd1aof51x2DgAnn3Ny2uvKVpbxi6/9gqbGJmYvnM2MNTM46Zsn8eDNDzLhhQkMHjg4iSoPmSaBq7w324ar/HWUvbDczmlAdmmzuMrnlM2hpLKEZt9Mc0tz6/8W3/KRc8Z/WqV/z/4cs0s78HAOMSUsVXZIrvLNRpUH8Z8MrvJwrA/qfMuRgZ/PJrjKS6tKOeOvZ/Cpl4AaTpDyNTUI4+JbPA9PehiAh3s9nP76Oci1GgDVVdU8fOvDPDz7Ya2Y1UL/pv6pqPIACHRsW67y8HuO3eds5AAcigbrcXTCVX7Rsxd1o8ohrX40NuiLb/E8OPFBAB7MfzD99Un92FDN/b+5n/tn3t+KKm9paUmiygNoL4ct5yoP+hSAYHnE/G5HW67yIXbfQAPdgtYsz0WRvkxkOxpQOD3wlgPw2/d+240q38Zy9PCjUwfuHCIAFoQsx3KwR6CJZTJEfSBahg1c5WNRG69iM8R1IVf55qLKAyqxI1T5Ru99L/s8EIUUb/IRNb6QmFv5CpGrfKz3/gm77mWgwbflKj/aHvFn2nKV74fAF0fZcwJX+VALg6yjLVf5vnTMVV5PXPM6HTXoYGQM+qLQ+Vwrx95oANgJzfYOoj2qPAutiUHccH69vX9PBFbJRMCkUntWI5r956B19tDYexNR2s0IWDPMylRKRJiGqEVgguuDwDQjrawBOZqFQssbiHmvWUgxVyE0ag8rTw0WaiTSdy638vYkOlFBkqjhKfZ9H3unZSiMOBpFP0bY8cVWD2HmWm9/YTCtQG2zr5VzptX7gWhm3YA6WSpX+XTkLOahjnCcHR+P8nX/jHQr0+rzOnvnaxGIZghqz0AU5Ihc5RlEoo7AlhSINz6w+h5InN3n2rVD7PNUYtrSUGJ2wgqkJ3vYtWGji4AenovCtT1RqLennbvI6nYocigyiejhYtTOYQjNsvMH2jV97fvuRB1KSgEyIiEyEZC+c4icDg32V2//A1o5O839ggRUeAA1hj64t30PGQyB7c7Z732JhDqBbjbQtWag9gr1W211jm/LVX4V6uv1SE9mI13o6b3v55xbj9pmGtLVM1GoNaDKA1f5YtTHjiUu0X0LRf0qiKj6ALwMCP4c+xz6dRJVnppxsAfSmWWJZ2Sh8G9AiedaOUbY77NQ+w5DdmQtshO9iFkpy9A6bADaBUdlMdKxNcge9Lfvi4gZECHjoLeVNWS7hLItJTIMhrbNtufX2rNC36iy5xYm2g+7PvSBkEUT9rQIS50riMsXZYl3CjTSjfbMJ+y8gCz/ufd+stNub0cgUOZCWzr7EbI1+1r5V1m9r/KWDrYJZPkuiCq1DVe5936x/d7RGveRyCYHrvLL062ht5FOEHLpkMN14XNniLc096pGDX8zQnWvs5e6D61Rv4IUbBYw3K6Zh9auZyJDNQYhJGfYS55jlToDrWPuYuf+Ein0B8hQh07/F8S8Fp5/sD1/oTXQQuADe/ZIe/4KBGYbbcffsOdVo/BHMOqpyNB3gXf9R4MKfRZ1pIA6f9Kelw6hOAkhSOvs/DLk8LQrl33/A0p1CN+DQ1JBXOevBg72EXU+m02ghhP3e9LaIYkiPgShyX9n7zAbdbKrrW3qiIjfW6xdK5ChfgmtH5UiY1dmf4usTp8jDiJNaLY8i7gWvs6Ov0rMUlhndV1OzFTIsPZ/w+r6NTQgHGjtucTK+GOEOp1n5Qno2ZusXT+wdrAMdTam6RuHYwhi+z4ZKE98T+rLOgzVSnp9OQdlZdxqz20Ankxz/nH2rgOQvvzazk/NUjgcre9OSqcvifOuISLM60lvO5J/K6wN70nRvSqrpyVE9Hot0XY8SEwtfBjZjnDNSmSgD7RrKu1vFtKr1agfNdu5VVbeWqKT9ijSxfX27EVIv/6CDOp004WDUV9baPdLtR3l1v5J2zHDzp1IB7bD6nstEeE/GTF8pepC9SZ0Ya6965mmC8vsnZPZBjWJ+4YslNSMlQtTypMs63EoxbbR2iu0WRUxFfdee8fDrY0Covx9a89VSBdq0NLGuYkyzUL97yzSZBzY85+y5/6K6OTeiIDMIB2cRbSbO9nxoPOB6/0INGiW2LGpyCaPRSDq163sF3Uyxu1m73yfPfNBtLz2NrIPwYZ+FunS+ygqPcqOXwaMt8/7I33p0dHzPo1c5Y+gtcsy5MHnWkXNpZurfIukC1HlzWht8nlkhMPGF0OQzpyC2nwR8vhzUAeZjQBLV9m5pyEP/E3gt15ZCouRIb4W6cEhxGWWBvvtbqQrzyGOAOjmKt+kdDFXeRayAbujGWnI43UoBfXHyGBvQGmC3nuf55ybggbaQch2zEV6tAC19wNoFt0XOY15aDDrjwz9bsjI7k2cXWYDy/Lz84d368fHJ6Z/R3vv33LOXY+iBJeiCcQUtER6O8qXPtEQ5PskZtdjkU4cS8z5H+C9b059ls2m56Bo8Ad2/4ne+wucc6cDZ3lxR+yEHPhm59yJKLf8f53oWd9ETv8Y4Lve+3c7erfNRZUnJYQLNylu++QqHxaKRwwRXW5l6OYq3wJJApu8963GeRugyjei2caDyIufidrqIeBK7/10J/L+BchJ7I/afCQCKPYi0mGGHPti051CFNUYgbzuMGsYjByACxPF+haaJfwb+Obo0aMzu3WjY+kK/SgvL19gh/KIW7V6FK2ZhaJuoFn0UmRHvoIYq7KQsz6MaDt6I70Zhox2BpoEBFxMcAYyiMtQv0AzszpiyLo76+BjFudccyKk/QCarU9CUbxBaGL3PAI2diT/8t43AGtsCbYIWOXac5XnIB6RwH8+G2XAgManAHTuCzzotEtYq3jvW5xz56LZ/l2dDdqw+ajypGRYwT7JXOVhfa2SGLLdJFf5+tr1PDLjkU6qbPsV51wrCjh8Tv4HNutY8h5Ddh3CmhVraGlsYeDwgaxauoqCogLOuewcHI5Tzjsl7TPLSsu49MxLaWps4oNFHzB33VxOPedU/vDrP/D6M68zZOCQVK7yBjTbmYV05zNo8JyD9s5dhNr0OORRf4nI6hWczHqvdI0yZJAPR3nguSgs1gdFZbKJhB5vID6AeWhgWIqY/76BgGuZyTp+cNqDVNVX8UmVrUGYp5OBxQMpX1lOS3ML/Yf0p2x5GX2L+nL6j04H4Nizj0173bpV67jp3Jtobmpm+vzpvLPiHT7/tc/z5O1PMuPfMxgycEgSVR62UA3Up32IuI+ZyAb8AA3IZ6A00ivQgDsHOWiZyCkch5aT9rbrPFoCeQkN7N8h2qt6ZDsupb3tmIvsVNjjgdeWvMbMNelgBFE2hdL/JErSjqT7nk4yXEaHf53paFHPIo7dtY1OpYaTN3rvD3XOvYVytac65wbR+Ti4uVzlu6FoXpCOuMqvQ0tj4+yaJGf6KKRvQ9iEfCSocvfJ4ypP3rOUSGvYKVf56urVfP+573dUH58eCajhxE6xK5cIO7K+bH0raviB/AfSX5/gKt9YuZHxvx7P+KnjW1eC+zX2S0WVFyDdCRSPQff+izgTCrKRthkPm5OlsBbpaqC4BTmcfe254b4Z9teLuJ9wq/zy1V92o8ohrX6sKdGXijUV/G3a3wD4W8Hf0l8/B63gDoCajTU8cccTPDH3iY5Q5UWo/QO4KYDibiBmIKTajiRlLXbN5+1zkqu8OnHOF4mo9L72f6idn2o7FqHIYqs8NvOxblT5Npajhx+dOnDjnDvCe/82WpJ9fRO3qEKRuBO992FAPckiRR3yhqc875eIJnUIcISlPt8A7GHprCPs+IUonD7UORccvVEoylzsnDvVJ0hZ2kkni+1jUXgpCTxqxGgwU84NKMv+9r2V8tS+b0TUlv+D1qwbwu8I+foqAk8sIILTViBPNgBkxth9A33kRmRws+y32SjMMBbN5iciRPm1tKUmfdiedTACDqxE692LgecTIIwaIt3nChRiqUOduR6F3DwKvwcqv0n2V4ZCqmX27IUI8NFoZQxApjK75zoiDeIkBFyotXMCqKWJiAhfYvdtseMB2bsAKd/yxHNbUsoWmL8moZlBAKGFewTwWb2d12z3nGzlrrXzkhSWqX+BW7uOmBO93u5RZtcut7pvsN9COWrsfxVyqmYTU3heQhGQUA/zrd5+ZM94GEVUXrN7/AOBxx5FyzUQKWYvRboTENiBwrQWrVE1WvkesPvdau0cEKuhvKXEPZ9Dnay0+g0AvoCMDUCmOnveJGubWjs+ye61JvF5sZUrAJJaiNkRHunH+9ZeFXZdoNdstGdOQUtOYT046NMCop4tQLrZiIBcQV/m2fnTkb4k7UCDHVtJpBGts7ZJBS8m7UjQjwXEjIkGu3am1UU16jMtiWuDPaq3MpQS9b+MCE5rsDK9a+93p9Xjb1HfDmXNQmuKG+3ZT9h9lxJtRxPCyayy8r6GbMe8RJumsx3Jtg/9q97eK9iOZmvrzmzHBmuP1XRuO2rtue/b//lIN5qIE6YGpAszEm0S6i/YjllWjqVWvkkdlHFdol2CTgX0d9CBRnuXyYly1Nr7v29tHeppLupDQTc22PvXJ547Cen4eqv/QJZViXRlBZGqucL+v4d092+0Baftb58HAQvscxGyrWuI4LQXaQt2G9YJOG2+3TsHZa58C0V0drO2Ow5F8eYhYNpYq4/9UcTnYhSV/o/dq3+H43MnA/dmo8rp5ipPRY0HjukqIs/0zUBpEtWJjEwW6izzScMzbZ+fSXxORX7OSdN2W8pVvtxH1HiSqzxpYFoRx2xCN2iLPH0Kdd7voxnLdGvfW9Cs5Dnijku1qCNOt7p7B+lFcIxm2HOCozgTdbJSq49qe9arpOcqD6k8M+xZ6+2aCfZ5Lupgvax9Arr4ZSJX+VQr3xy7V9CrVQj0sgDpdjAqdahvXIGMyYNWvzMQqvty2nOVT0H6t7Vc5TMS528NV3kLbZHD6bjKHW25xJP6kPrXKXoY9bFlduxsu2Y90ocwaK+2ss60+g7pRc9aHb9q9RecxrXWdsuItLar7f2X2Dmv22/L6ZirfDdr2/VWbwvQYNWEdPFgImJ6tbXLDKJjUof6+tZwlW8gZqW8zKa5yp9GelpF1I2brR0npdiOZJZBM0Jcd1TGJFf58kQZr6EtV/kSNs1VHlDslYnnPE6KfcP4yhP2pczuF+hMp6PobuAgP5A4eKdDlrdmU7D1yPIzgb938vtxob5S6nv/xPcsK8PeHd3Hf1SoctfNVf6plC7mKl/hvR/unPsTyrc/DzkDByK9OxaBT05EM693aM9V/jPEZPRlhECegnTtXBRKO5hI9NIb6cMPEap8AOpQS6z43Vzlm5CkfmRkZNDSolWIbcBVXotY7ZYQZ9RlCBeThXTkKpR9cD8aeH9K5CpfgMBofZAj0d/+7qc9V3m5/W9Am2BciHaAOsa+fwPZwLX5+fkDuvXj4xOzG3PR3gQBWZ7jvb/U1rn/473/mXPuFOB7fuuR5X3QQJyLHKpHvfdvJn4/jgQPuh1rXW9PHPsX8Cfv/ZMdvduHQZV70tDD+W6u8k+dZGRktA7W4b9zbltxlQe8xbsoBBW4yusx5KdzLpe2hBepXOWBvGZvlEXQA+nZb1Bf6GXXh+P5aLkmB+mq7RItZHE3arhzyczMbB2sw/+MjIyPGlXuUT+uRVkGt6N2G46R/3iBEsPSQlhGgshOVYU2sWkwp384cvT6EAleAtnHQLsmm+jEDUOh9YuJDGv13frx8YoTn3ieb4ssfyhxSgBZTCaOL+kkicyRo48AACAASURBVCyvBKYZQVhSPue9r3BiXzsaYSaecM5d6r1/KPWGmyr6pk74MKhyB59OrvK1NWu5a8JdnVTZp0tGfXYUJTNLyMjIIDMnk4baBgoGF3DC904A4PAzD097XcXqCv7w3T/Q3NTM+3Pf58VFL/LZr36WF8a9wKxXZzF88HDWl69Poso90M90YyfacpX3Bn7qtIH9QDTwZpGeqzwThTcDV3nYAez3yCF4lqh76bjKj0fLJLeShqv89ndvp6Ku4kPV5Y4oux+xO0unL8U5R2ZOJo11jRQM2Tr9WPDGAoYOGprKVQ7/n73zjrOrqvb4d01NMmmkkJAMYQIJhBZCEUERUOk+aXZ4KvoQUVBQsfAQRAQRVB6iIr0JAgoWRJp06SSkAyEhCUlIb5PMJJm63x+/teece+feO5NkkkmZ9fnMZ+4995x9dvnttdde+7fXFs/hTDRoNyHvy8HoQJm4S6U72r1yKJmxyiuB6ZbEKo/hT2Os8sVm9jpypy5EM+61CHv/Qi70eKTjHmit9DKEH2XusfOZsLBlUtUlm0DGDB7DtcdlcMiWtfFIZH23sMXbuA/kaTkuhDAv140hhBjg6RnfEvY5Mo2FguJbFPdBM/u80iGs8ihhG49VvnTNUn763E/zVMd2JDlYw7H2F05fyMKhCu37xHN5DmR5C/lGdoR1a9bx+A2P8/jsx7Vitg7qG+tzxSovJYkjXihWeTHyxkTpn3V/xFAMKbpDVjqRcVyM1lifRwo7xhv4oj9Tgwb+Frn2lWu7WOWQ4CPSJ6GldRZMW8CCnbQDYUPwkYNVvhZ5SuI2sEiGTEuaQR6JjvF6OQkm0rHK4+6B7FjlcSdBjFX+WTRw1yOd8S7y7OU+QaVLNqcsRbE+2sUs99nyrmTGKj8YGeltipntCTSEEGJsgf1Yv1jlZYiBPiP4fvC89xZY476cJFZ5lCZ872r2GnfoilW+vrHK90Jrpjv49w2NVV7i5YrSj/WPVb4KES/SscpjZLnsWOV9/dlCRl9c3IyxysejgTfGKt+NJKzpLiSnz60jUaagOp2N2rvIn12JDMAY9nQo8IsQwrWOocMQmeckpIivRQr4v5BH5hxEUvkImp31R0z1CrSeXYsCNMQwmE1I2c8macNhnr8yhJ8Yf3ki8g4NQm26zvMwDXmKylN1szPJmmoVyaEnxWhgGeh1tgq1YQPJUs+bJLHKF5PEnO5Lsrd8ij+/t3+PS1x1/nmWl68EYbGaBHfZMalHkikzSc6kTscqr/NyRfd1Pom7Ekq87qb5c0Wonteiuh3pdWYkscp3INn6tdTrqdzfuYaE1bvOy74ghHComf0K+AYiG93i9TYBeVo+BRBC2NEUq7wXWmZ7l9axyo/z5xaQxCp/z+vvOkTMqkFtA5n4WEGyTRWvg/EF6qnKy7KEzFjlIz2dapIY6H28DrLPQohx7KMeb/Zn6lEbxQEg6pdB/n+tfx5I7jj2lf5bEYl51oTIerni2MezEIpIsLEEtW0f/16L+kTULWtJiG3Z0itVP7FP7eFlj4ZbOdLxf0B6bQaKVFadYy93JKt9AOn1YtT+vYFHgm8HMx3reVSuGbeZfQBhoA8JofesEMJy/z3fGvdAknMNnkBBpapzlDmRAgy4NHM4bslYgtP3CzHecqS1NcYqn4cAsBb4tV9Pxyq/0utkBgL6VanypmOV/9vzuwz4EZnxhtOs0HM9vYNoHat8JZnbw1pilSP33DDknhnv6daTFavcy9pAZoziW0i2f5xOsj0jbhHJFas8bsnJ/mtKfT6SZOvK6tT7Yqzyc9BSRWTeNyNuxKUk/II5yPCaS7Il7UFkDMxHnXmx1+s05LJ83PMet+M8iwaZuN1npdfBM+SOVT4Tnd8MrWOVL0ID2h0IG41eH5d7vcUY683Id7Da6zXuUsiIVU7rGOUXIgLVEqSspno5TyTByiSyGOYkuyEiXi5CBMxxXt5FJLPQyGyen2rTFxALu5qEXRu3XJ7nZZuKPGhXIx5KS1uGhEX8Osm2x1zbwdLfI7P/La/zW9GAmN6m82cS9nfUHRNTadQA3yTBzyI6L1b5ZOA7Kd0Rt6mtRROCQ8mMVf4MySD3KlCVQ2fu7Pmc52U4j8y49QsR5qv9PWuR7kvrjhIy49ZHtnw9CQP9I55OjGmxgiRefDajew+EuQme9wa0RPFzRO4C9Y9Y9qXAJX791dT1uJ1rEclWtZmezxtojYUvI4/odP98m6exGvWNAQgfzd7Gk9BkLdZvC6Pcy1Xr746Tsq5Y5TnS2Zpilc9ApIJHkcU6o6KiYmQXMzS3bA7WcIpVXo069ecQFnZESqAfGvT/gDrtCtTBP4NmH88jLsXewGnIe/NvtPUoO1b5gf65GVncdcjQ+D3aGfFZf48Bu3ftOCgsaXxUVFSwbt06mpqaOppV3khy0tdi1G97IcU8Fw2kf2XTxyov9mf39jzMraio2KULH50n48aNC8DhIcUoRwPyQuC5DmaUj2ALj1UeM1ow5KnfszXFKr8bzQSfQJ29AVjTxQzNLyUlJTQ1CcNx0C4tLeW0004DyMkGjrKerPLVyMB6BG3jeRfNGm5AW3DGIUPwJZL1yr6oHUeQnLf8GMLBCvLHKo/7awcj/KTXKmeTuLvLRo0atWsXNvJLGh+1tQpg2NH4WLZsWTPJqniMVV6E2nRjYpUP8+/tiVX+I6Q3eiAd0ww0demOzhUza+hgRvlyYKCZNaP2TksZMDNswbHKo7QV8nQImuFsrljlcaC/Hin2gaxfrPJz0Cz8QNTBH6Q1ca6LHZqSwR8bTPWMauqW1mGlRmnPUkoqSrjueYV5f6jfQzmfW7tsLeMvG09oCrww5QWuH3s9lcdUMuO+Gawcu5IRlSPSrGHQYBvP1i1BbfQWcp1Gw60XwsX/ITzMIIlV3oSC6ax0I+AExBDPjlUeuQJLSaKFfQnhIrrr90MnhMUQmS3ShY1MGfyxwdTOr2Xd4nUUdyumvH855TuUdzQ+piDl+wUSkloDhWOVX4yzytFEoBwty6Vjlcd18xirfG9PI5CcNR1jlZ+DvDHnI702B3l7do1lum/KfbwwJ44h6yf5vKKbWkKrUN9btozoN4LvHprfGHQJaLntdjO7Fo076XFwYFbI04+bWZ2vcTcBJb6+PSadqM+4H8gKeXqIj2VXAnv7rphhyBu0DO1uudtDntaR8I52aasQG8wqDyGk6dV1wKlmdmUIIe6R3In2xyo/DQ2qGxOrHJLZ1p9QZ1qfWOW/Au4I2o++GK2Zd0kOGfvjsWCwdtFamhs007YSo6G6gdAcGPODMQWfr32vloZVDVRUVhBCYOZfZmIlxoqpK6CZDNawS2Rv90C4jOSe42jNMK+hNfAtz+fsWOVpok0MVRmJLgvQYP1vZBTGiFpdkiURHw01DdSvqodmKO5RzLql62iub+bwWw4v+Pz64GPIkCFxV0AZSazy2K6nI89MrljlRanrkaQJ+WOVp3czRAJbjFV+MZm6YzUK6JTUyfyx3DflvjbrLp9YBx8A0+73bkUHnxxSeUj2wN2cg1H+f2j59GI0kUzvjVmNBtbjyDz8o71SgSYE+6O17ieQh+dsNOm4AM36zw0h/MNd8aCBfjaaiD4JnGRtxCrvMFY5Wr/uGUK4yGfcMXJa3CJRS0JA+AqySJ9GxI2hyNoIyFUwDHWMKciN1QdZw6uQ22pPZBg0ICv7x8jirUdr3ReidYbXkWW0D2qUd9E61NFoRjYadfRaZCVfiw4W2RUp5ajIa/z55f5bZGOWok5c7Xme6M9E92wxUggxDvkeaJCIa+ur/HMziQES41kP87Rm+juj0ij3/EYmeqN/biRhhZZ7/Ubm5Vx/b2TqrvA6LfFrcXCKLuUmEuZuD5L40FHSW2hySSRDxTqKDMtGEgZzIxqQYx3FMjSSsMrjO6MBGV3msf5jsJW1aDBt8HLGmddzqTL393e/ichOMTJa3BZYTLJFbBZiwNf7O4tR+w0kiawWWdqRdBWDgMRTpSAZJGL41KFofa0PSeztRaiNqv17FcLFAC93bI8mr4++yBjuhnA2zcsy2O9p9jz1JGEOv+u/9/TfosepwX+fg2YAuVjEvRCfYJ2XZSAJ5oyExBjPLy/2vBXCR9xrvwD1+8hi3iP1GdR2+/rnaEjFg0PWkeyjj4PwWkT6iTEZilP10YMk3Gl05SwmYXlHHsUAEu/KTORh+SsK+lTj9TSaZGJT7OUOqN2eB04m0zDA06sg2Y6K/x/v70jvDMHz0RO190qk2NOM8sjDeM/zNcLrZqp/Ns//UC97bI95/vyOJKRBSJj80RMZA81MI5n8DCDRXzshrJNKIzLKB6bKUYTwupvnr8TrrhphKxpM0cCaTKL/A9K55SQ7HnYh2c5X5emU+rv7+O81JH18HsnS57PIg/YvEsNsuOf3SISPGEdkHppYxngkI9BY9dMQwhVkic+4nwTGhxBOMbO7gQecRzOCZOC+BPXFJYik+D1P97vI23OTl7URODA1Ec6UdrLK4xaSnKxyEgU42ysvHav8n565OYgF+jZJrPI5QH+/L8aMLUVAbkTGwKf9/pP9vrPRuuYA1FE+mWKhZscqPxDNkOLs6Ca08L8MdYBbkWX1rj/3EGrYEpJDI2Is4r1T5R2LWJ4zPA8L0FoInv9e/nknL8dMb4wGRJQaD+zr91zk+RuPAD0XATeyhuN2rci6rwFu8WdP9Pw/irYyTEDErDrUCY5CscLHIp7Ay0jhve35N8SYPd7f2YgU1Ac8L5FZeX6q7B8mk0EeB64lqc/voAFyll+7wdvtCMRruBwZVb8h8cLUoDXqgAaOGBUtslfr/f23e318GgG/GpE6ylCHbEJuqjmexvFe9lUkxzKeiDrnBKQwTvM6XOHXrvbPjyLM1CJl9wM0s4Kkb8xBRmUzUuj/RJ1+jLdp8PrfzT8f789f4/fdhpTmHKRA+iIMDfRyXe5lmuB1ugAZrmkMvYeM19eQe38tWrs92p+7FJE8y1F4zrXI01TldREPyMiOWz3Y63+xl3eH1G9xaWmC19W1fn0ByUEqad2RZpV/FfhzitU+Bm2jmeH5P8B/q0o9f6nnO7KB4/bOfyLsXObpTkPK/xmk4Cd6Wvf6c9d7+6bbYgaJIfCOl6cYzY4W0DpWedQLj/o7bvZ0voiW2OqQfluJ+m2Np/kI6u/xEJFm1F8fzqF/xyJm8psI67d5O0wh0S97A9P9c9r9vwatk+J5vhgNYuVeZ2PR5GkCwvVrSEetRjj8o1+L+iXiZh2aFf7Tnz+K1rG3BwP9/PPBXucz0IRqMckulr5eH/UIq/P9XR8gExuHIz0St5jNQrh4hOQwot8g/Mz2vF+ODKjYrl/19H4J/MY/v+TvPY7MPnAmjmX/fjmJftkRjR3FecbM3iSH8fwe+EjW77nqq4U9n7r2MPCpfGPzhrDK4ywj5z5uM7uMZAtVnHEvReC5wht8oVfArWjGtTSE8FVTrPLZIYTPOsOuAc2ii9AM+q6gvbq/Qa6F5Yi9+eMQwi8sd6zylxFIBniDHInAeqOnH2ce74UQdjOzyC79KjIOSioqKuhihuaWzcEadlY5aI26m5l9HXWKz6E16l2B60MIV5nZX9FAfRA6GWxnpJgqEQ5uRuS2cxEe9kAK7QpP5ySS2VkZGjDjnuX7EN6eRyzT/buwUVjGjRtHnz59WLVqFSNGjGD+/PnU1tZ2NKs8IOV9DhpcFqM2nILa9/UQwklm9mvEqbkTtek1QFEIIZjZq8CeIYTeZjYH6adZJGd8705mrPJKNDhfhrg2L5Lwd55ARnDoimXfuTJu3LjlyDDoHkLoa2YfR2PQdGSA3RVC+IaZDQWeCiGMysMsXx1CuMq/T0cD8sJc73TCYwx5+nWgJeRpgX3c2bHK/wXcFjowVnl6sG4r5GlklfcG7g1JrPLmkMQqfxR1OJAF3dPTbHbC23z/rTciuHVDg+rv0WBei5Qs5IhVHkJY4dFw5pIcsbYUDdbzkTtoDZoFRwnIanoOOGTUqFEVXczQ3LI5WMPOKm9GOwjSa5IxVnk5iUu9N4kbri+KYhTMrJLE5V2H+BYLSJYoziJZ54xuv7hEcjKahRyLZmtL0eD/yKhRo8q6sJFfysrKqK5WHInp06cDUF5evilY5U1oUIXkzIE1SGkPTF0vRriJrta4PFMGrHP9MgjNho9GuLiA1rHKY5CgxSQhT88hOfK1Hjhn1KhRN3fho/PEzObip6mZ2U74PvYQwsE+YEYSzfqEPAV4yhTCOy1HhhBWhi0g5Gm7WeVRQmbI0wfQgAnwSzM7Abl+VpoCtZdROFZ5EUms8kFooP4mGqj/jAbqRuAcM/sCOWKVm1l0Hz3v/wejDlbk+a9Gcai/jlzHLyImeTxoIkMW1SziyheuzFsh0XsRCBv9OTI6W333z7n+Z9+fz5vSUTL8mOFUv19N7cJaSrqX0KN/D3r078EtL98CwEt/finnc7VLannmomdobmzm5Tdf5s5JdzLyhJFMvGsi816ax/Chw6leXp1mla9BRt1M5CYLJLHK+wE/N7NzEQaakGflVeB438IRA1+AlPYgZOSVora+gSRWeQytGtdsv4vc4w+a2WHIHfpj/y0jVvkFT1zAkjVLaA7NhBD0H/1vDrmitG7bssvRu7Bm6RpqF8moqxhUQY8BPbj1lVsBePkvL+d8rnZJLU//79M0NzbzypuvcNfku1rwsey1Zey8085pVnk8f/l7aK92XNtfijx/Iy0zVvmX/R6A2hTpayVyZdahGfeLSF+8F/LHKh+OsPIycsX/iSQefoZb4eZxN/PEzDwhXrskQzaUELfngD356UfTnOmWgC9r0Vr/yRQIeeqymhxjW0qagGND7shpmy3kaUexytPya+SKjKzytxHR56PIxRT3QYIU8frEKg+oEf6G3B3VaACPxK5stnkJ6oSRcPIX5H6vQQZAKRrIYyOchzrfQOSKz5DqumrumHBHnmL7S10RGLbRnyOAc33O9z/XPR0tM64QLptqm2hc3QjNUNS9iJpFNTTXN7P3bxVl8+2lb+d8vnpiNXXVdZQPKae+qZ7Jd09mybolLB+/nMamRpqam7JZ5YuQsh3q340k2ll6Fg6tY5Wnf4OERBRDbK7Ice8ckrCmnwU+bWaz/be3kCs+GhMt8sq8V3h/9fsYRpEVYab/RVaU0b7burx7xbv6EKBxVSPN9c1YiVGzpAYM9rha0UDfXJJbN62asKoFH+ua1jHpj5NYtHYRK95YQXlTeTarfI4/FsMMr0X9Oy1p/XAqardX/fsKPLRvCOFhM3sZMYN3JHOmFQlhUWKs8qPRWm412plyMZpxfSR1LwtqFuQtb5cksjGTjfKS8lyXv4ja417EffhKG8k8jQ4tGo+W0NZHegLXeZCVlpCn7XjuftNJZjHk6alt3F9wjfs1RLZJ10bONe42XyLW+Ry0vvwOskbHhYR1fhti/NYCHwshzDGdIPY8Wl/qj9bahyOrdwCa1d+NiDDvIxLBxchS/h6yuJ9Cs/SFaME/xsj9GJrtX4E66DDkQrsthPB/ZnaDp1/v5V+KrLfIKjc0QJSSxBrOxQytQCS495CCGExyeEFxKp23/fpuJDFyqxDZYg0yePqRHLK+1PO1GyKvxHTnk8TrjSzSWSSsUPN6XooGw8gYdk3bwuCNjHjQIDfdP++IjJp4EEM+WYLqbidEEFmd9ftQ1Kax/Ob31KC2XYaU6WyEuRj3+e/IZT0fkSAfR1yGWkQw+RTasxtnzOciotqXSFyma5DhV+q/fczTOI8kRnFvhJcyr68lqD0q0UB+DUmwlrhNyDzNRn93ZKLPQvjqTRKHPhKhdkcdvMbrNiEN5JYqL/fU1Hsim7gJ9YNq/74HauOVCCezvd4bSdjq5Qi/EUuLETZi+0QOSNwLP53W2yuj7I+w8i4y1Cvy3Aeqrymp/IPqay3Cy96ez9UkuH/f/5eQMOWH+O/zEV4uDiH83sweR8b4x1FfewrNiqMX7S+oz3ULOgnwUEQq+yaKZ74/4kN8HGHig8glvgPwrRDCzWY2ydOK8egfCCFcZma/8DSmozaIMafTa6IjPc+xLvOxyrMZxXGHxNQcdZot+yIjs5JkOXEt0mE7obqPxNkiRHiMg8FKpGey89uThOm+FmG5FumfAajPNyDcx+BGET9Fnu6sPGUDkRTbCoRQ4nmd7OmsIyFRRonM814hhIG+T/rIEMKCNtLeaqTQwP06aoRDSbaBzUeNbus5cNciwDSjGe3XPe1/oc53L2ITltE65OnVyAJuT8jT7yAW4vOILZgd8rQvsrS/7Wn+GHXK60IIV5pZ36AgHU8jC76mf//+w6uqqtpb1O1Kxo0bx+jRo5k8eTIHHHAADQ0NTJo0qd3kI4C6ujqmTZvG3nvvzaJFi1i2bBnFxcX06NGDyspKSkpKIjltCiKWXICIYp9H1ulApHx2QINfN9T+pyBlPQXhrRtSQPMQA/Vg5AWaiRTMk37v99EAVo0GviccG7XA/4QQ7jOzR4CP9+/fv6wLG/kl4mP69OnstddeNDY2MnHixA7Fx8SJEwNa6piCAlrsiAyzvRGD+3g0+70OGYQfRAS1F0II5QBmtjMaCM5AE4D+KMb2zb6s9x4yFPZAjOnBrp/wa4aWWS5DeuYdhI+ZXfjoPBk3blw8qOq6EMLBnZ2fjpRCrvI9nGXZMstGFs56+ftMscq7oRnNGDQ4X0kSq/w0NPs9GM2Wf516/GUy3d+PIiNiKcmMBtTp4qlEH0Wz4n+TnL7Ukh2kqCvQ7K0Pskb3McWNfcLze5jnbUBFRUVX2MI8YmbstttuTJs2jSuvvJKf/OQnAO2ur5qaGo444gjuu+8+Tj31VBYtWsSAAQMwMy6++GIWLFjAbbfdhpk1oba8E4XIbSCZWYIMyv3RTDEG8umLwpUeQuLhiPu+ewCPhhAazCzuPZ6LZmHr/P4BaOa4m5mdhjA8yszOQl4furBRWMyMb3/72/z+979n7NixPPbYY3ziE5/oUHxMnDhxPsnyx3JkyA1CA2gTwsrDqWTT+oys66R+e8nMJiBdMRRNWHbwcs0k2WIYPW49kQdlH3/vW1346FxxvXEzbbvH1zfdHWkd8hScoNaR78onhQbutOshukVbyDh5WOUZYpmxyv9qZs+SsM4DSaxy0EyokqQDVZCcjhNjldeRxBVuAPo6C68ZWckLEfP3dRQ/+FikpPPFKo9EktfIDFu4Crnyjz3ooIM2LcNrK5bS0lL+9re/AXDMMccAYg1fc40g0RZr+FOf+hSnn346p56qJZ1Bgwa1/P61r32N//qvljDhC1E7Rnd3JZoNj0EDeCA5IjIGMlnt129Ba0b17k1pQHiY4diJR2ZG/EFyKlUpIid9xMxWom0lN5nZqcCQgQMHxqWFLskhZWVlnHnmmYAOoQkh0K1bt47GRzOJjojs4L6o/eP1eCxv1B3LgWIzK3EWcCVJ0Jd5CGfvIy7DCsQKXox0SneSNfMHQghfz5H9mwC6dEeny5QQwkEdnWgIYTFZIU83t3Qoqzwt7n56nVSs8hDCb0whAS9Gs+avoYHz8yj4yYt+b3R9ziB/rPKLyIxVHpBbfbSndQ+ylGvIH6t8FdoS0IPMsIXL8tVNVzzqRHY8ckfWLVvHuiU6LrfbwG50699tU8UqH4jckUWojd9Fa8L/jfZk90D4WEsSMWkEyU6EezytGuQ+PRq50F9BZLaHUDCEbmitbhUe0c29MKVo1gVaQ8veDsLnH/g8C2tybu/cLmXgEQM7HB9r3ljDsCHD0vjoSXLOQX+kQyqQB+Z8tH78MWTQRd0B8ta95YRBQwM1CGMfQxOMuI8fxBEoIxm064HjzKwihFDrWw7XhTyRrq55+Roempa7vF2SKWlybZrYmSZ95vq818C9uPxjl6eT2mZDEreXVR5DGrZIAVZ5lAPIilVuZutIwv4ZUrw/Q/tqf4ys2WzNl+3CSl+L1yNjdC2axf/I31NHa7dYOlZ5MdoeUoH228UTXK4DfmRmE9dnPW57kRiLOoRAfXU9zXXNWKlRt7yOaqvmw7/9cMHnNyBW+WCS0Kkx+hZoJvRF/2xosN0DkVdiONqI8Vw4ysZUJOX18e+L0Vrp39G6+SfM7D+ejy5pQ3b9zK7MfHAm9Svq6TaoG6U9xA2tOrmq4HOF8FHaXJrNKu+JdE1a6hFxcTyaAMSz0iEz3Gh6R0LI+h0y8bFjVhr1aHnlFR/8V6Nlv9whKruk3RK3T8ZtrenP6W2W2Z97l/fOTmpHMzs8hPB8Z5RjU8r6ssrjAB5CCIVYxbnS+weKRvZhdB7pr7J+vxAlfKV/fxyFOQSFTz02fR8K8bkEGJxihl4aQjg2PhtCeNndoQvRjO1HaA1qbQjhTL/vFUQ4+VYqLx3FDIWNZ4eOIQkXucb/+pKEmS1Gs4EapGiGoxlnjO0cQ3/G/Hb3/OyHGJ5DSWJuv+PpxXjs+P31ZDJDy9EsNh/foS12dJoZCmqTRjTwNiE3eGSGLkdrzWuB0SGEBZ2MjbNItnjsQeKGzSX7o8HDPO0iErwsQ7PFUpJZXS9k7HZHnqRGMiUyhSMLuI6E/f8mYq+vRfgoQYb3NL9/CMJED2TQGAkT+F1PKxdWd0CYqvP8TEP43ZMkvnSpv78BMd/7F6gTED52QW09kCSs6TTkPYuHd0RDvx4tm/UkwUeUPdHe3P9k6Y6rvC5+5vn5MvAJf2ZD8HE3sHsI4QP+jknAtBDCZ9IFW098gOpvBMJ+ulz5mNcRA9nYSMsQEuMyxjZoQoZojIvRDfXlGBuhGeGuFBkkhso9PZVuzFMl0j2QHNAzz98b48nXII/pPqgOYlz8PVCdpsvWD2E/7nneheT8gbSO7O/X3vH35KujKHsCP8kea7YFKTTjNuQuSrPKF+Ks8vV5iZlVISX2Khq4zzWzL6EwlN8LIcQDGNJn5rLxvgAAIABJREFUkM4j2bc7N+v6B1Ejxkg12fcPjc94x6z2+4ciIB6aemYEmYcqQHJoyWecGRr36w7Nui/bxMs3Pd8lz/X2Tuejcu5GclJWeg/xHrSW2LZ7pq7F/Mb8jGxnftKBRuL7C7GG21uuA1Os4fJFixZVOGu40lnDA0pKSoaPGzcuoH22cTtHp2EjhHATvoY5YMCAUFVV1VZZs3/vk/U/1z0gwyqXpK+n+2/2rDNKrpibg1Ofu5PsgYb8WI3et3Re0+8fnf1ALnxMmjSJAw44ILu8cZvW/llpd3d8lO29994jU6zyyixWeSOtcfAzNJDsAPw8hDDJzPZjw/FRTuYkpg4ZFBmyAfiI0puEYxElX1vkw0Y+iUb48KzrO5AbeyNSn7N/z85TjFi3a9b1Pqlns7GxS450ILdrO1f+0jjJV0e43sjW7duEtJdVHqUfG8YqfxAdVLHKzP6AOlXw/79GYUzzMT1zzezbywzN9cxM4Ou+jh4Ds/w8696v0sUMbVM2B2s4xSq/I+vxjcFGfzOLTONKFKBhMOI5jC6EjfSMatiwYV3YKCBlZWXcfvvtnHnmmYwdO5YVK1asV52tB6t8bo7Hr0H4ODaEcHXq+obqjsXobOaZaLY3hIQ30SJd+NhyxMzmh+Rc7W1KCg3cs8wszq7ijK/F4lxPVvk9IYS/+v2LUr/fTLJVIzJAo0QGKHmuL8VZ5SlmaLy/hYmeYg4vJ5M5HCOrxSP5WiRtNXcxQ/PLZmINg1yIadfgxmKjRwhhTMoVOhq5yiPeu7DRAVJcXMyBBx5IUVERvXv3pqamhu7du3c0Phay+XRHDBYUd6SkXdtAFz62MNlmmaKFBu7RtF4/SFuj68MqrzSzJmeV/wr4AlpjGkiy7ewh4Ekz+x9kKXcniVU+OmXpVgBHhdByqk+aGfobT+sR4I9+PQCv+P0PofWwHmgNJcYqPwmt0RWUmStm8sl7P9nWbduN9PxwTxqWNVC3VJEhyweUU9q/lF889QsAbu12a87n6pfXM+vqWYSmwHOTnuPql6+m/0f7s/DBhawat4oRlSNYtWJVmlVuwLe3ZGwAHP3Ho5m/en7bN24n0uPQHpQuK6V+eT311NNzeM+Nxkfz5GZ2GbJLmlU+gM2jO2aTnBhXhFzl2a7nvHLZc5dx/9T723t7l2yAHLjTgdx1yl3pS9slq7w7UmKzUMc4Ac241wG915NVDgmr/GgSotM4tCUHWruqslmeluO39P3ZDGGjtVssMocbU9/noeAvbUp5cTl7DdyrPbduF7LHmXsw5U9TWLpmKT0H9aS0ZylFJUWM+XLhLY7vz36fGatn0GdYH0IILPn7Eob0HULjjEaKKSaEkM0q70dCzIMtEBsAI/uNpG+3vu29vdMlhLBJ46fv9Y29mP/6fBZOWMjg/QdTMaiCkvISKnYsFA21MD6KQlE2q3xHkvX9Tak7Iqs8XmumNeclrwzuObhLd2xiqepblX1pu2SV/wcFIEgfNNIC6m2cVd4WMzSbzZiPGZpP9kVrZotIGOY1iHC2hiRedDfkpluKGMPdURss8Gf7k7CvDbEt09IXGU+QuPneQ+6/wSQn56xGpMM0W7UMEZvS36d6GntTOFZ5ZJW3lx26G2rLGGVvJpkyGngyhHACbFXY6Ovf3yUTH/uidu1F0iZDkWG8CK2fvoXYvrHd5iMWcMRLMyIdrfL6XEsSr365pzEIkXPinvPIci/zvK9DhLzKVF5ivPK07Ifar8jfvcbvn4Rw2dfz2wcNcK1O1suSaQgbJf7OGBiht6cXyzWLtvGRj1V+qf/eUfjoCFb5MFT36eBWhtqlhmSbbDYelpDEde+J+uQcMvGwmkR/9EdtvtrrMNbTutT3/TzN8YhYVkEyyapEbRoZ5vmY21FHFKN98IsRZnsjbAzwMtf5u+ei6HI1qF27eRnXkizD1pJs7R1EcihVHcLEABK9AcJbqb8/Wy9vl6zybqhRD01di8ddbtOs8nYyQ3OxGXMxQ/NJZda93VL/+6WuDySJGJbv2cgWbw+DNc1A7+5/8X252Kqlqc8Z7ND1YA3ny9v+KVZ53xRr+MA8scqjbG3YiDPCND7SzO408z+eSpYdlW03ckvcehUHy+FkunCzGb3p/JaRmzWcC9tpbORimLdilb/xxhvsu+++ufCRvQsiVx32pR34KMAq72h8dCSrPNe19NJjNh6GZd1bSms8xDbpnrqnH5m6pEfW9+y85MNyXuZ2SnYmk0+QTqub/0V3VPYxXmVZ9+b6rQcecpZMVnmU2J9a8trFKpcVPwRZnxXIymmXbI2s8i5maPtkc7CGnVVeiyz4tHRhYwuX3r178/rrr3PIIYd0Bqu8o/HRxSrfymRbZpUXcnemWeVD/H/L7M/MvhuZ5fkkH6s8hNAUQmhGUc7iGmI+Zmi+6y3M0KzrGWm1g1Ueo3G1SAjhphDCQSGEgwYOzJ7sdkmUyBqeOHEivXv3pn///jQ3N3PNNde0MIfzST7WcHFxMUVFRXzta1/jtddei7evpAsbW52MHDmSIUOGMGvWLE488UQqKyvZb7/9OhofhVjlHY2PdrHKu/CxxUgXq9wlHfRju2OVT182ncNuP6yt27YbsYOM8hXlNK1sYi1rKRtWRtghcMljlwBwVfNVOZ9rWN7Ayt+uhCZ4auJTXPLcJXQ/rDs1/6yhfmI9I3ceyeoVq7c6VvmBNx3I3Opck7/tU2r719JEE03Lmnh00qMUjypmfI/xjH9MB2r9oukXOZ9rXNHYCh89DuvB6n+upvytcqqGVm11rPLvP/F97px4Z3tv75INkEMqD+GhL2TEg9+uWeXPoPNuTyUJebnf9sgq71Xei1NHndqeW7cPGQWzXpnF3DfmMuygYfQe1JuS8hJ6D24VMzhDZr08i8drHqdfVT8IsPKRlRxYeSBT5k7BigwLtlWyyo8fcTzL1y5v7+3bvuwFa1asYf6U+ZSUlbDj7jvSY4cebT426+VZPFbzWAY+Dqg8gKlzpyp29VbIKj9gpwOobaht+8Yu2WAZ0W9E9qXtklX+EiIBlJOANVqbIYRQnPPBfC/atljl2ezQyCqv8DzlYwtHdugYRPQrYePZofv4s2/QOgb6bp6XenKzhaOUeTqR0b6UwuzQMmTU5ZN47nVkrbfFDo1T62I0082O2TyErYdV3lHM4TrElO0o5vDGYGNfFFu9hraxMdfrsRCBdRntYw6P8LKMRsTBLlZ5go3VSHdsjN4oRdgY7M9EbKwPq3yk/4+s8lH+fX1Y5ctIiGeRVV7k5cmFjTrUL1bkyVeU7ZJVvietWeURWNs0qzwtFRUVPUeNGpWPrZ3reiG2cJodGtmfm4Md2p32sUMr/C99Xy52KFCQNdwtlV6UnOzQFGsYZw33SseidlZ5M1sIqzwlvTcAG+vDHO7GloWN/iTbD3Ollc0cZsqUKYwaNYqSEqmZxsZG3n77bfbZZ5/sQ0jyMofr6upGOz5G5mGVg3TKS6n0Oo1VnpYC+OgIbHQjc7fJ1swq3ynr3rTkwkYFrcvRSsaNG9fEdsgqnxdC+JCzyiv9e5GZfQ64r70v2BpZ5dlhC7uYobllc7CGnVW+li2EVR5CuMnMbgXeGTVqVBdruIB8/OMf59FHH6WsTLq3vr6eE044gSeffLJdz7eTVf4+MvjPANKHMXcKq7xLd2w5YmYLt1VWeaGBuznFKp8OYGZPAof75202VnmXtE8ia7ipqYkTTzyRp556iv33339TxCrPxyonz/VNjY2Dkbsz+0SkLknJ0KFD+eAHP8hJJ52EmfGPf/yDgw8+mGuuuYYQAt/97ndbzlIGMj7XN9Rzyqmn8LnPf44TTjyBtQ1r6d2vN800U1pUmh2rfBxwhJntFHSCXKfFKu+SLUq2e1Z5dL98PPX7dscqBzj/sfOZsHBC2zduB7Js52UUlxfTsKSB5956jp779WTegHlc9/x1ADzU76Gcz61dtpbxl40nNAVemPIC14+9nspjKplx3wxWjl3JiMoRadYwaODekljlLe7UtFRdW8V71e+tVx1u0zIX6AsTnvP+0gfGTxvfsup7Qc0FuZ8LwN+A7vDkmif54RU/1PXV8POTfs6FH7mQv/3tb+yzzz5MnToVpDv+F6gys25o3TXiY6SZDUdrsJ8HTvP2fgb4NPIefhn4h7/9If/+sv/+dIpVDlrDHYKMhXazyrv0xqaXMYPHcO1x16YvrRcPa2uSQgP3+f43BLmJeqFBeA0637bwRsxtkFUOcN111xEGBY444oj2PrLR8txzzwFsce+sOrmK+up6Vk5bSVFZEb2H96asT1ne+6PUvldLw6oGKiorCCEw8y8zsRJjxdQV0EwGazhLthRs5OR4LPrHIsq7lfPDH/ww18+bRH52+c8AuPjHF2+2d7ZbDte/+rX1lHUXLi677DIAfvKTn2BejWaW8fm9Se9xy6RbGLTrIIrulrf7mLOOYdJLk7jl4Vu4t+xeqqqquPHGG7n//vsJIUw1s8XAn5F+OieE0OTpnQs8jtr2thBCJGD9ELjPzC5HXJ544smtyLCbgWban/fr9Ygw9ybCyK0k8S3alAceeICanjWMGVM4jn8u2dD+3xl6A+CFF14A4LDDOn3r7M5t37J1SiFW+c2IFXkgSYzspYhgsDaEsF6nKWwDrPIK1FGnI7JIL8SGTLtj2opBnWaHRrfbWqRsViBrfiWZ7NDIzI5s0Kgs+pMYRfuTsEzTzOEYg7qUxEWYS9LxryPzdBhieC5D670DSdidTZ7HMloPfvH/ylSee3u+4/Oz/V17onnZSBTPO5s1HPPVBFyxBWHjO16eIoSNSEhcSMIcNq/zuAfoQP89HRO80su2iAQPvfxzkafT6NdLvc7qPc2IjRiHfLrnqQdi7UZc7u/PzEZs8KkIp9UI02lsZDPP021Q4+/q5+9fRW5svI9wjF+L68wxHnWRPzcbkZ4aED6ysRF3aqz2+p3k12M86hijv1cIYaCZTQOOdFd5h4uZfQad7X2mf/8icHAaG369kO5Y4vmv8d9jG+XSG8P9c3v0Ri5WefocgqX+/iZU93si3bE/CW5Kaa03Ik6j3siOBb6+eiPGnt8TYWGN/5+F9GQP2qc39vF7eqHJ4VKEu7SUAXuFEApNTrdaKVSoT6ODA+K2HyNphLanVSnZSlnlvYFhFRUV5VnM0PTnobTey9leVnmUGCs8rq8OTF2P/9PxxNOSzksfkvjWG8MOTTNPByJln51fICdr2Jw1bLRmtKbTj+xQ6urq9ijEGnZWedxKEuVDyMXZTGZQoM2FjVqge0VFRWkWNrKxkL2hPY2NKv9fQm5cREn3tSIymf0RG9AaC+m8dCMZTON9aUZyNjZy4SfN9i1HbVuVdU93UqzyHL9FiQz1bMnAhkusw3R86pjXAePGjWs0s1OA6k01aLsU4uC0iJMX56ClmUXAA8Cv0Gz9JOBPqC0WIjy8jwbmK0IIfzCz/0NLkm8Bb6MZ/2rgKKA0hDDXzCoRVn8FXIjaZi7wuxDCZWZWE0LoCWBmY0MIB7ln4UtIfzciXTsK9aOdkF7+MPACGsSnAF/0/H4mhDArpuXpDgaeIjE8m1Df+43n5yQv40o0YasCFoUQfmtmy5HBtgNaNr0L9eV3/f+ZXt9/Re1+JXAaGsRPQIbQ39HA3YTCc69KcRwws+94frZJaS+r/CzgJmeVn4xWoNolWyOrHLnBfgjsNWrUqHe7mKG5ZXOwhp1VvjrH4z9BA+ixWdc3F6t83qhRowZ3YaNzxbkKt6OBbVPK6+RYL8+Rn2Lg92hJcJ4/9xBwLtKbxWjCUo4G/zfQDDISQiYjY3R/FPjqo0gHDgEed30K0t3TPP1dQwi7t5H/RuCGEMLPzewg4FlkTI0BLkGD9v8gg2wZmsm+igbeo83sm8DuZhYX6kchT053ND58Oas+7gf+gpj+53mZHjeze5FhGZCxEQl+i5CHYBjymP0O2At5WgZ6Xc4A/oDqfxxwJDIyFpjZt4EjzWyMpz2bZBl2m5P2sspvAvA16jL/vC2zyg8GZoQQZh500EH5irfdSyHWMHQoq7yeTAxEF3c1nccqn0TmDLpLOkcmotncuDbu2yhx70y+9fK0tOgOADO7DzjJl3ke8WuPAxcgr8gZaIZa5883x88hhOfNrAknYQJPA/8dQmiwJAQrJMsxbUncd/4m8gCMCiGc7B5R0Cx5Dho4n0J9bNeg9dSbUrP3SuBO4BbgxhDCU2b2PvIupKOU3QGcHEKYaGZnoKWML5jZ0cDZwBPIPf92CGEfr5s70JhgwL/RksyzIYR7/fcZwKAQQpWZjUURPR8LIdxKwlPY5mV9Y5WnN863xSo3VJFvpQf3tDsDOIXEFfkQ8CczuwZZl5uCGfoQcrFMRtbYUwh82czhnKxh6GKHpmX2qtmwC9wx4Q5dGAaPLXyMxxZq62Q+VnkIgWm3TKOkooS6fnU8dIfuq1tZxwdHfZBrj7u2hTXsshL4fAobJWgmHIBhmxkbkAcfXdjY9JKDOQwy4PqTn8PRIRJCeAQffAtICzbM7CLgG0A3U/yLK9DZ4/GeT5Cs2/YjM/83ZaXbB1jsg/ZHSZYLPuTvehIZnuuAHj6QLgH6m1kZmk1fZ2ZvorX3X6EoZtl5v8vz/DSq14PNbAqa9R5oZt8CjgB+4OUp9bp529P+LzQgf8qfudxnw6eTrEO/4/93RbP7XcxsPDK+4pj0CvJcLEMz6R/7c3OAA8xsd6+jo9GyAmZ2EvLiNiMPw/khhBfYBmV9WOU9kGVYj2bQP20j7Q+jNZLJKffK/wJfyOXOcGbon0lYmx3ODPV3vI7A9RhwDnKJZq+F5I0Mt6Hs0I1heHYGS7O9rHKApromisvbv/Ni1fRVLHppERWVFYy9RK7m4Z8azuJXFzN9wXSe7vV0C2vYZR1yM0ZsnBFCuMfMdkQd/HmEy82BDRA+Wh1tWwgbm6oNt1RsdIJsKbEYtP9QhMj/Ai5GO2x+irgDdyLuxL/RgHMW0oEZ+fdALmm5B/inzzInoPXvqWiQmgVcA/wmhDDGzF7ASYYhhNM9P7f6O05AxsfBtF6GNOBexFN4AxkCv/JygMaBC4GHQgjjfJkiLVegvjYe9Z+vooH0DRQyNk724sBdgpYJ3gsh7G9mvwE+APw9hLDEzL6CjIB5yIioQ16unyFPbjMi533V03vK8xbMbDTaZRC5HduUrA+r3JBFuAPQEELonvPBLVzaww41s18gq3M6qoNq/ymyQPsii3cGiZtqPwSkfOzQyMpfQiY7dD6t41EPQIDsR352aDEJMWR/1FmG+7tjlLExJO6xyA6NzNC+yCKeTiZzuNZ/T7ND9yNhL9d5WSIJKd+a8XJkmIET/TzPq/36MDSLaPQyrEOdcoXnK8YxB9glhJDzjEQzu5QcuxQ2RNqJjcgq3wXV2wQyWeWRITwQ1VlkzPZGs4XIEN4D9at1CAPdUP30JWEIl/m1iIGeSNnvSNL2+PuHohlLNjN8D+Qpa0QYqEDux+w4z+XA3mTGq8/GQLTOIsHpPc9vOu70LOS6jsz6qGCa/fngaZYgMlKaANjTny0i4bcUe14j0xgv3yK/d5VfGxjyKbPNKHEHA3Aj8BU8FGtqR8RsVBe1qC99A3gRzcB/GUK4wdex/4F0bQ+gewhhF3dpP4oOfjoUYe9LyEs0FU2WDkLr6Rl9IhLWPI2H0frzGoSlI1HbFQNnZu+48IEwPteA6r0aYbzE03oOGSExFvsXQwhrzOxOZBy/hPrMV5DH61Ckpz7obu9jkPGxMxqsv4L6xwzg7BDCvWb2ES//yLaIiN4Ot4UQ9ix031YrIYScf6izvIQ6UPyLa34h33Nb+h8CzOOp7xcCF2bdUwIsQGSlGf5579TvPZEVWI8APA+BejbwDb/n/xAw30BEjTV+/XakvKegQXQGUrxVqENf5f8nIOV8iT/3BhqUL0Wei5eA4/y3GrSsMMef+SliYs7z38uRUn8YDRSvAv8EvuK/V3l+hiNLfggih5yBLPN5yDB4GJFN1pKcVZ3r72p/3xgv4/PIep/l+f85UvprvQ7Xeh3NQrPquHvhOq+fScABntcKtAUofm6ph82BjRQ+FpLEq64Fvuy/zUbK+DxkkNWhAeoJ5OqMz+/gvx3gZZyIZvoBeNfvexRY55/3RINptb/7/RQ2JgFN6bb0z2chlu8ziBC1xt95fVZ5DHk0mj3/a5Eb83fIuwHQP3X/ROBW/3wn0hUPIw/bKv+ryYONZmQIXEti3B7kaf0GmOyf+6LBoAkZK4em3n8OWuqYSsJcPqCzdUuqbWciI2ii1/e9wBEpfNyHiGc3o/64CvW71ak0evvnM73eJqC+0Qwc4r8NRgM0yPir9/vmAxdk5avG3znb3/kGCjD045SOeA8tJU3w+1Z43s4nU0fMQThc6Vi5BC1V3EYyQfiWpxu9YdM93VXIuI1xPN5AXq1pyOBd4fVX4+9bjAybX/qzzQirffPU/2IvXyNapu10TGwSnBUAYOxAAXXI4I27D1v3wB071nBkHU4kNSj7PcVosJ6FlO4CxHC8DDjR7znPO8hyB0kE+1D//aveMd8mMXomO4CfR5brXAf+hWiGWeed88XY2VJ5muR5Xeh/F/n1sx2ocbayzL/XeEec4H9LkSJc49ebPc1X/bn3Pa27kDJe5h30FUQ6WUyikJv9L3h+A1KkDf65n6fzPbTEsdTzMMfrYRUyXlan0nrUyz/X733X7zfkqlvp5d3V62EiUtwXbU5s5MDH+16OJWiWtAjNfr/tdVaNBuaHvTzx1KXfkZya1IwMrc963bzn79kLDVwTvU4u8HQuxRUzGhSiQT0PrT3GtnwA4ep9f089mgm+iit/T+MwkoE1GmXrPO93+j1HAP9BGF4NPOHXX0OK9WHgeH8ueggCMviCl+st/9yI8DXB0/yPp3M5MN7TvRMp6+iNuoqk7x1Dcszra4ig9Gpn65ZUfZ7g9f4u4kn8FPWba5GO2BXNUpcg/bErMsob0CAW8bHS6yogXfMD1JfO9vecm8JHHXC8X2/BRypP0UB4y++d5/hYhjAf9dfzCK+vIW/IQq/vN71N4+BbiwbQCan2moX0W5OXa6KX+19+z9XA8lSe7kLeq3dTGJnqZZ6EBu5DSYySxUifXgVclafuZ6PJwuHoRMFOx8MmwVgB8E1ECjhaybHDNbEVD9w5OlYrxU/7ZuWP47MApHBjgIABfu0M73xjswB1BprtTkldryKxaI8EHvbf0gN3TCdXp4xWd5UD/w1ELjk2O79o5lWCFIClnov5GeX5uN7zWok67JlIOZ/hnTIq5DQ2WrwxiFH6aeCTwL1Z+e2NOnl8/1ikHP6cuudG4Aup79OAnTobGwXwcY+3a2znx9Fa3O9S9Z3GwP3AuBwYmBbbIgcGjiRr4E7VXxoDsS0fTGPAr/VwfHww6/pzJLP7vb09ryeZcc8C9kth+w4Stv6lnq8qx87EFD7SM+0GCuiOiIE0PnDcp+4Z7W1zX2fgYyNw9ek0PtI6InXPGkTqivgo9TZfk8LHlKx0Y7un083Ah19rQHumYxtNA/6VjY8c7REnEWlcfQkNsq3w4ffNA+7w69XI/Q5av65LpX+H18svERM/3fe/laOsER+nIJ5Vrjyn62FW/Lyt/eXaIx0lzSqP65gxotNWLSGER0IIu4cQdgshXJHjlmzWcDqAB2a2B5qVxXtGI4s2V91kk0xuxw+nSLFDz8+651AzmwiUm9l+edLJEN8/+ggaeP+NFNs3fEsent+laD9+IwkTN0pfMxsSQngbWdeRkHKtl20pwsHpyM0b85XGRsxLeg/dK8CHzWyE/9YDKaMlwL3OJq1Dg98NqecKtsGmknZgI+ZtlZmNTOVtd+TJSN+z3NOM9R3x0QfNHm5MYeCi1LP9fe0eoCHVhiCj4WzgTDPb26/lw8bjOAbMrNjM3vL3/juE8GrWvZFfQBDBbx1wYur3Xmi/bA3CAAgb42hNDBtNgo8ocYsdZjbVWcE4wRAzK0eEwhtQ/1iC+sqOZnaLmVWY2TAUlOOLyMO02fGRS8wsmNmvU98vMLPfpvABWjZ6r/XTLc9UIc/COFIMcn+uO+rbD5BsWYwS8TEUeMrMxpE7gI7Rur5mALdFfJnZ7maWPor388ijky1zkPf1TOC7jsNeyAtVQmYQnu7IcwBq01yE6BpgQNQRyGu1l+cpFz6+ijx0mQXU8wF4whnufZFHIfu+muxrW5sUGoQvQB05MvdWIBfZIrT2uC1LoQAeIKVRCTxtZpMQyJbnSii0ZofWIRfUbkgBLs76/Q1ExtoPbU963czuyZFO9nua0GxxGlqXfhkNwG/4do6hQElWOuky7UASTvUKL99+nr//RYEPDkGuqrEIDwG5zFb4/5Y9qKl8LUEziHu9rl7x8h+AZnXdUP3VhxCeTj3aVht0psRB6E5XEFcg79SlWffkk3sQiegshIEAHEfrqGGgQXmSmd2DYwMprxcQPnJhLMotOAZIlln2Qlt89sm610hImKA2Tcfivhi52LsjDFQibLRSjCS6I42P6M5fjrAf2b7fd4NiEvBPx0AJwscfQgiRIPcjkrXU64GPePnS0ln4qANONbMBqWtlOD5SOuLSXA9bEqRqORrE7gEOcgb5/qhPn4C8N9mk4JtQ3dWjiGvHo5nt8Hbk+4/IxR11xI0kxlUZMtz+kuO5N9DSSQnwJMJhxMfdZOmAdsgaZJBFHXEWSdTFDHwgw7WRHEeqIm9FPRrXIqnyI+uZl61DCrhJZqAOuhQ1RCOymBqBJZ3tKtiUf6y/qzzD9dxG2jVojSYSlS5AsbNBpKwHUTSk1xFLdDZSvn2Rcl0GfMnv/yM6DSv7HT8Bvo+2ckxGoH/Ly3WJp92IOr0hd1UNUhATEIsVnODmeViIZmFLHA9rPS91JG7Q6DY/qI06GAzMTn3/CL4OlrrWKa5MGmXvAAAalklEQVTyzsCH1/2FyACoQjOXvJjw65PRzGdAezDhv/VArsaF3s6vkhDDGpHrciIyrpY5NoYjI/B15PqPrtlsbKxBSvsHaIa1goQXUe+/B782pY363arwkW6/9vTpVPtFvkM98Kd2tN+RXo8DkAHzBFqSuBHN5gcg3fIvEg7EpYhrkqu+PkDi/j4DDZ6PoXXqv5LwGI4jMf6eSqV7p+ehETHFr8ZJdig8a0a7oNCq01CAlzeRXoqnRd6ZqqfFiNwb94//29//DNI3Oxdoiy+R8IEmelvkxPDW/FcIjGu9MdLrmNFqbu7sjG/SSmkfge0cNPPZGa0rR2LFeTnSOxLNZiJT/Hdel33I7OR/Qh6NuL2jDinnG1Cwhn0cfFOQYVWHBveBOMsSWeRj0QC7koRM8g9Ppx9ygT3jeYjElFkkSjyyQ9Nrrad43iNz/Tvk2XHg90QSXnY6v0Sdu9Y7ZF+kBH6ZVWeLkAKYgIyO1zobF5sQH/EY0XoSxZfGxGH+eT4yniaQDIwREzejgXYlWgNOM/EHej1fgGZQNchtGvzz+f75Ub//RW/jCZ6vB1NlasjRpp90vL3v71/l1+OhKIGEuBgQbgthYxIydCIeM/CBjIXZXqdjkSeo0/Dhddjb85SrT8f2G4YznUn69EPI8LnZr08HeqbSHkzCBTnbsRJ3XMRdBad6vQ5ARmU1yY6TN/29n0DuZYv1Rea69RkI032QF6wWDfgDHSvD/b5+nqdLkdfnUGRorkGz/Spvl5NTbfoj//wjz/e0VJn6epo1/vwOSH+8i/Tc75BRdBwyTgJ51q2RF+sdr4cKL+NxXsfRsD2HbXzgfiPV+U73/5FV3tDZGd/kFZODpEQmq7wbUoKzHGCRGfoOOpUmndaRJISzBgd6k3ewPyNiz9lIkTWSsHLrUQzm05El/U1kia5Eru+paNY0GlnekYl5CbJe/wicjBTD7mgW2ODvrvc2neP5epZEUR6OXJVppfoIyZa2VSQBEOZ7Z5pEst75Me+A85FLLZ3OMWjgG+P1sBi52nbwOoiM2dkoWMq7yJApOIvfyvGx1jEwBQ3aTV7H/+P/I9O+0dsv7k74o2Piq2iW/EXHRlTOr3r6ER9x6+ICTy9iIfIM/oIMwveB+f7sMpLZU2+koLOxcS8yrn7t/1f49SZPKyAlv8DL82Yb2PiKv7eBxKi5JeKDhOT3+y0BHyReiMuQyzg9cC8m2dkxweujF+rTd5PE7K7Fw3+S2Q/O9esTydxxMgGFI8Wx1ej4mervHIJmlzP8HsuuL1oP3DejrVoTSQ79mIkz2bPytNjb8xU0eYjb3qJuW4nw2x8FRpnu/wd6+v9AbvaylE6p879aT6MB6akfIlzO9XLOI9mpMsWf/T0yJhaRteOE1hjepgfuqDxCrr/OzviW+ueAPDrr2pFkMcWRlTkbubVjJ1+Ku7yynt8Z7Ve+F1nw49B2tF+Rx0WIXF1HkckM7ebA3tnz9E7q3c+SUn5kMVg9r3EgaKLwPu5oAORkh6bSbBc7dFv6y4OPOHDnw0RcumipkyxM7IrW/16MOPN7MrDh7/5o6vt0ku08afb6T4C5/nkZ4kaAK70c2JiG3KDXoFlaoIDuQMp2m8EGbffp7jmeydV+5wG/KvCeI0n0yAR8Fuzfl6ew8TO0HfHn+H7qPOm1tCOtGe4P+/tOBO7O8eylZO5sqMn3W45ny5HhexcKOVyonibmK2eOe78NXJ7jeisMdzZmNvavEDltrldSILF+YiSrUOC57VacGRqPL82WQ00nrfUws71DCMvRbCx9EscTyBp/wszGmdllACGEuWiGMRIB7zVk1f+H/GzaJ5CV/AVE+uhHcjTjUuRS3xU428weRW1aKP58X2CgmX2AhJ0aSPZhN6fuPcvMLvC8FTqIIyc7NJV2rIez8tyz1Ygzj2/G8eHM40tTtxyKli+aUbtFeQLNcEB18h9nDh+PYyLoQIsX0Ew4HZs5GxsvoK2LmNleiCT2RJ4sD/SdDY1oMIaETZ4tg5AyrkcEoRhBMM4mIz6asvLWChtmdqSZPcxWhg3v2xchD9r/AB/y9k23Hx7uOaNPp9ov9ulCUuRExUrgFTN7wXSsaZrYeB9aDvs0YqJviHRHZLeXgWOdZDfBzGpMZ5+fjc4POMjMrvOynWFmvyuUqBPx+gTFfT8fGGM6gKQ/2scf75vh+jSN2WPITeCM8hTwWTPr7/dHgtuLeGhj8mN4q5JCA/dvkSKP1nMMh7nIf+uSlFjW8aVZP0c2cGRbxtM3niM57xxkMf4HuQt7At80s8P9t1fRDNmQFTqUREnnMqRuQcrxiyiS12khhJXIHTYZkYjuRWttv0WhMW/wzpkvnO3n/N5SkrCU1Ui5g4y77CM4cxp5pgMY8rFDQSSeA9AAdU6qHrZWqUPEmYtz4KOJZCfBj9FAGOXbiGE8CdXvc3idIMMvxn3+DzLMJpEp6fq/Hg3Ik9C6YTPyzGTLTKTwD0Trkpea4rj3KVC+KpLjKY1k21IFmTsu0kZtvgnACLY+bNShtebb0YAcpaX9fAdC2iiLfRrUfuk+nU+GIx28B9IDO6CjP+fEG4K28/UC3g8bcEa5hzvtgUhySxBu61C71qPB7wbgvhDC2BDCt9cj+V7Aw47B5xBXBrSE8JlUPcVB96fAMWb2BmrvBbTWMUBLua8AnnOjMx5udR7CSVsY3mqk0MD9IcQwnIoGkgqkKHZALpQucbEcx5emJYSwKoRQg5TRRWif7gBkDF0RQrjUzAYi9+EQ1Em+iogZ95tZX9R5jkWWcDVSavuTeWRlzE83NECfjNYkzw0h/M73endDrtn+iNBzKVLoFcgwqyf3DH4RMgROQriJxKN4tOBihJNuJDP3SpJ42un8fRntEz89uP8qR53N9/+LUYSmg3PdtzWI4yNuncl1bvJwtHXodaTIFgG/M7PJCDOfR21yeQjhbLSWPBHtxz4NIITwEtol8Ekz+7uZ/ROxsY81s++a9ss/hVyno/29Rei4xgfxQ1NMxyru7++7KoRwu+fn+BDCL0IIPVF0r93cyBuP2v7X/r7/Rri4H7nES5GXaB5S/LuiAft8fEuYmR1nZm+bDsf4X2S4bDXY8DqJuzT+O4TQA/dkhBCWohn3dNS/DjSzD/ujY5BxbshVfkYIYZmZ/dHMjsrxnmcRofP9EMKyEMIxIYS9feA8AnjBtOd9CjLgrjCzF81supkdDGBmB5vZS95uf0IekiiDHDdPoLbay3RA1KgQwv5uWE7yvFwaQvhV9JB4HcR8Xorw/KCZve5/H/bfFoQQDg4hjA4h7BtCuNMfewhNED8TQtiLRKdVe90147onhFDnZZltZj83s5fNbKyZHYDOBO+OthKe4Wl8GvW/cuSOb8nrViv5fOjkZobGMIaNne3j31L+EMDvAq4tcM9gv68GWceN5GafHoUGvWGIpPIS2tqRZpQ/hlyI0z2tVmxa5Nq8HbnMLkTWeDc0834QgXgw0M/vjwedGDIQWqJgpdL8JZp93Y9mfldnYSPuPAhoxnYxSTSldDrH4fHIC9TXJotH3on4qCc/8/ivJMzjT3r9Gpm7CcaRRKOagUhBx2W96xNIsc5ABME3kOKLpKLfORYm+vVr/PrlJLGl70CDQ7F/P9ifsdR7ngRm+ueeiGtxk+PmR3h0LHLrjmY0I52FBvqpyJ0+0rFRjW9D2pqwwcYxy1t2Bvj1DGZ51nvGIEPpZW+3kX69CumVdBzw2xxHJ6ETt/A8xvXeo0h2DJyBjKuoE44kxZdIvf9ZMrkwLfeRWifPV+Y8ZTrDsfklkhC7U7xMI0m2d73u5Rrt98ym9dkQvRABLm63PYZk22sRwujhnY2Xjf0rdKznDP/f5BX6J7TOGffEdYkk3/GlwwBCCDcgi+8byBK8EinybyNlFuUo1Clj4IQSNEi+4/cuQ0FQzkKD+kfR1oobU++NsiNaZ7sbHRl4AprpfQ14PoTQaGafRlG1GtHs+/QQQjCze9GgPx0oMbN6xEr/rpfhCM/3L9Ds8FLknroSsZzHIa/MeQhDj6GoSPMQaedCZPn+WxMNXgkhnG1mQ4BbQggnoBnX3/z3ErTH9bE22mFLlYiPZrQFqhtabojH5ILOFD7ey9uMjKieyH16OCIs3g/8xDkGQ4DbQwiPmdnZ0IKzR1A7HYoMvjkIc98ys2PRrK4R4XMBcIjP6nsCc80sngC3AAV9iTscPh9cCzo+DgEq/PdFJPG2IQnQEsvyAlLufRE29kJGxyK0HjzA7zscYaMe+KBjeqvCRghhlZnl69t7WXIMZm8z60Vm+/4BcUOGIp37gmUemzkrhHBKCGGCme2KBqSjUICmQ/19s0IIk0HR6dCe6+B9+Fiv01JgqCnAyrv+Pcq/g7g3HSFHASeYIp4BFLt7/PshhMfzPPMn4CIzawkeE0KYbmbXI71XjkiQB3s9DwHONbOvI9f6syGE1cBqM1vnnspj/G+8J9kTGQPPd1A5O0cKWEFdrPIO/mPzsU//Dnws9f0/aEvQX8kdsGU2yT7NUmBpgbSXtIUNtLaUl1W6Pf5txrY/g0x28GxyxMYmR+xx/3wH8Ol2lGdftE1nHnJ5H0ky82q37kDG6nOp7yeSY6a3pf9trvbNkcbvkIetikzPVks7kskevwP4dur67Dy4aWnPrPc9S/tm3DnL3BZm0QB9A8mMeziaAOyQyv8ZhbCd/g0t4Xy9s/HR0X/tZZXPRS6suK8u59rT1iiWO87wpZvgPT1Q7PHJyNorQbF+o3QI+9SZmKuB083sWFO4wA8iBfEh4AFfQzvIzG70x3qSEIE+R2GPylNoRhixAUlUrHj29ykFnt8oMbOdzewZM3vLFPP6vE34rg7HRtCMJjKPozwFvGhmk81sipmNN7Oe69v27ZC4MwE0wNzjs7BbgFP882HArlaAKWxmu4UQJocQrkIBUEYhzEVuQwWaPYPc31eTnPrUZCI/Rdbv28BwM9vN7//CBpYNM+tmZq+Z2UTHxk83NK12vCsDG0CpmV2ap303uG+bWQ8zuyeFjYlmVum/lSEPRt4Y6DmkDyKCgQa7KC3YcO/MjcCR5ixyE5/hLtTGF/h9ZyBDI5fkLHN8zsyazWx06v4vuO66A83WB/r13ogbUG1mgxBBbX3kceCrJvJw1B+TTTsXtlppL6u8AinnVchluy2xynPFGd4Uch6abewbQtgHbXFIH/Kx0exTV4hVnm4xWntch0htY9Fa122ILXwrYpdHKTazVz2f3yG/nIdcqZVo3SggHK31/w1oLWpTSSPwvRDCnshle45pa9OmkE2FjV+TyTx+B/WxWJdvo3qEDWMetxLHxgASctyP/J0r0VLI8yGEMZ72zFCYKXx+HERQuz+K1hcb/dr9KGAQiHT0RZKtX28jN/xEtNNhHZpl/ctETlufQShb6pCnaT80kz/OzA7ZiPTaelc+bGS378b07fOARSm9cQ/wqE8AxqN+/eB65Ptq4EozexE/GCgbG0Gu7H1IdgD8K4QwJoTwJWSg/aod7ylUZpCn5qLsh0II9WgJcEf/Hk+am4p014vtLyqEEJ5ALviXvc7+g7xNW7cUcF88iEAyiSSqTTz3dWJnuwo66o+NizPcrtjh/tt1aMDJvl6FlNktyD10D7I4X0TrzAf7fQejWfN4/79HSFxEf0FutqfR+mEMr/qd1HueJb+LaylaQ8xb5jzYmEsSqzye87sGqPL7/oAUy1Tgp6nnZ6PgEC/77wcgy/hdnEjl933f8zAp/XxWXloFNOnCRodi4wwSN2ab2Ejh42XHVZPj4j+Ok9c2BzbIc3xpFzY6Fxup5673fMf8TGET6w002XgKETe3uuWYjDosULnbBaucLjYoZA7cbbJBU9gIJBHUWs7jTnXAmKdif3+HskG97uYAvbuwseUwhZGhf4ZjYQnJToMGoHZTYsPTm+Btd1WX3tiysJF+jhws8k2MjRibIGdZt6a/LlY5HcoGXR60XzvXOzaEDToZdVCQcrjTdMZvQGtqx6L4yN3REaMgV1b6eMb2yAUodnG6zINQe0c2aDPwl6AzqiM2mtHWoKORYv4GsoCjfNYU2aoEsUH3IgkQEoPQTEZKa73YoFY44E2HyRaMjb60ZgoX+Xs7hClsZl9BATC6m9lhwN7A0WYW10h7m1kvb7u0LEK4bMbPWkazojUky3ObBBtBx9uO8fv+Zmb7hBCmbEj525JNiQ3v23G5YSFaajgNsag3Sm+kXtPRLPJWZU5jw/F0HuJXdEd8il0sxSJ36XBsmFlvNLiPM7MjO6jMnSaFBu79zGyV3xMPU1+36bPUaXItcq3dnrpWhI5mTHdKzOx5FLlqGFqnOQVt+SpIGvLO+Vfgr2bWjLZpPUjm+bXpM62bSdroZ8AzIYRTnMTxbAjhcTO7BFnE53rejsTJIxsoOcucJREbRaiTgBTnk/EG74wXAB8IIawwBfbolkojXcbs8pcgi/nKEMKNZIm1EfBmE8iWiI3ngHdDCGO8bm8MIVwXsZF6pra9hcyRp9tNoTwPCiGca2ZLgWFtYAPEkI7nIlf5tZaAIpsSG6m8rzSzZxE5bpMM3C6bBBtB68yttk2ZiIIbpTdSz2wwNnJIm3ojKJjP7U5qi5g6C+1OADYdNszsSuBEMzvB0+ttZneHEP57g0rbyVKInFZBckRbFQkzdAId2+CdLRVm9uuQsEHPJ4kM12Fxhs3sY2b2F2c0TkURplpFFSsg+dig2dITxaD+//bOJUSOKozC548TkjhGUXESTcRAxOCQgFEXwpDE6MKVuBFFfOAqKCEL3fgiW4mIiwghG8VoVprZiQtFgqDmhZInMgpxDEbjAzEoMRPy+F2ce6du13TXVCdV0485HzRT3fW6NX26bt17z/1/GF3lh0KrbA3oKI/u0BVgCwrgk28MG9nSDZoQtRFd5O+BQVXiD2kpqneDLjGzIeMj/d9gl9czZvZNm8dtB2mjfW0A1MeuZP/FYJCfS2Brsy5t3GRmt5nZqDGe9kvFh7lyvGIXeR4zGzGz68NylS7yPOmsgMuhrDby7EC9LvIlZjbk7q+4+1J3XwZGItzdq5U2UFxxb0QYewGfKKMzdBHoSO4nojv0LfCmE6kyzvBzaAwVuwvZza0MU9ygeYzu0LPIEkQMO92gd4E/zM2euUO/Bx/E8kznBgUybcwFu9+eAHUx+QTs1btBR8Ebywj4HcWKbSA8RdeFtJFRRhsA9fFYWN4N6uAa8H6zv0Zt3IxgSAPH098EzVt1U6WLPM9yMPZ2ZS7yFkzOCjCzolklrSirjQa8fhd51EZfUdRVHmOVrwJbV4OgoeJeMJZxv3AGNDO84O6vmdmr4E0GYLfLALI8sTsBIAhiDfhU+FfYd45xfvT77v75lLNwnGqLu6dzPxHGhAbM7B1wetNhAKfDD20IWTabi6CJ7Gowa89DyWFijOHBsD5WqCmHQOd3M75CNgzS9JpzRG2sDWWcB3ZHrgT/nyfDdmfD+2UARt19R3KMF81sfSjrBjP7FEwuscUZ3xlgHPSJcPzP3P04gONmdgLAumS7upA22tcGQCfzQfD7vAGcnrgHjLp3a9imcm0YxzH/AfNU56+xUrwxNvfvSJIFhTI+3mK/p5PlPShuPMHdPwAjLeb5Cfy9xe2eTZYn17n7XjTGx98cPt8BtnbjPudB7eTPf3/u/RcI3e3pMYquuckx8+d+G6y8p1xLbr9lBcdI120FsLXg/JPX0LN4a+df6iofD39/BG/KPZ/PNLlOuUPbdIei0VUeI2T9G8pxCfW7Q8fBltW3ADZIG92jjbDuaNjvPBhk6EL4/AcAH9eljfB/PADe0A+Cre3BTt9j9NKr6lcZV/kp8Ia1E8Cd7n7OpsbG7mm8QncogBEzewONjDvNIZW6ypPj1+0OfR6MeR4ZMLNtYPCOfWBL6hTY0vsu2a4uV/mIu/9qZkNgzPMxd68l9rC00UAZbQBZsJVz4AyHOWa2AvRExAhpdWjjMDi3d5O77zezrWCgmc1XfOU1Y40u8si4u9cWhbBuLHORp3zt7hs7UZ5+ooyrfCGyZOwT1hj4vp+oxB3qLdygQPWu8mSfmXCHbo8LZnYR9DwsBF27AG+cPybb1OYc9iSto5nFtI51Jg2QNsi02gAm9bEd/L4/Ch+PJevrcg4vBnDS3WPEr1Gw4u56irTRq3hwkXe6HP1IGVf5EWTjVA+DGabGWu/Wm7jcoZF2XOU/g92RN4IV1B/geCtQn3N4MLRsYWaDYMurzuk+0kZGKeewu18Fzunf5u4GjkP/Ara+70B9zuHfwCxnK8J2D6KxB0iIvqCMq3wl2G1+DBxXehk0JvUjcoe25ypfCk5dOgaGMJwTy+b1uUMXgSkPD4PjmZ/4zKR1lDZKOofNbD74QLU2nOce8HquA7C6Rm0AwCYwecoRcMz79fYuUYjux9ybmy/N7EPQGDMMBlSYB5pn7gOw190fmKlCiu5C2hBFBH2cB7u2H4H0IUSlFLW4h939SbBr6xYAl9x9PTgV7M+ZKJzoWqQNUcSwM7jFakgfQlROkTktphU8jWBAMrN57j6WjCGJHLPEHbo8cZVLGyWZJdoAMlf5hLufMTPpQ4gKKeoqvwgaSJqaWYLpRMxCpA1RRKKPBWCQlEGw25yT/93ntt5bCDEdLVvcwRnagJmtAw0m/WpOEyWQNkQR0ocQ9VLU4p4PukZvB1Py7UMS2KGugBei+5E2RBE5fRwF8K67X+hsqYToH6ZzlcsZKqYgbYgiEn18Cc7RPuHu+XFwIcRlMp2rXM5Q0QxpQxQx7O5Phchmj4JJV4QQFVFUcUdX+YS7nwEy5zCYr1fMXqQNUUTUB9RFLkT1lHGVyxkqGpA2RBGJPgDGFV8A4L+w7O5+bafKJkQ/IFe5aBtpQxTRTB9CiOoo6yqXM1RMIm0IIUTnKOMqlzNUNCBtCCFE5yiquI+6+6qwPADggLvfPZOFE92JtCGEEJ2jjKtczlCRR9oQQogOUcZVDsgZKhKkDSGE6BwtK24hhBBCdB9FXeVCCCGE6DJUcQshhBA9hCpuIYQQoodQxS2EEEL0EKq4hRBCiB5CFbcQQgjRQ/wPk07Jbytq0oMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 80 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = list(range(0,80))\n",
    "fig, axs = plot_partial_dependence(clf, x_sm, features,\n",
    "                                       feature_names=list(data1)[:80],\n",
    "                                       n_jobs=-1, grid_resolution=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "######## scikit-learn multi-models #########\n",
    "############################################\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor, VotingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV , GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.externals import joblib\n",
    "import catboost as cb\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "\n",
    "n_jobs = -1\n",
    "n_iter = 5\n",
    "n_iter_nt = 1\n",
    "n_components = 25\n",
    "cv = 10\n",
    "seed=42\n",
    "n_features= 5\n",
    "# n_features= x_sm.shape[1]\n",
    "# n_features= n_components\n",
    "is_pca = False\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "# is_pca = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### models ################ param\n",
    "\n",
    "# estimator = XGBClassifier(nthreads=-1,tree_method='exact')\n",
    "param = {'objective': 'reg:linear',\n",
    " 'colsample_bytree': 0.9683760122352089,\n",
    " 'gamma': 0.7790711924812199,\n",
    " 'learning_rate': 0.2249426498504554,\n",
    " 'max_depth': 20,\n",
    " 'min_child_weight': 10.95324500379702,\n",
    " 'n_estimators': 150,\n",
    " 'scale_pos_weight': 1,\n",
    " 'seed': 42,\n",
    " 'eval_metric': ['mae'],\n",
    " 'lambda': 2,\n",
    " 'alpha': 15,\n",
    " 'rate_drop':0.1,\n",
    " 'tree_method':'exact',\n",
    " 'normalize_type':'forest',\n",
    " 'subsample': 0.9035691355661921}\n",
    "\n",
    "estimator = XGBRegressor(**param)\n",
    "# objective = 'binary:logistic'\n",
    "\n",
    "# Parameter for XGBoost\n",
    "params = {  \n",
    "    \"n_estimators\": st.randint(3, 40),\n",
    "    \"max_depth\": st.randint(3, 30),\n",
    "    \"learning_rate\": st.uniform(0.05, 0.4),\n",
    "    \"colsample_bytree\": st.beta(10, 1),\n",
    "    \"subsample\": st.beta(10, 1),\n",
    "    \"gamma\": st.uniform(0, 10),\n",
    "#     'objective': [objective],\n",
    "    'scale_pos_weight': st.randint(0, 2),\n",
    "    \"min_child_weight\": st.expon(0, 50),\n",
    "    'lambda': st.randint(1, 20),\n",
    "    'alpha': st.randint(0, 20),\n",
    "    'rate_drop':st.uniform(0, 1),\n",
    "    \"seed\": [seed],\n",
    "}\n",
    "\n",
    "xgb = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter, scoring = scoring) \n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=n_components, svd_solver='full')), ('clf', xgb)]\n",
    "    xgb = Pipeline(estimators)\n",
    "    xgb = GridSearchCV(xgb, cv=5, n_jobs=-1, param_grid=param_grid)\n",
    "    \n",
    "#################################################################\n",
    "#################################################################\n",
    "\n",
    "estimator = LogisticRegression()\n",
    "# Parameter for LogisticRegression\n",
    "params = {\n",
    "    \"penalty\": ['l2'],\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"tol\": [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    \"solver\": ['newton-cg', 'lbfgs', 'liblinear', 'sag'],\n",
    "    \"max_iter\": st.randint(50, 100),\n",
    "    'random_state': [seed],\n",
    "} \n",
    "log = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter , scoring = scoring) \n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=n_components, svd_solver='full')), ('clf', log)]\n",
    "    log = Pipeline(estimators)\n",
    "    log = GridSearchCV(log, cv=5, n_jobs=-1, param_grid=param_grid)\n",
    "\n",
    "#################################################################\n",
    "#################################################################\n",
    "\n",
    "estimator = KNeighborsRegressor()\n",
    "# Parameter for KNeighborsClassifier\n",
    "params = {\n",
    "    \"n_neighbors\": st.randint(2, 50),\n",
    "    \"weights\": ['uniform', 'distance'],\n",
    "    \"algorithm\": ['ball_tree', 'kd_tree', 'brute'],\n",
    "    \"leaf_size\": st.randint(10, 30),\n",
    "    \"p\": st.randint(1, 2),\n",
    "}\n",
    "knn = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter_nt , scoring = scoring)\n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=n_components, svd_solver='full')), ('clf', knn)]\n",
    "    knn = Pipeline(estimators)\n",
    "    \n",
    "#################################################################\n",
    "#################################################################\n",
    "\n",
    "estimator = RandomForestRegressor()\n",
    "\n",
    "# Parameter for RandomForestClassifier\n",
    "params = {\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": st.randint(1, n_features),\n",
    "    \"min_samples_split\": st.randint(2, 10),\n",
    "    \"min_samples_leaf\": st.randint(1, n_features),\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"criterion\": [\"mse\"],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "rnf = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter, scoring = scoring) \n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=n_components, svd_solver='full')), ('clf', rnf)]\n",
    "    rnf = Pipeline(estimators)\n",
    "    rnf = GridSearchCV(rnf, cv=5, n_jobs=-1, param_grid=param_grid)\n",
    "    \n",
    "#################################################################\n",
    "#################################################################\n",
    "\n",
    "estimator = ExtraTreesRegressor()\n",
    "# \n",
    "# Parameter for ExtraTreesClassifier\n",
    "params = {\n",
    "    \"n_estimators\": st.randint(5, 50),\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": st.randint(1, n_features),\n",
    "    \"min_samples_split\": st.randint(2, 10),\n",
    "    \"min_samples_leaf\": st.randint(1, n_features),\n",
    "    \"bootstrap\": [True],\n",
    "    \"oob_score\": [True],\n",
    "#     \"criterion\": [\"gini\", \"entropy\"],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "ext = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter, scoring = scoring) \n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=n_components, svd_solver='full')), ('clf', ext)]\n",
    "    ext = Pipeline(estimators)\n",
    "    ext = GridSearchCV(ext, cv=5, n_jobs=-1, param_grid=param_grid)\n",
    "\n",
    "#################################################################\n",
    "#################################################################\n",
    "\n",
    "estimator = AdaBoostRegressor()\n",
    "# Parameter for AdaBoost\n",
    "params = { \n",
    "    'n_estimators':st.randint(10, 100), \n",
    "    'learning_rate':st.beta(10, 1), \n",
    "#     'algorithm':['SAMME', 'SAMME.R'],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "ada = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter, scoring = scoring) \n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=n_components, svd_solver='full')), ('clf', ada)]\n",
    "    ada = Pipeline(estimators)\n",
    "    ada = GridSearchCV(ada, cv=5, n_jobs=-1, param_grid=param_grid)\n",
    "    \n",
    "\n",
    "\n",
    "#################################################################\n",
    "#################################################################\n",
    "estimator = SVR()\n",
    "# Parameter for SVC\n",
    "params = {  \n",
    "    'C':[0.001, 0.01, 0.1, 1, 10], \n",
    "    'degree': st.randint(1, 10),\n",
    "    'shrinking': [True, False],\n",
    "#     'probability': [True],\n",
    "    'tol': [1e-3],\n",
    "#     'random_state': [seed],\n",
    "}\n",
    "svc = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter_nt, scoring = scoring)\n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=n_components, svd_solver='full')), ('clf', svc)]\n",
    "    svc = Pipeline(estimators)\n",
    "#     svc = GridSearchCV(svc, cv=5, n_jobs=-1, param_grid=param_grid)\n",
    "\n",
    "#################################################################\n",
    "#################################################################\n",
    "\n",
    "# Parameter for LGBMClassifier\n",
    "params = {'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "#           'objective': 'binary',\n",
    "          'nthread': 3, # Updated from nthread\n",
    "          'num_leaves': 64,\n",
    "          'learning_rate': 0.05,\n",
    "          'max_bin': 512,\n",
    "          'subsample_for_bin': 200,\n",
    "          'subsample': 1,\n",
    "          'subsample_freq': 1,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'reg_alpha': 5,\n",
    "          'reg_lambda': 10,\n",
    "          'min_split_gain': 0.5,\n",
    "          'min_child_weight': 1,\n",
    "          'min_child_samples': 5,\n",
    "          'scale_pos_weight': 1,\n",
    "          'num_class' : 1,\n",
    "          'metric' : 'mape'}\n",
    "\n",
    "gridParams = {\n",
    "    'learning_rate': [0.005],\n",
    "    'n_estimators': [40],\n",
    "    'num_leaves': [6,8,12,16],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['mape'],\n",
    "    'random_state' : [42,502], # Updated from 'seed'\n",
    "    'colsample_bytree' : [0.65, 0.66],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "    }\n",
    "\n",
    "estimator = LGBMRegressor(boosting_type= 'gbdt',\n",
    "          objective = 'mape',\n",
    "          n_jobs = 3, # Updated from 'nthread'\n",
    "          silent = True,\n",
    "          max_depth = params['max_depth'],\n",
    "          max_bin = params['max_bin'],\n",
    "          subsample_for_bin = params['subsample_for_bin'],\n",
    "          subsample = params['subsample'],\n",
    "          subsample_freq = params['subsample_freq'],\n",
    "          min_split_gain = params['min_split_gain'],\n",
    "          min_child_weight = params['min_child_weight'],\n",
    "          min_child_samples = params['min_child_samples'],\n",
    "          scale_pos_weight = params['scale_pos_weight'])\n",
    "\n",
    "lgb = GridSearchCV(estimator, gridParams, verbose=0, cv=cv,n_jobs=n_jobs , scoring = scoring)\n",
    "if(is_pca):\n",
    "    print('asas')\n",
    "    estimators = [('reduce_dim', PCA(n_components=n_components, svd_solver='full')), ('clf', lgb)]\n",
    "    lgb = Pipeline(estimators)\n",
    "    lgb = GridSearchCV(lgb, cv=5, n_jobs=-1, param_grid=param_grid)\n",
    "# lgb = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter_nt)\n",
    "\n",
    "#################################################################\n",
    "#################################################################\n",
    "\n",
    "estimator = cb.CatBoostClassifier()\n",
    "params = {'depth': st.randint(3, 16),\n",
    "          'learning_rate' : st.uniform(0.05, 0.4),\n",
    "         'l2_leaf_reg': st.randint(0, 10),\n",
    "         'iterations': [1]}\n",
    "\n",
    "cat = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=2, scoring = scoring) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score1(y_true,y_pre,thresholds = 0.5):\n",
    "#     fpr, tpr, thresholds = roc_curve(y_true, y_pre, pos_label=1)\n",
    "#     print(thresholds,'thresholds')\n",
    "#     print(auc(fpr, tpr),'auc')\n",
    "#     y_pre[y_pre >= threshold] = 1\n",
    "#     y_pre[y_pre < threshold] = 0\n",
    "#     print(fbeta_score(y_test, y_pre, pos_label=1 , average='binary', beta=0.5),'f2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196.36302776403062 mean_absolute_error\n",
      "196.1167343601457 mean_absolute_error\n"
     ]
    }
   ],
   "source": [
    "###### test single model #######\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA ,NMF\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import f1_score , precision_score , recall_score , accuracy_score , roc_curve , auc\n",
    "from sklearn.linear_model import ElasticNetCV , RidgeCV\n",
    "\n",
    "# nmf = NMF(n_components=5, init='random', random_state=42)\n",
    "pca = PCA(n_components=15, svd_solver='full',random_state=42)\n",
    "estimators = [('reduce_dim',pca ), ('model', log)]\n",
    "pipe = Pipeline(estimators)\n",
    "pipe\n",
    "\n",
    "model = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1])\n",
    "model.fit(x_sm, y_sm)\n",
    "\n",
    "# y_pre = model.predict_proba(x_test)[:,1]\n",
    "y_pre = model.predict(x_test)\n",
    "# y_pre_2 = model.predict_proba(x_train)[:,1]\n",
    "y_pre_2 = model.predict(x_train)\n",
    "\n",
    "\n",
    "score1(y_test,y_pre)\n",
    "score1(y_train,y_pre_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.22172935688934"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252639.6551981492 mean_absolute_error\n",
      "1008945.7724326251 mean_absolute_error\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import grid_search\n",
    "\n",
    "# param_grid = {\n",
    "#     'alpha': [10 ** x for x in range(-6, 1)],\n",
    "#     'l1_ratio': [0, 0.05, 0.1, 0.2, 0.5, 0.8, 0.9, 0.95, 1],\n",
    "# }\n",
    "# sgc = linear_model.SGDClassifier(max_iter=1000,loss='modified_huber', penalty='elasticnet' ,alpha= 0.05, l1_ratio= 0)\n",
    "# clf_grid = grid_search.GridSearchCV(estimator=sgc, param_grid=param_grid,\n",
    "#                                     n_jobs=-1, scoring='roc_auc')\n",
    "model = linear_model.ElasticNetCV(cv=5, random_state=0,l1_ratio=[.1, .5, .7, .9, .95, 1],n_jobs=-1\n",
    "                                 ,normalize=True, positive=False)\n",
    "\n",
    "model.fit(x_sm, y_sm_log)\n",
    "# y_pre = model.predict_proba(x_test)[:,1]\n",
    "# y_pre_2 = model.predict_proba(x_train)[:,1]\n",
    "y_pre = model.predict(x_test)\n",
    "# y_pre[y_pre < 0] = -1\n",
    "y_pre_2 = model.predict(x_train)\n",
    "# y_pre_2[y_pre_2 < 0] = -1\n",
    "score1(y_test,y_pre)\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pre, pos_label=1)\n",
    "# f1_1  = auc(fpr, tpr)\n",
    "\n",
    "score1(y_train,y_pre_2)\n",
    "# fpr, tpr, thresholds = roc_curve(y_train, y_pre_2, pos_label=1)\n",
    "# f1_2  = auc(fpr, tpr)\n",
    "# print(f1_1,f1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## feature something ##############\n",
    "a = log.best_estimator_.coef_\n",
    "a = ada.best_estimator_.feature_importances_\n",
    "# print(np.argwhere(a>0.01),np.argwhere(a<-0.01))\n",
    "# print(np.argwhere(a!=0))\n",
    "b = np.argwhere(a!=0)\n",
    "# np.reshape(b,(b.shape[]))\n",
    "b = b.ravel()\n",
    "print(b,np.array([9,10,11,136,148,154,156,158,159]))\n",
    "print(np.argwhere(a>0.01),np.argwhere(a<-0.01))\n",
    "x_sm2 = x_sm[:,np.array(b)]\n",
    "x_sm2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "########## train #########\n",
    "is_xgb = 1\n",
    "is_log = 1\n",
    "is_knn = 1\n",
    "is_rnf = 1\n",
    "is_ext = 1\n",
    "is_ada = 1\n",
    "is_lgb = 1\n",
    "is_svc = 1\n",
    "is_cat = 0\n",
    "\n",
    "# is_xgb = 0\n",
    "# is_log = 0\n",
    "# is_knn = 0\n",
    "# is_rnf = 0\n",
    "# is_ext = 0\n",
    "# is_ada = 0\n",
    "# is_lgb = 0\n",
    "# is_svc = 0\n",
    "is_cat = 0\n",
    "\n",
    "if(is_xgb == 1):\n",
    "    xgb.fit(x_sm,y_sm)\n",
    "if(is_log == 1):\n",
    "    log.fit(x_sm,y_sm)\n",
    "if(is_knn == 1):\n",
    "    knn.fit(x_sm,y_sm)\n",
    "if(is_rnf == 1):\n",
    "    rnf.fit(x_sm,y_sm)\n",
    "if(is_ext == 1):\n",
    "    ext.fit(x_sm,y_sm)\n",
    "if(is_ada == 1):\n",
    "    ada.fit(x_sm,y_sm)\n",
    "if(is_lgb == 1):\n",
    "    lgb.fit(x_sm,y_sm)\n",
    "if(is_svc == 1):\n",
    "    svc.fit(x_sm,y_sm)\n",
    "if(is_cat == 1):\n",
    "    cat.fit(x_sm,y_sm)\n",
    "\n",
    "########## save #########\n",
    "\n",
    "# joblib.dump(xgb, 'xgb.pkl') \n",
    "# joblib.dump(log, 'log.pkl') \n",
    "# joblib.dump(knn, 'knn.pkl') \n",
    "# joblib.dump(rnf, 'rnf.pkl') \n",
    "# joblib.dump(ext, 'ext.pkl') \n",
    "# joblib.dump(ada, 'ada.pkl') \n",
    "# joblib.dump(lgb, 'svc.pkl') \n",
    "# joblib.dump(svc, 'svc.pkl') \n",
    "# joblib.dump(cat, 'svc.pkl') \n",
    "\n",
    "# vote2 = joblib.load('vote.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_xgb = 0\n",
    "# is_log = 0\n",
    "# is_knn = 0\n",
    "# is_rnf = 0\n",
    "# is_ext = 0\n",
    "# is_ada = 1\n",
    "# is_lgb = 1\n",
    "# is_svc = 1\n",
    "############ load ##############\n",
    "# xgb = joblib.load('xgb.pkl')\n",
    "# log = joblib.load('log.pkl') \n",
    "# knn = joblib.load('knn.pkl') \n",
    "# rnf = joblib.load('rnf.pkl') \n",
    "# ext = joblib.load('ext.pkl') \n",
    "# ada = joblib.load('ada.pkl') \n",
    "# lgb = joblib.load('lgb.pkl') \n",
    "# svc = joblib.load('svc.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "          fit_params=None, iid=True, n_iter=1, n_jobs=-1,\n",
       "          param_distributions={'C': [0.001, 0.01, 0.1, 1, 10], 'degree': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000021304344550>, 'shrinking': [True, False], 'tol': [0.001]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_absolute_error',\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(x_sm,y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## params #############\n",
    "if(is_xgb == 1):\n",
    "    best_params1 = xgb.best_params_\n",
    "if(is_log == 1):\n",
    "    best_params2 = log.best_params_\n",
    "if(is_knn == 1):\n",
    "    best_params3 = knn.best_params_\n",
    "if(is_rnf == 1):\n",
    "    best_params4 = rnf.best_params_\n",
    "if(is_ext == 1):\n",
    "    best_params5 = ext.best_params_\n",
    "if(is_ada == 1):\n",
    "    best_params6 = ada.best_params_\n",
    "if(is_lgb == 1):\n",
    "    best_params7 = lgb.best_params_\n",
    "if(is_svc == 1):\n",
    "    best_params8 = svc.best_params_\n",
    "if(is_cat == 1):\n",
    "    best_params9 = cat.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb\n",
      "254532.13750836425 mean_absolute_error\n",
      "1017293.2615378051 mean_absolute_error\n",
      "log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan mean_absolute_error\n",
      "nan mean_absolute_error\n",
      "knn\n",
      "38.366438484270375 mean_absolute_error\n",
      "31.23424553259459 mean_absolute_error\n",
      "rnf\n",
      "103357.16381686457 mean_absolute_error\n",
      "255447.7230441693 mean_absolute_error\n",
      "ext\n",
      "219693.07248182266 mean_absolute_error\n",
      "858810.9392285313 mean_absolute_error\n",
      "ada\n",
      "252976.02766755465 mean_absolute_error\n",
      "1010537.6134396361 mean_absolute_error\n",
      "lgb\n",
      "44635.386154201115 mean_absolute_error\n",
      "175661.59716907048 mean_absolute_error\n",
      "svc\n",
      "252105.85713033308 mean_absolute_error\n",
      "1006316.1779143119 mean_absolute_error\n"
     ]
    }
   ],
   "source": [
    "########### evaluate ###########\n",
    "from sklearn.metrics import f1_score , precision_score , recall_score , accuracy_score , roc_curve , auc\n",
    "x_val = x_test\n",
    "y_val = y_test\n",
    "# def score1(y_true,y_pre,thresholds = 0.5):\n",
    "#     fpr, tpr, thresholds = roc_curve(y_true, y_pre, pos_label=1)\n",
    "#     print(thresholds,'thresholds')\n",
    "#     print(auc(fpr, tpr),'auc')\n",
    "#     y_pre[y_pre >= threshold] = 1\n",
    "#     y_pre[y_pre < threshold] = 0\n",
    "#     print(fbeta_score(y_test, y_pre, pos_label=1 , average='binary', beta=0.5),'f2')\n",
    "    \n",
    "def auc_score(model,x_val,y_val,x_train,y_train,name = 'model'):\n",
    "    y_pre = model.predict(x_val)\n",
    "    y_pre_2 = model.predict(x_train)\n",
    "    print(name)\n",
    "    score1(y_val,y_pre)\n",
    "    score1(y_train,y_pre_2)\n",
    "#     fpr, tpr, thresholds = roc_curve(y_val, y_pre, pos_label=1)\n",
    "#     f1  = auc(fpr, tpr)\n",
    "#     fpr, tpr, thresholds = roc_curve(y_train, y_pre_2, pos_label=1)\n",
    "#     f1_2  = auc(fpr, tpr)\n",
    "#     print(f1,f1_2,name)\n",
    "    \n",
    "\n",
    "\n",
    "if(is_xgb == 1):\n",
    "    auc_score(xgb,x_val,y_val,x_train,y_train,'xgb')\n",
    "\n",
    "if(is_log == 1):\n",
    "    auc_score(log,x_val,y_val,x_train,y_train,'log')\n",
    "    \n",
    "if(is_knn == 1):\n",
    "    auc_score(knn,x_val,y_val,x_train,y_train,'knn')\n",
    "    \n",
    "if(is_rnf == 1):\n",
    "    auc_score(rnf,x_val,y_val,x_train,y_train,'rnf')\n",
    "    \n",
    "if(is_ext == 1):\n",
    "    auc_score(ext,x_val,y_val,x_train,y_train,'ext')\n",
    "    \n",
    "if(is_ada == 1):\n",
    "    auc_score(ada,x_val,y_val,x_train,y_train,'ada')\n",
    "    \n",
    "if(is_lgb == 1):    \n",
    "    auc_score(lgb,x_val,y_val,x_train,y_train,'lgb')\n",
    "    \n",
    "if(is_svc == 1):\n",
    "    auc_score(svc,x_val,y_val,x_train,y_train,'svc')\n",
    "    \n",
    "if(is_cat == 1):\n",
    "    auc_score(cat,x_val,y_val,x_train,y_train,'cat')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan mean_absolute_error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "score1(log.predict(x_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_xgb = 0\n",
    "# is_log = 0\n",
    "# is_knn = 0\n",
    "# is_rnf = 0\n",
    "# is_ext = 0\n",
    "# is_ada = 1\n",
    "# is_lgb = 1\n",
    "# is_svc = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ for vote #############\n",
    "vote_list = []\n",
    "if(is_xgb == 1):\n",
    "    xgb = XGBRegressor(**best_params1)\n",
    "    vote_list.append(('xgb', xgb))\n",
    "if(is_log == 1):\n",
    "    log = LogisticRegressor(**best_params2)\n",
    "    vote_list.append(('log', log))\n",
    "if(is_knn == 1):\n",
    "    knn = KNeighborsRegressor(**best_params3)\n",
    "    vote_list.append(('knn', knn))\n",
    "if(is_rnf == 1):\n",
    "    rnf = RandomForestRegressor(**best_params4)\n",
    "    vote_list.append(('rnf', rnf))\n",
    "if(is_ext == 1):\n",
    "    ext = ExtraTreesRegressor(**best_params5)\n",
    "    vote_list.append(('ext', ext))\n",
    "if(is_ada == 1):\n",
    "    ada = AdaBoostRegressor(**best_params6)\n",
    "    vote_list.append(('ada', ada))\n",
    "if(is_lgb == 1):\n",
    "    lgb = LGBMRegressor(**best_params7)\n",
    "    vote_list.append(('lgb', lgb))\n",
    "if(is_svc == 1):\n",
    "    svc = SVC(**best_params8)\n",
    "    vote_list.append(('svc', svc))\n",
    "if(is_cat == 1):\n",
    "    cat = cb.CatBoostRegressor(**best_params9)\n",
    "    vote_list.append(('cat', cat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote.predict_proba(x_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "############# stack ##################\n",
    "xx = x_sm\n",
    "xx_all = x\n",
    "xx_val = x_val\n",
    "xx_train = x_train\n",
    "xx_ans = x_ans\n",
    "no_feature = 0\n",
    "\n",
    "if(is_xgb == 1):\n",
    "    xgb.fit(x_sm,y_sm)\n",
    "if(is_log == 1):\n",
    "    log.fit(x_sm,y_sm)\n",
    "if(is_knn == 1):\n",
    "    knn.fit(x_sm,y_sm)\n",
    "if(is_rnf == 1):\n",
    "    rnf.fit(x_sm,y_sm)\n",
    "if(is_ext == 1):\n",
    "    ext.fit(x_sm,y_sm)\n",
    "if(is_ada == 1):\n",
    "    ada.fit(x_sm,y_sm)\n",
    "if(is_lgb == 1):\n",
    "    lgb.fit(x_sm,y_sm)\n",
    "if(is_svc == 1):\n",
    "    svc.fit(x_sm,y_sm)\n",
    "if(is_cat == 1):\n",
    "    cat.fit(x_sm,y_sm)\n",
    "    \n",
    "def stack_data(model,x_data,result,no_fea = 0):\n",
    "    if(no_fea == 1):\n",
    "        result = model.predict(x_data)\n",
    "        result = np.reshape(result, (result.shape[0],1))\n",
    "    else:\n",
    "        re1 = model.predict(x_data)\n",
    "        re_1 = re1\n",
    "        re_1 = np.reshape(re_1, (re_1.shape[0],1))\n",
    "        result = np.concatenate((result, re_1), axis=1)\n",
    "    return result\n",
    "\n",
    "if(is_xgb == 1):\n",
    "    xx = stack_data(xgb,x_sm,xx,1)\n",
    "    xx_val = stack_data(xgb,x_val,xx_val,1)\n",
    "    xx_train = stack_data(xgb,x_train,xx_train,1)\n",
    "    xx_ans = stack_data(xgb,x_ans,xx_ans,1)\n",
    "    xx_all = stack_data(xgb,x,xx_all,1)\n",
    "\n",
    "if(is_log == 1):\n",
    "    xx = stack_data(log,x_sm,xx)\n",
    "    xx_val = stack_data(log,x_val,xx_val)\n",
    "    xx_train = stack_data(log,x_train,xx_train)\n",
    "    xx_ans = stack_data(log,x_ans,xx_ans)\n",
    "    xx_all = stack_data(log,x,xx_all)\n",
    "    \n",
    "if(is_knn == 1):\n",
    "    xx = stack_data(knn,x_sm,xx)\n",
    "    xx_val = stack_data(knn,x_val,xx_val)\n",
    "    xx_train = stack_data(knn,x_train,xx_train)\n",
    "    xx_ans = stack_data(knn,x_ans,xx_ans)\n",
    "    xx_all = stack_data(knn,x,xx_all)\n",
    "\n",
    "if(is_rnf == 1):\n",
    "    xx = stack_data(rnf,x_sm,xx)\n",
    "    xx_val = stack_data(rnf,x_val,xx_val)\n",
    "    xx_train = stack_data(rnf,x_train,xx_train)\n",
    "    xx_ans = stack_data(rnf,x_ans,xx_ans)\n",
    "    xx_all = stack_data(rnf,x,xx_all)\n",
    "    \n",
    "if(is_ext == 1):\n",
    "    xx = stack_data(ext,x_sm,xx)\n",
    "    xx_val = stack_data(ext,x_val,xx_val)\n",
    "    xx_train = stack_data(ext,x_train,xx_train)\n",
    "    xx_ans = stack_data(ext,x_ans,xx_ans)\n",
    "    xx_all = stack_data(ext,x,xx_all)\n",
    "    \n",
    "if(is_ada == 1):\n",
    "    xx = stack_data(ada,x_sm,xx)\n",
    "    xx_val = stack_data(ada,x_val,xx_val)\n",
    "    xx_train = stack_data(ada,x_train,xx_train)\n",
    "    xx_ans = stack_data(ada,x_ans,xx_ans)\n",
    "    xx_all = stack_data(ada,x,xx_all)\n",
    "    \n",
    "if(is_lgb == 1):\n",
    "    xx = stack_data(lgb,x_sm,xx)\n",
    "    xx_val = stack_data(lgb,x_val,xx_val)\n",
    "    xx_train = stack_data(lgb,x_train,xx_train)\n",
    "    xx_ans = stack_data(lgb,x_ans,xx_ans)\n",
    "    xx_all = stack_data(lgb,x,xx_all)\n",
    "    \n",
    "if(is_svc == 1):\n",
    "    xx = stack_data(svc,x_sm,xx)\n",
    "    xx_val = stack_data(svc,x_val,xx_val)\n",
    "    xx_train = stack_data(svc,x_train,xx_train)\n",
    "    xx_ans = stack_data(svc,x_ans,xx_ans)\n",
    "    xx_all = stack_data(svc,x,xx_all)\n",
    "    \n",
    "if(is_cat == 1):\n",
    "    xx = stack_data(cat,x_sm,xx)\n",
    "    xx_val = stack_data(cat,x_val,xx_val)\n",
    "    xx_train = stack_data(cat,x_train,xx_train)\n",
    "    xx_ans = stack_data(cat,x_ans,xx_ans)\n",
    "    xx_all = stack_data(cat,x,xx_all)\n",
    "#     re1 = cat.predict_proba(x_sm)\n",
    "#     re_1 = re1[:,0]\n",
    "#     re_1 = np.reshape(re_1, (re_1.shape[0],1))\n",
    "#     xx = np.concatenate((xx, re_1), axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_data_elas(model,x_data,result,no_fea = 0):\n",
    "    re_1 = model.predict(x_data)\n",
    "    re_1 = np.reshape(re_1, (re_1.shape[0],1))\n",
    "    result = np.concatenate((result, re_1), axis=1)\n",
    "    return result\n",
    "xx = stack_data_elas(elas,x_sm,xx)\n",
    "xx_val = stack_data_elas(elas,x_val,xx_val)\n",
    "xx_train = stack_data_elas(elas,x_train,xx_train)\n",
    "xx_ans = stack_data_elas(elas,x_ans,xx_ans)\n",
    "xx_all = stack_data_elas(elas,x,xx_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5088, 8)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3938, 8)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx_ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### for second stack models ###########\n",
    "n_jobs = -1\n",
    "n_iter = 50\n",
    "cv = 5\n",
    "seed=42\n",
    "# n_features=xx.shape[1]\n",
    "n_features= xx.shape[1]\n",
    "\n",
    "param = {'objective': 'reg:linear',\n",
    " 'colsample_bytree': 0.9683760122352089,\n",
    " 'gamma': 0.7790711924812199,\n",
    " 'learning_rate': 0.2249426498504554,\n",
    " 'max_depth': 20,\n",
    " 'min_child_weight': 10.95324500379702,\n",
    " 'n_estimators': 150,\n",
    " 'scale_pos_weight': 1,\n",
    " 'seed': 42,\n",
    " 'eval_metric': ['mae'],\n",
    " 'lambda': 2,\n",
    " 'alpha': 15,\n",
    " 'rate_drop':0.1,\n",
    " 'tree_method':'exact',\n",
    " 'normalize_type':'forest',\n",
    " 'subsample': 0.9035691355661921}\n",
    "\n",
    "estimator = XGBRegressor(**param)\n",
    "\n",
    "\n",
    "# Parameter for XGBoost\n",
    "params = {  \n",
    "    \"n_estimators\": st.randint(3, 40),\n",
    "    \"max_depth\": st.randint(3, 30),\n",
    "    \"learning_rate\": st.uniform(0.05, 0.4),\n",
    "    \"colsample_bytree\": st.beta(10, 1),\n",
    "    \"subsample\": st.beta(10, 1),\n",
    "    \"gamma\": st.uniform(0, 10),\n",
    "    'objective': ['reg:linear'],\n",
    "    'scale_pos_weight': st.randint(0, 2),\n",
    "    \"min_child_weight\": st.expon(0, 50),\n",
    "    \"seed\": [seed],\n",
    "}\n",
    "xgb2 = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter, scoring = scoring) \n",
    "\n",
    "estimator = LogisticRegression()\n",
    "# Parameter for LogisticRegression\n",
    "params = {\n",
    "    \"penalty\": ['l2'],\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"tol\": [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    \"solver\": ['newton-cg', 'lbfgs', 'liblinear', 'sag'],\n",
    "    \"max_iter\": st.randint(50, 100),\n",
    "    'random_state': [seed],\n",
    "} \n",
    "log2 = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter, scoring = scoring) \n",
    "\n",
    "estimator = RandomForestRegressor()\n",
    "# Parameter for RandomForestClassifier\n",
    "params = {\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": st.randint(1, n_features),\n",
    "    \"min_samples_split\": st.randint(2, 10),\n",
    "    \"min_samples_leaf\": st.randint(1, n_features),\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"criterion\": [\"mae\"],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "rnf2 = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter, scoring = scoring) \n",
    "\n",
    "estimator = ExtraTreesRegressor()\n",
    "# Parameter for ExtraTreesClassifier\n",
    "params = {\n",
    "    \"n_estimators\": st.randint(5, 50),\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": st.randint(1, n_features),\n",
    "    \"min_samples_split\": st.randint(2, 10),\n",
    "    \"min_samples_leaf\": st.randint(1, n_features),\n",
    "    \"bootstrap\": [True],\n",
    "    \"oob_score\": [True],\n",
    "#     \"criterion\": [\"gini\", \"entropy\"],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "ext2 = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter, scoring = scoring) \n",
    "\n",
    "estimator = AdaBoostRegressor()\n",
    "# Parameter for AdaBoost\n",
    "params = { \n",
    "    'n_estimators':st.randint(10, 100), \n",
    "    'learning_rate':st.beta(10, 1), \n",
    "#     'algorithm':['SAMME', 'SAMME.R'],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "ada2 = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter, scoring = scoring)\n",
    "\n",
    "params = {'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "#           'objective': 'binary',\n",
    "          'nthread': 3, # Updated from nthread\n",
    "          'num_leaves': 64,\n",
    "          'learning_rate': 0.05,\n",
    "          'max_bin': 512,\n",
    "          'subsample_for_bin': 200,\n",
    "          'subsample': 1,\n",
    "          'subsample_freq': 1,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'reg_alpha': 5,\n",
    "          'reg_lambda': 10,\n",
    "          'min_split_gain': 0.5,\n",
    "          'min_child_weight': 1,\n",
    "          'min_child_samples': 5,\n",
    "          'scale_pos_weight': 1,\n",
    "          'num_class' : 1,\n",
    "          'metric' : 'mape'}\n",
    "\n",
    "gridParams = {\n",
    "    'learning_rate': [0.005],\n",
    "    'n_estimators': [40],\n",
    "    'num_leaves': [6,8,12,16],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['mape'],\n",
    "    'random_state' : [42,502], # Updated from 'seed'\n",
    "    'colsample_bytree' : [0.65, 0.66],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "    }\n",
    "\n",
    "estimator = LGBMRegressor(boosting_type= 'gbdt',\n",
    "          objective = 'mape',\n",
    "          n_jobs = 3, # Updated from 'nthread'\n",
    "          silent = True,\n",
    "          max_depth = params['max_depth'],\n",
    "          max_bin = params['max_bin'],\n",
    "          subsample_for_bin = params['subsample_for_bin'],\n",
    "          subsample = params['subsample'],\n",
    "          subsample_freq = params['subsample_freq'],\n",
    "          min_split_gain = params['min_split_gain'],\n",
    "          min_child_weight = params['min_child_weight'],\n",
    "          min_child_samples = params['min_child_samples'],\n",
    "          scale_pos_weight = params['scale_pos_weight'])\n",
    "\n",
    "lgb2 = GridSearchCV(estimator, gridParams, verbose=0, cv=cv,n_jobs=n_jobs, scoring = scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "############### Xgboost2 ###################\n",
    "############################################\n",
    "import xgboost as xgb\n",
    "dsm2 = xgb.DMatrix(xx, label=y_sm)\n",
    "# dv0 = xgb.DMatrix(x_val0, label=y_val0)\n",
    "dt2 = xgb.DMatrix(xx_val, label=y_test)\n",
    "dtrain2 = xgb.DMatrix(xx_train, label=y_train)\n",
    "evallist = [(dv0, 'eval'), (dsm2, 'train')]\n",
    "                  \n",
    "dx2 = xgb.DMatrix(xx, label=y_sm)                  \n",
    "evallist = [(dt2, 'eval'), (dx2, 'train')]\n",
    "                  \n",
    "num_round = 10000\n",
    "# binary:logistic\n",
    "param = {'objective': 'binary:logistic',\n",
    " 'colsample_bytree': 0.9683760122352089,\n",
    " 'gamma': 0.7790711924812199,\n",
    " 'learning_rate': 0.2249426498504554,\n",
    " 'max_depth': 20,\n",
    " 'min_child_weight': 10.95324500379702,\n",
    " 'n_estimators': 150,\n",
    " 'objective': 'binary:logistic',\n",
    " 'scale_pos_weight': 1,\n",
    " 'seed': 42,\n",
    " 'eval_metric': ['auc'],\n",
    " 'lambda': 1,\n",
    " 'alpha': 1,\n",
    "#  'rate_drop':0.5,\n",
    " 'tree_method':'exact',\n",
    " 'normalize_type':'forest',\n",
    " 'subsample': 0.9035691355661921}\n",
    " \n",
    "evals_result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[0]\teval-auc:0.513333\ttrain-auc:1\n",
      "Multiple eval metrics have been passed: 'train-auc' will be used for early stopping.\n",
      "\n",
      "Will train until train-auc hasn't improved in 100 rounds.\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[1]\teval-auc:0.513333\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[2]\teval-auc:0.746594\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[3]\teval-auc:0.746594\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[4]\teval-auc:0.746594\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[5]\teval-auc:0.746594\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[6]\teval-auc:0.746594\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[7]\teval-auc:0.746594\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[8]\teval-auc:0.746594\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[9]\teval-auc:0.746594\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[10]\teval-auc:0.746594\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[11]\teval-auc:0.746594\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[12]\teval-auc:0.761836\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[13]\teval-auc:0.788648\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[14]\teval-auc:0.79384\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[15]\teval-auc:0.806973\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[16]\teval-auc:0.806605\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[17]\teval-auc:0.810406\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[18]\teval-auc:0.810172\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[19]\teval-auc:0.81163\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[20]\teval-auc:0.809699\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[21]\teval-auc:0.809143\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[22]\teval-auc:0.809705\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[23]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[24]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[25]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[26]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[27]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[28]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[29]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[30]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[31]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[32]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[33]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[34]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[35]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[36]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[37]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[38]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[39]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[40]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[41]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[42]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[43]\teval-auc:0.809316\ttrain-auc:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[44]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[45]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[46]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[47]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[48]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[49]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[50]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[51]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[52]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[53]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[54]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[55]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[56]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[57]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[58]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[59]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[60]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[61]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[62]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[63]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[64]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[65]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[66]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[67]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[68]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[69]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[70]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[71]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[72]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[73]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[74]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[75]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[76]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[77]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[78]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[79]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[80]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[81]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[82]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[83]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[84]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[85]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[86]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[87]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[88]\teval-auc:0.809316\ttrain-auc:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[89]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[90]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[91]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[92]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[93]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[94]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[95]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[96]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[97]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[98]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[99]\teval-auc:0.809316\ttrain-auc:1\n",
      "[11:45:18] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\n",
      "[100]\teval-auc:0.809316\ttrain-auc:1\n",
      "Stopping. Best iteration:\n",
      "[0]\teval-auc:0.513333\ttrain-auc:1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### train ####\n",
    "bst2 = xgb.train(param, dx, num_round, evallist, evals_result=evals_result,early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252263.63511946218 mean_absolute_error\n",
      "1004213.2860045467 mean_absolute_error\n"
     ]
    }
   ],
   "source": [
    "#### evaluate ###\n",
    "from sklearn.metrics import f1_score , precision_score , recall_score , accuracy_score , roc_curve , auc\n",
    "treee = bst.best_ntree_limit\n",
    "treee = 8\n",
    "y_pre = np.array(bst2.predict(dt2, ntree_limit=treee))\n",
    "score1(y_test,y_pre)\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pre, pos_label=1)\n",
    "# roc1_1  = auc(fpr, tpr)\n",
    "\n",
    "# y_pre_1 = np.array(bst2.predict(dv0, ntree_limit=treee))\n",
    "# score1(y_val0,y_pre_1)\n",
    "# fpr, tpr, thresholds = roc_curve(y_val0, y_pre_1, pos_label=1)\n",
    "# roc1_11  = auc(fpr, tpr)\n",
    "\n",
    "y_pre_2 = np.array(bst2.predict(dtrain2, ntree_limit=treee))\n",
    "score1(y_train,y_pre_2)\n",
    "# fpr, tpr, thresholds = roc_curve(y_train, y_pre_2, pos_label=1)\n",
    "# roc1_2  = auc(fpr, tpr)\n",
    "# print(roc1_1,roc1_11,roc1_2)\n",
    "# print(classification_report(y_test, y_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       importance_type='split', learning_rate=0.1, max_bin=512,\n",
       "       max_depth=-1, min_child_samples=5, min_child_weight=1,\n",
       "       min_split_gain=0.5, n_estimators=100, n_jobs=3, num_leaves=31,\n",
       "       objective='mape', random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "       scale_pos_weight=1, silent=True, subsample=1, subsample_for_bin=200,\n",
       "       subsample_freq=1),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'learning_rate': [0.005], 'n_estimators': [40], 'num_leaves': [6, 8, 12, 16], 'boosting_type': ['gbdt'], 'objective': ['mape'], 'random_state': [42, 502], 'colsample_bytree': [0.65, 0.66], 'subsample': [0.7, 0.75], 'reg_alpha': [1, 1.2], 'reg_lambda': [1, 1.2, 1.4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## train scikit #####################\n",
    "xgb2.fit(xx,y_sm)\n",
    "log2.fit(xx,y_sm)\n",
    "rnf2.fit(xx,y_sm)\n",
    "ext2.fit(xx,y_sm)\n",
    "ada2.fit(xx,y_sm)\n",
    "lgb2.fit(xx,y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb2\n",
      "254138.9574090474 mean_absolute_error\n",
      "1012575.6072421253 mean_absolute_error\n",
      "log2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan mean_absolute_error\n",
      "nan mean_absolute_error\n",
      "rnf2\n",
      "28538.802124819398 mean_absolute_error\n",
      "126749.58190394573 mean_absolute_error\n",
      "ext2\n",
      "76860.53192683205 mean_absolute_error\n",
      "126565.33018867923 mean_absolute_error\n",
      "ada2\n",
      "15352.867242733699 mean_absolute_error\n",
      "126565.33018867923 mean_absolute_error\n",
      "lgb2\n",
      "166871.07590903927 mean_absolute_error\n",
      "156787.27432007765 mean_absolute_error\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score , precision_score , recall_score , accuracy_score , roc_curve , auc\n",
    "\n",
    "# def auc_score(model,x_val,y_val,x_train,y_train,name = 'model'):\n",
    "#     y_pre = model.predict_proba(x_val)[:,1]\n",
    "#     y_pre_2 = model.predict_proba(x_train)[:,1]\n",
    "#     fpr, tpr, thresholds = roc_curve(y_val, y_pre, pos_label=1)\n",
    "#     f1  = auc(fpr, tpr)\n",
    "#     fpr, tpr, thresholds = roc_curve(y_train, y_pre_2, pos_label=1)\n",
    "#     f1_2  = auc(fpr, tpr)\n",
    "#     print(f1,f1_2,name)\n",
    "\n",
    "# def score1(y_true,y_pre,thresholds = 0.5):\n",
    "#     fpr, tpr, thresholds = roc_curve(y_true, y_pre, pos_label=1)\n",
    "#     print(thresholds,'thresholds')\n",
    "#     print(auc(fpr, tpr),'auc')\n",
    "#     y_pre[y_pre >= threshold] = 1\n",
    "#     y_pre[y_pre < threshold] = 0\n",
    "#     print(fbeta_score(y_test, y_pre, pos_label=1 , average='binary', beta=0.5),'f2')\n",
    "    \n",
    "# def auc_score(model,x_val,y_val,x_train,y_train,name = 'model'):\n",
    "#     y_pre = model.predict_proba(x_val)[:,1]\n",
    "#     y_pre_2 = model.predict_proba(x_train)[:,1]\n",
    "#     print(name)\n",
    "#     score1(y_val,y_pre)\n",
    "#     score1(y_train,y_pre_2)\n",
    "\n",
    "auc_score(xgb2,xx_val,y_val,xx_train,y_train,'xgb2')\n",
    "auc_score(log2,xx_val,y_val,xx_train,y_train,'log2')\n",
    "auc_score(rnf2,xx_val,y_val,xx_train,y_train,'rnf2')\n",
    "auc_score(ext2,xx_val,y_val,xx_train,y_train,'ext2')\n",
    "auc_score(ada2,xx_val,y_val,xx_train,y_train,'ada2')\n",
    "auc_score(lgb2,xx_val,y_val,xx_train,y_train,'lgb2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## vote 2 #############\n",
    "\n",
    "# best_params21 = xgb2.best_params_\n",
    "# best_params22 = log2.best_params_\n",
    "# best_params23 = rnf2.best_params_\n",
    "# best_params24 = ext2.best_params_\n",
    "# best_params25 = ada2.best_params_\n",
    "# best_params26 = lgb2.best_params_\n",
    "\n",
    "xgb2 = XGBClassifier(**best_params21)\n",
    "log2 = LogisticRegression(**best_params22)\n",
    "rnf2 = RandomForestClassifier(**best_params23)\n",
    "ext2 = ExtraTreesClassifier(**best_params24)\n",
    "ada2 = AdaBoostClassifier(**best_params25)\n",
    "lgb2 = LGBMClassifier(**best_params26)\n",
    "\n",
    "# xgb2.fit(xx_all,y)\n",
    "# log2.fit(xx_all,y)\n",
    "# rnf2.fit(xx_all,y)\n",
    "# ext2.fit(xx_all,y)\n",
    "# ada2.fit(xx_all,y)\n",
    "# lgb2.fit(xx_all,y)\n",
    "xgb2.fit(xx,y_sm)\n",
    "log2.fit(xx,y_sm)\n",
    "rnf2.fit(xx,y_sm)\n",
    "ext2.fit(xx,y_sm)\n",
    "ada2.fit(xx,y_sm)\n",
    "lgb2.fit(xx,y_sm)\n",
    "    \n",
    "    \n",
    "vote_list = [('xgb2', xgb2), ('log2', log2), ('rnf2', rnf2), ('ext2', ext2), ('ada2', ada2), ('lgb2', lgb2)]\n",
    "vote2 =  (estimators=vote_list, voting='soft')\n",
    "# vote2.fit(xx_all, y)\n",
    "vote2.fit(xx, y_sm)\n",
    "auc_score(vote2,xx_val,y_val,xx_train,y_train,'vote2')\n",
    "# auc_score(xgb2,xx_val,y_val,xx_train,y_train,'xgb2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote2.predict_proba(xx_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## ans #################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(param, dx, num_round, evallist, evals_result=evals_result,early_stopping_rounds=10)\n",
    "sv = model2.predict(x_ans)\n",
    "np.savetxt(\"test30.csv\", sv, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dans = xgb.DMatrix(x_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sv = np.array(bst.predict(dans, ntree_limit=treee)) _proba\n",
    "# sv = vote2.predict_proba(xx_ans)[:,1]\n",
    "\n",
    "# sv[sv < 0] = 0\n",
    "# sv[sv > 1] = 1\n",
    "# sv = np.array(bst2.predict(dans, ntree_limit=treee))\n",
    "\n",
    "# np.savetxt(\"TJ2018-AUDITION-[11011].c.csv\", sv, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.predict(xx_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"test000000.csv\", np.zeros(10000), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normalised_Last1_Month_FQ</th>\n",
       "      <th>Normalised_Last1_Month_max</th>\n",
       "      <th>Normalised_Last1_Month_median</th>\n",
       "      <th>Normalised_Last1_Month_min</th>\n",
       "      <th>Normalised_Last1_Month_STD</th>\n",
       "      <th>Normalised_Last1_Month_Sum</th>\n",
       "      <th>Normalised_Last2_Month_FQ</th>\n",
       "      <th>Normalised_Last2_Month_max</th>\n",
       "      <th>Normalised_Last2_Month_median</th>\n",
       "      <th>Normalised_Last2_Month_min</th>\n",
       "      <th>...</th>\n",
       "      <th>New_SmartTile_Name2</th>\n",
       "      <th>New_SmartTile_Name3</th>\n",
       "      <th>New_SmartTile_Name4</th>\n",
       "      <th>New_SmartTile_Name5</th>\n",
       "      <th>New_SmartTile_Name6</th>\n",
       "      <th>New_SmartTile_Name7</th>\n",
       "      <th>New_SmartTile_Name8</th>\n",
       "      <th>New_SmartTile_Name9</th>\n",
       "      <th>New_SmartTile_Name9_2</th>\n",
       "      <th>New_SmartTile_Name9_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.012926</td>\n",
       "      <td>0.014394</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.003563</td>\n",
       "      <td>0.003698</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.017270</td>\n",
       "      <td>0.011458</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>High (3.3e+06 to 2.275e+07)Text</td>\n",
       "      <td>High (3.35e+06 to 2.3e+07)Text</td>\n",
       "      <td>High (3.35e+06 to 2.2e+07)Text</td>\n",
       "      <td>High (3.15e+06 to 2.1e+07)Text</td>\n",
       "      <td>Above Average (41500 to 106250)Text</td>\n",
       "      <td>Average (16250 to 42000)Text</td>\n",
       "      <td>Above Average (42000 to 105000)Text</td>\n",
       "      <td>Above Average (42000 to 107500)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9761</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.022595</td>\n",
       "      <td>0.014405</td>\n",
       "      <td>0.018463</td>\n",
       "      <td>0.035338</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.018798</td>\n",
       "      <td>0.016256</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Above Average (485000 to 3.3e+06)Text</td>\n",
       "      <td>Above Average (485000 to 3.35e+06)Text</td>\n",
       "      <td>Above Average (500000 to 3.35e+06)Text</td>\n",
       "      <td>Above Average (475000 to 3.15e+06)Text</td>\n",
       "      <td>High (106250 to 270000)Text</td>\n",
       "      <td>Average (16250 to 42000)Text</td>\n",
       "      <td>Above Average (42000 to 105000)Text</td>\n",
       "      <td>Above Average (42000 to 107500)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3904</th>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>0.012984</td>\n",
       "      <td>0.013073</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.017893</td>\n",
       "      <td>0.012229</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Above Average (485000 to 3.3e+06)Text</td>\n",
       "      <td>Above Average (485000 to 3.35e+06)Text</td>\n",
       "      <td>Above Average (500000 to 3.35e+06)Text</td>\n",
       "      <td>Above Average (475000 to 3.15e+06)Text</td>\n",
       "      <td>Below Average (6300 to 16250)Text</td>\n",
       "      <td>Average (16250 to 42000)Text</td>\n",
       "      <td>Average (17000 to 42000)Text</td>\n",
       "      <td>Below Average (6500 to 16500)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.002209</td>\n",
       "      <td>0.024731</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>0.014784</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.013232</td>\n",
       "      <td>0.019508</td>\n",
       "      <td>0.011752</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>High (3.3e+06 to 2.275e+07)Text</td>\n",
       "      <td>High (3.35e+06 to 2.3e+07)Text</td>\n",
       "      <td>High (3.35e+06 to 2.2e+07)Text</td>\n",
       "      <td>High (3.15e+06 to 2.1e+07)Text</td>\n",
       "      <td>High (106250 to 270000)Text</td>\n",
       "      <td>High (108750 to 280000)Text</td>\n",
       "      <td>High (105000 to 260000)Text</td>\n",
       "      <td>High (107500 to 275000)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4141</th>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.013081</td>\n",
       "      <td>0.012573</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.017375</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>High (3.3e+06 to 2.275e+07)Text</td>\n",
       "      <td>High (3.35e+06 to 2.3e+07)Text</td>\n",
       "      <td>High (3.35e+06 to 2.2e+07)Text</td>\n",
       "      <td>High (3.15e+06 to 2.1e+07)Text</td>\n",
       "      <td>Below Average (6300 to 16250)Text</td>\n",
       "      <td>Average (16250 to 42000)Text</td>\n",
       "      <td>Below Average (6800 to 17000)Text</td>\n",
       "      <td>Below Average (6500 to 16500)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.024947</td>\n",
       "      <td>0.016115</td>\n",
       "      <td>0.011150</td>\n",
       "      <td>0.018320</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.023088</td>\n",
       "      <td>0.021345</td>\n",
       "      <td>0.013879</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Above Average (485000 to 3.3e+06)Text</td>\n",
       "      <td>Above Average (485000 to 3.35e+06)Text</td>\n",
       "      <td>Above Average (500000 to 3.35e+06)Text</td>\n",
       "      <td>Above Average (475000 to 3.15e+06)Text</td>\n",
       "      <td>High (106250 to 270000)Text</td>\n",
       "      <td>High (108750 to 280000)Text</td>\n",
       "      <td>Above Average (42000 to 105000)Text</td>\n",
       "      <td>High (107500 to 275000)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>0.022736</td>\n",
       "      <td>0.004207</td>\n",
       "      <td>0.012786</td>\n",
       "      <td>0.009738</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.022014</td>\n",
       "      <td>0.023422</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.016982</td>\n",
       "      <td>0.008848</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Extremely High (Above 2.275e+07)Text</td>\n",
       "      <td>Extremely High (Above 2.3e+07)Text</td>\n",
       "      <td>Extremely High (Above 2.2e+07)Text</td>\n",
       "      <td>Extremely High (Above 2.1e+07)Text</td>\n",
       "      <td>Average (16250 to 41500)Text</td>\n",
       "      <td>Average (16250 to 42000)Text</td>\n",
       "      <td>Average (17000 to 42000)Text</td>\n",
       "      <td>Average (16500 to 42000)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.080896</td>\n",
       "      <td>0.037038</td>\n",
       "      <td>0.013170</td>\n",
       "      <td>0.010634</td>\n",
       "      <td>0.007269</td>\n",
       "      <td>0.082502</td>\n",
       "      <td>0.090493</td>\n",
       "      <td>0.100947</td>\n",
       "      <td>0.017471</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Extremely High (Above 2.275e+07)Text</td>\n",
       "      <td>Extremely High (Above 2.3e+07)Text</td>\n",
       "      <td>Extremely High (Above 2.2e+07)Text</td>\n",
       "      <td>Extremely High (Above 2.1e+07)Text</td>\n",
       "      <td>High (106250 to 270000)Text</td>\n",
       "      <td>Extremely High (Above 280000)Text</td>\n",
       "      <td>Extremely High (Above 260000)Text</td>\n",
       "      <td>Extremely High (Above 275000)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966</th>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.003044</td>\n",
       "      <td>0.012997</td>\n",
       "      <td>0.010050</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.017274</td>\n",
       "      <td>0.009729</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>High (3.3e+06 to 2.275e+07)Text</td>\n",
       "      <td>High (3.35e+06 to 2.3e+07)Text</td>\n",
       "      <td>High (3.35e+06 to 2.2e+07)Text</td>\n",
       "      <td>High (3.15e+06 to 2.1e+07)Text</td>\n",
       "      <td>Below Average (6300 to 16250)Text</td>\n",
       "      <td>Below Average (6200 to 16250)Text</td>\n",
       "      <td>Below Average (6800 to 17000)Text</td>\n",
       "      <td>Below Average (6500 to 16500)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9508</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.015199</td>\n",
       "      <td>0.018346</td>\n",
       "      <td>0.019555</td>\n",
       "      <td>0.016149</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.004617</td>\n",
       "      <td>0.026404</td>\n",
       "      <td>0.016328</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Above Average (485000 to 3.3e+06)Text</td>\n",
       "      <td>Above Average (485000 to 3.35e+06)Text</td>\n",
       "      <td>Above Average (500000 to 3.35e+06)Text</td>\n",
       "      <td>Above Average (475000 to 3.15e+06)Text</td>\n",
       "      <td>Above Average (41500 to 106250)Text</td>\n",
       "      <td>Average (16250 to 42000)Text</td>\n",
       "      <td>Above Average (42000 to 105000)Text</td>\n",
       "      <td>Average (16500 to 42000)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.014098</td>\n",
       "      <td>0.029326</td>\n",
       "      <td>0.026315</td>\n",
       "      <td>0.024799</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.005730</td>\n",
       "      <td>0.031815</td>\n",
       "      <td>0.024732</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Average (71000 to 485000)Text</td>\n",
       "      <td>Average (71000 to 485000)Text</td>\n",
       "      <td>Average (76000 to 500000)Text</td>\n",
       "      <td>Average (71000 to 475000)Text</td>\n",
       "      <td>Above Average (41500 to 106250)Text</td>\n",
       "      <td>Above Average (42000 to 108750)Text</td>\n",
       "      <td>Above Average (42000 to 105000)Text</td>\n",
       "      <td>Above Average (42000 to 107500)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5737</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Below Average (11500 to 76000)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Average (17000 to 42000)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.034008</td>\n",
       "      <td>0.054089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Below Average (10375 to 71000)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Below Average (11500 to 76000)Text</td>\n",
       "      <td>Below Average (10750 to 71000)Text</td>\n",
       "      <td>Average (16250 to 41500)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Average (17000 to 42000)Text</td>\n",
       "      <td>Average (16500 to 42000)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3815</th>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.017837</td>\n",
       "      <td>0.012265</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Above Average (485000 to 3.3e+06)Text</td>\n",
       "      <td>Above Average (485000 to 3.35e+06)Text</td>\n",
       "      <td>Above Average (500000 to 3.35e+06)Text</td>\n",
       "      <td>Above Average (475000 to 3.15e+06)Text</td>\n",
       "      <td>Below Average (6300 to 16250)Text</td>\n",
       "      <td>Below Average (6200 to 16250)Text</td>\n",
       "      <td>Average (17000 to 42000)Text</td>\n",
       "      <td>Below Average (6500 to 16500)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.060152</td>\n",
       "      <td>0.031644</td>\n",
       "      <td>0.021879</td>\n",
       "      <td>0.102859</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.021811</td>\n",
       "      <td>0.039340</td>\n",
       "      <td>0.022560</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Above Average (485000 to 3.3e+06)Text</td>\n",
       "      <td>Above Average (485000 to 3.35e+06)Text</td>\n",
       "      <td>Average (76000 to 500000)Text</td>\n",
       "      <td>Above Average (475000 to 3.15e+06)Text</td>\n",
       "      <td>Extremely High (Above 270000)Text</td>\n",
       "      <td>High (108750 to 280000)Text</td>\n",
       "      <td>Average (17000 to 42000)Text</td>\n",
       "      <td>Above Average (42000 to 107500)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.011768</td>\n",
       "      <td>0.054232</td>\n",
       "      <td>0.044180</td>\n",
       "      <td>0.032975</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.050216</td>\n",
       "      <td>0.050216</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Average (71000 to 485000)Text</td>\n",
       "      <td>Below Average (10250 to 71000)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Average (71000 to 475000)Text</td>\n",
       "      <td>Above Average (41500 to 106250)Text</td>\n",
       "      <td>Average (16250 to 42000)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Above Average (42000 to 107500)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>0.017840</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.018503</td>\n",
       "      <td>0.014170</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Above Average (485000 to 3.3e+06)Text</td>\n",
       "      <td>Above Average (485000 to 3.35e+06)Text</td>\n",
       "      <td>Above Average (500000 to 3.35e+06)Text</td>\n",
       "      <td>Above Average (475000 to 3.15e+06)Text</td>\n",
       "      <td>Average (16250 to 41500)Text</td>\n",
       "      <td>Average (16250 to 42000)Text</td>\n",
       "      <td>Average (17000 to 42000)Text</td>\n",
       "      <td>Average (16500 to 42000)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.008213</td>\n",
       "      <td>0.014392</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.003485</td>\n",
       "      <td>0.019286</td>\n",
       "      <td>0.014039</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Above Average (485000 to 3.3e+06)Text</td>\n",
       "      <td>Above Average (485000 to 3.35e+06)Text</td>\n",
       "      <td>Above Average (500000 to 3.35e+06)Text</td>\n",
       "      <td>Above Average (475000 to 3.15e+06)Text</td>\n",
       "      <td>Above Average (41500 to 106250)Text</td>\n",
       "      <td>Average (16250 to 42000)Text</td>\n",
       "      <td>Average (17000 to 42000)Text</td>\n",
       "      <td>Above Average (42000 to 107500)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.051785</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.018896</td>\n",
       "      <td>0.109428</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.042104</td>\n",
       "      <td>0.018444</td>\n",
       "      <td>0.014613</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Above Average (485000 to 3.3e+06)Text</td>\n",
       "      <td>Above Average (485000 to 3.35e+06)Text</td>\n",
       "      <td>Above Average (500000 to 3.35e+06)Text</td>\n",
       "      <td>Average (71000 to 475000)Text</td>\n",
       "      <td>High (106250 to 270000)Text</td>\n",
       "      <td>Extremely High (Above 280000)Text</td>\n",
       "      <td>High (105000 to 260000)Text</td>\n",
       "      <td>High (107500 to 275000)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4089</th>\n",
       "      <td>0.002580</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>0.012802</td>\n",
       "      <td>0.012740</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>0.017039</td>\n",
       "      <td>0.010020</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>High (3.3e+06 to 2.275e+07)Text</td>\n",
       "      <td>High (3.35e+06 to 2.3e+07)Text</td>\n",
       "      <td>High (3.35e+06 to 2.2e+07)Text</td>\n",
       "      <td>High (3.15e+06 to 2.1e+07)Text</td>\n",
       "      <td>Below Average (6300 to 16250)Text</td>\n",
       "      <td>Below Average (6200 to 16250)Text</td>\n",
       "      <td>Below Average (6800 to 17000)Text</td>\n",
       "      <td>Below Average (6500 to 16500)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5141</th>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Below Average (10375 to 71000)Text</td>\n",
       "      <td>Average (71000 to 485000)Text</td>\n",
       "      <td>Average (76000 to 500000)Text</td>\n",
       "      <td>Below Average (10750 to 71000)Text</td>\n",
       "      <td>Below Average (6300 to 16250)Text</td>\n",
       "      <td>Below Average (6200 to 16250)Text</td>\n",
       "      <td>Average (17000 to 42000)Text</td>\n",
       "      <td>Below Average (6500 to 16500)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5507</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.003856</td>\n",
       "      <td>0.019220</td>\n",
       "      <td>0.021619</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>0.018696</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Average (71000 to 485000)Text</td>\n",
       "      <td>Average (71000 to 485000)Text</td>\n",
       "      <td>Above Average (500000 to 3.35e+06)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Average (16250 to 41500)Text</td>\n",
       "      <td>Average (16250 to 42000)Text</td>\n",
       "      <td>Average (17000 to 42000)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.004433</td>\n",
       "      <td>0.012594</td>\n",
       "      <td>0.014136</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.012433</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>High (3.3e+06 to 2.275e+07)Text</td>\n",
       "      <td>High (3.35e+06 to 2.3e+07)Text</td>\n",
       "      <td>High (3.35e+06 to 2.2e+07)Text</td>\n",
       "      <td>Above Average (475000 to 3.15e+06)Text</td>\n",
       "      <td>Average (16250 to 41500)Text</td>\n",
       "      <td>Below Average (6200 to 16250)Text</td>\n",
       "      <td>Average (17000 to 42000)Text</td>\n",
       "      <td>Below Average (6500 to 16500)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.175059</td>\n",
       "      <td>0.332958</td>\n",
       "      <td>0.016471</td>\n",
       "      <td>0.519049</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.101102</td>\n",
       "      <td>0.672130</td>\n",
       "      <td>0.022529</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>High (3.3e+06 to 2.275e+07)Text</td>\n",
       "      <td>High (3.35e+06 to 2.3e+07)Text</td>\n",
       "      <td>High (3.35e+06 to 2.2e+07)Text</td>\n",
       "      <td>High (3.15e+06 to 2.1e+07)Text</td>\n",
       "      <td>Extremely High (Above 270000)Text</td>\n",
       "      <td>Extremely High (Above 280000)Text</td>\n",
       "      <td>Extremely High (Above 260000)Text</td>\n",
       "      <td>Extremely High (Above 275000)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.004041</td>\n",
       "      <td>0.015141</td>\n",
       "      <td>0.017591</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.003462</td>\n",
       "      <td>0.020691</td>\n",
       "      <td>0.015487</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Average (71000 to 485000)Text</td>\n",
       "      <td>Average (71000 to 485000)Text</td>\n",
       "      <td>Above Average (500000 to 3.35e+06)Text</td>\n",
       "      <td>Average (71000 to 475000)Text</td>\n",
       "      <td>Average (16250 to 41500)Text</td>\n",
       "      <td>Average (16250 to 42000)Text</td>\n",
       "      <td>Average (17000 to 42000)Text</td>\n",
       "      <td>Average (16500 to 42000)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.082280</td>\n",
       "      <td>0.049971</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.011254</td>\n",
       "      <td>0.007971</td>\n",
       "      <td>0.093176</td>\n",
       "      <td>0.105042</td>\n",
       "      <td>0.072794</td>\n",
       "      <td>0.019159</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Extremely High (Above 2.275e+07)Text</td>\n",
       "      <td>Extremely High (Above 2.3e+07)Text</td>\n",
       "      <td>Extremely High (Above 2.2e+07)Text</td>\n",
       "      <td>Extremely High (Above 2.1e+07)Text</td>\n",
       "      <td>High (106250 to 270000)Text</td>\n",
       "      <td>Extremely High (Above 280000)Text</td>\n",
       "      <td>Extremely High (Above 260000)Text</td>\n",
       "      <td>Extremely High (Above 275000)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4553</th>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.012434</td>\n",
       "      <td>0.016405</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.016732</td>\n",
       "      <td>0.015867</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Average (71000 to 485000)Text</td>\n",
       "      <td>Average (71000 to 485000)Text</td>\n",
       "      <td>Average (76000 to 500000)Text</td>\n",
       "      <td>Average (71000 to 475000)Text</td>\n",
       "      <td>Below Average (6300 to 16250)Text</td>\n",
       "      <td>Below Average (6200 to 16250)Text</td>\n",
       "      <td>Below Average (6800 to 17000)Text</td>\n",
       "      <td>Below Average (6500 to 16500)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5767</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>...</td>\n",
       "      <td>Above Average (-1850 to 780)Text</td>\n",
       "      <td>Below Average (-750 to 1900)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Below Average (10250 to 71000)Text</td>\n",
       "      <td>Below Average (11500 to 76000)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Average (16250 to 42000)Text</td>\n",
       "      <td>Average (17000 to 42000)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6651</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.025131</td>\n",
       "      <td>0.039969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Below Average (10375 to 71000)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Average (16250 to 41500)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5958</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Below Average (11500 to 76000)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Below Average (6800 to 17000)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6877</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>0.029390</td>\n",
       "      <td>0.029390</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Below Average (10250 to 71000)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Average (71000 to 475000)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Average (16250 to 42000)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Above Average (42000 to 107500)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6899</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6890</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6581</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.005754</td>\n",
       "      <td>0.036521</td>\n",
       "      <td>0.037992</td>\n",
       "      <td>0.009502</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Average (71000 to 485000)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Average (16250 to 41500)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6880</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6878</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.012569</td>\n",
       "      <td>0.080763</td>\n",
       "      <td>0.128449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Below Average (10375 to 71000)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Below Average (11500 to 76000)Text</td>\n",
       "      <td>Below Average (10750 to 71000)Text</td>\n",
       "      <td>Above Average (41500 to 106250)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Average (17000 to 42000)Text</td>\n",
       "      <td>Above Average (42000 to 107500)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.004930</td>\n",
       "      <td>0.021884</td>\n",
       "      <td>0.029368</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>0.032060</td>\n",
       "      <td>0.024017</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Average (71000 to 485000)Text</td>\n",
       "      <td>Average (71000 to 485000)Text</td>\n",
       "      <td>Average (76000 to 500000)Text</td>\n",
       "      <td>Average (71000 to 475000)Text</td>\n",
       "      <td>Average (16250 to 41500)Text</td>\n",
       "      <td>Above Average (42000 to 108750)Text</td>\n",
       "      <td>Average (17000 to 42000)Text</td>\n",
       "      <td>Average (16500 to 42000)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6907</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5450</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Below Average (11500 to 76000)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Above Average (42000 to 105000)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6876</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6875</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2817</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Below Average (10750 to 71000)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Average (16500 to 42000)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6191</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.005591</td>\n",
       "      <td>0.035922</td>\n",
       "      <td>0.057132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>0.050383</td>\n",
       "      <td>0.050383</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Below Average (10375 to 71000)Text</td>\n",
       "      <td>Below Average (10250 to 71000)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Average (16250 to 41500)Text</td>\n",
       "      <td>Average (16250 to 42000)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.032271</td>\n",
       "      <td>0.031272</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Below Average (10250 to 71000)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Below Average (10750 to 71000)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Average (16250 to 42000)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Average (16500 to 42000)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5491</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.005690</td>\n",
       "      <td>0.036559</td>\n",
       "      <td>0.058145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Below Average (10375 to 71000)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Below Average (11500 to 76000)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Average (16250 to 41500)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Average (17000 to 42000)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5813</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>0.020578</td>\n",
       "      <td>0.031821</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.027845</td>\n",
       "      <td>0.026480</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Below Average (10375 to 71000)Text</td>\n",
       "      <td>Below Average (10250 to 71000)Text</td>\n",
       "      <td>Below Average (11500 to 76000)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Average (16250 to 41500)Text</td>\n",
       "      <td>Average (16250 to 42000)Text</td>\n",
       "      <td>Below Average (6800 to 17000)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>0.046145</td>\n",
       "      <td>0.045652</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Below Average (10250 to 71000)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Average (16250 to 42000)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.030941</td>\n",
       "      <td>0.040551</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>0.046237</td>\n",
       "      <td>0.031790</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Below Average (10375 to 71000)Text</td>\n",
       "      <td>Below Average (10250 to 71000)Text</td>\n",
       "      <td>Average (76000 to 500000)Text</td>\n",
       "      <td>Below Average (10750 to 71000)Text</td>\n",
       "      <td>Average (16250 to 41500)Text</td>\n",
       "      <td>Average (16250 to 42000)Text</td>\n",
       "      <td>Above Average (42000 to 105000)Text</td>\n",
       "      <td>Average (16500 to 42000)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.029616</td>\n",
       "      <td>0.014738</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>0.052068</td>\n",
       "      <td>0.028556</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Average (71000 to 485000)Text</td>\n",
       "      <td>Average (71000 to 485000)Text</td>\n",
       "      <td>Average (76000 to 500000)Text</td>\n",
       "      <td>Average (71000 to 475000)Text</td>\n",
       "      <td>Above Average (41500 to 106250)Text</td>\n",
       "      <td>Above Average (42000 to 108750)Text</td>\n",
       "      <td>Average (17000 to 42000)Text</td>\n",
       "      <td>Above Average (42000 to 107500)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6538</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.008083</td>\n",
       "      <td>0.036178</td>\n",
       "      <td>0.042563</td>\n",
       "      <td>0.013235</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Average (71000 to 485000)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Above Average (41500 to 106250)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6872</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6874</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6873</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6879</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Extremely Low (Below 1525)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Extremely Low (Below 2475)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6506</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.018178</td>\n",
       "      <td>0.084513</td>\n",
       "      <td>0.131081</td>\n",
       "      <td>0.021138</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Average (71000 to 485000)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Above Average (41500 to 106250)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6854</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.010612</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Low (-9700 to -7100)Text</td>\n",
       "      <td>High (7200 to 9800)Text</td>\n",
       "      <td>Low (1525 to 10375)Text</td>\n",
       "      <td>Extremely Low (Below 1500)Text</td>\n",
       "      <td>Extremely Low (Below 1725)Text</td>\n",
       "      <td>Extremely Low (Below 1625)Text</td>\n",
       "      <td>Below Average (6300 to 16250)Text</td>\n",
       "      <td>Extremely Low (Below 2400)Text</td>\n",
       "      <td>Extremely Low (Below 2700)Text</td>\n",
       "      <td>Extremely Low (Below 2550)Text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows  83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Normalised_Last1_Month_FQ  Normalised_Last1_Month_max  \\\n",
       "1213                   0.003588                    0.009777   \n",
       "9761                   0.000000                    0.000000   \n",
       "564                    0.000153                    0.022595   \n",
       "3904                   0.000432                    0.002827   \n",
       "310                    0.002209                    0.024731   \n",
       "4141                   0.003243                    0.002728   \n",
       "199                    0.000615                    0.024947   \n",
       "2375                   0.022736                    0.004207   \n",
       "16                     0.080896                    0.037038   \n",
       "3966                   0.003444                    0.003044   \n",
       "9508                   0.000000                    0.000000   \n",
       "1328                   0.000419                    0.015199   \n",
       "1126                   0.000061                    0.014098   \n",
       "5737                   0.000000                    0.000000   \n",
       "3283                   0.000004                    0.005293   \n",
       "3815                   0.000716                    0.003124   \n",
       "856                    0.000087                    0.060152   \n",
       "613                    0.000017                    0.011768   \n",
       "2523                   0.000362                    0.004165   \n",
       "1059                   0.000733                    0.008213   \n",
       "139                    0.000105                    0.051785   \n",
       "4089                   0.002580                    0.002904   \n",
       "5141                   0.000092                    0.002117   \n",
       "5507                   0.000026                    0.003856   \n",
       "3788                   0.001445                    0.004433   \n",
       "9                      0.000070                    0.175059   \n",
       "2157                   0.000148                    0.004041   \n",
       "1                      0.082280                    0.049971   \n",
       "4553                   0.000048                    0.002089   \n",
       "5767                   0.000000                    0.000000   \n",
       "...                         ...                         ...   \n",
       "6651                   0.000004                    0.003911   \n",
       "5958                   0.000000                    0.000000   \n",
       "6877                   0.000000                    0.000000   \n",
       "654                    0.000000                    0.000000   \n",
       "6899                   0.000000                    0.000000   \n",
       "6890                   0.000000                    0.000000   \n",
       "6581                   0.000013                    0.005754   \n",
       "6880                   0.000000                    0.000000   \n",
       "6878                   0.000000                    0.000000   \n",
       "1044                   0.000004                    0.012569   \n",
       "1583                   0.000052                    0.004930   \n",
       "6907                   0.000000                    0.000000   \n",
       "5450                   0.000000                    0.000000   \n",
       "6876                   0.000000                    0.000000   \n",
       "6875                   0.000000                    0.000000   \n",
       "2817                   0.000000                    0.000000   \n",
       "6191                   0.000004                    0.005591   \n",
       "1944                   0.000000                    0.000000   \n",
       "5491                   0.000004                    0.005690   \n",
       "5813                   0.000009                    0.003291   \n",
       "6220                   0.000000                    0.000000   \n",
       "2245                   0.000013                    0.004831   \n",
       "1234                   0.000039                    0.008151   \n",
       "6538                   0.000022                    0.008083   \n",
       "6872                   0.000000                    0.000000   \n",
       "6874                   0.000000                    0.000000   \n",
       "6873                   0.000000                    0.000000   \n",
       "6879                   0.000000                    0.000000   \n",
       "6506                   0.000017                    0.018178   \n",
       "6854                   0.000004                    0.001652   \n",
       "\n",
       "      Normalised_Last1_Month_median  Normalised_Last1_Month_min  \\\n",
       "1213                       0.012926                    0.014394   \n",
       "9761                       0.000000                    0.000000   \n",
       "564                        0.014405                    0.018463   \n",
       "3904                       0.012984                    0.013073   \n",
       "310                        0.014444                    0.014784   \n",
       "4141                       0.013081                    0.012573   \n",
       "199                        0.016115                    0.011150   \n",
       "2375                       0.012786                    0.009738   \n",
       "16                         0.013170                    0.010634   \n",
       "3966                       0.012997                    0.010050   \n",
       "9508                       0.000000                    0.000000   \n",
       "1328                       0.018346                    0.019555   \n",
       "1126                       0.029326                    0.026315   \n",
       "5737                       0.000000                    0.000000   \n",
       "3283                       0.034008                    0.054089   \n",
       "3815                       0.013502                    0.016377   \n",
       "856                        0.031644                    0.021879   \n",
       "613                        0.054232                    0.044180   \n",
       "2523                       0.014583                    0.017840   \n",
       "1059                       0.014392                    0.016758   \n",
       "139                        0.013700                    0.018896   \n",
       "4089                       0.012802                    0.012740   \n",
       "5141                       0.002220                    0.001239   \n",
       "5507                       0.019220                    0.021619   \n",
       "3788                       0.012594                    0.014136   \n",
       "9                          0.332958                    0.016471   \n",
       "2157                       0.015141                    0.017591   \n",
       "1                          0.014426                    0.011254   \n",
       "4553                       0.012434                    0.016405   \n",
       "5767                       0.000000                    0.000000   \n",
       "...                             ...                         ...   \n",
       "6651                       0.025131                    0.039969   \n",
       "5958                       0.000000                    0.000000   \n",
       "6877                       0.000000                    0.000000   \n",
       "654                        0.000000                    0.000000   \n",
       "6899                       0.000000                    0.000000   \n",
       "6890                       0.000000                    0.000000   \n",
       "6581                       0.036521                    0.037992   \n",
       "6880                       0.000000                    0.000000   \n",
       "6878                       0.000000                    0.000000   \n",
       "1044                       0.080763                    0.128449   \n",
       "1583                       0.021884                    0.029368   \n",
       "6907                       0.000000                    0.000000   \n",
       "5450                       0.000000                    0.000000   \n",
       "6876                       0.000000                    0.000000   \n",
       "6875                       0.000000                    0.000000   \n",
       "2817                       0.000000                    0.000000   \n",
       "6191                       0.035922                    0.057132   \n",
       "1944                       0.000000                    0.000000   \n",
       "5491                       0.036559                    0.058145   \n",
       "5813                       0.020578                    0.031821   \n",
       "6220                       0.000000                    0.000000   \n",
       "2245                       0.030941                    0.040551   \n",
       "1234                       0.040268                    0.029616   \n",
       "6538                       0.036178                    0.042563   \n",
       "6872                       0.000000                    0.000000   \n",
       "6874                       0.000000                    0.000000   \n",
       "6873                       0.000000                    0.000000   \n",
       "6879                       0.000000                    0.000000   \n",
       "6506                       0.084513                    0.131081   \n",
       "6854                       0.010612                    0.016878   \n",
       "\n",
       "      Normalised_Last1_Month_STD  Normalised_Last1_Month_Sum  \\\n",
       "1213                    0.003242                    0.003563   \n",
       "9761                    0.000000                    0.000000   \n",
       "564                     0.035338                    0.000276   \n",
       "3904                    0.002113                    0.000427   \n",
       "310                     0.015968                    0.002984   \n",
       "4141                    0.001554                    0.003169   \n",
       "199                     0.018320                    0.000895   \n",
       "2375                    0.001908                    0.022014   \n",
       "16                      0.007269                    0.082502   \n",
       "3966                    0.001647                    0.003364   \n",
       "9508                    0.000000                    0.000000   \n",
       "1328                    0.016149                    0.000664   \n",
       "1126                    0.024799                    0.000158   \n",
       "5737                    0.000000                    0.000000   \n",
       "3283                    0.000000                    0.000011   \n",
       "3815                    0.002176                    0.000743   \n",
       "856                     0.102859                    0.000373   \n",
       "613                     0.032975                    0.000069   \n",
       "2523                    0.003687                    0.000416   \n",
       "1059                    0.005630                    0.000838   \n",
       "139                     0.109428                    0.000342   \n",
       "4089                    0.001583                    0.002479   \n",
       "5141                    0.004432                    0.000025   \n",
       "5507                    0.005787                    0.000038   \n",
       "3788                    0.001985                    0.001371   \n",
       "9                       0.519049                    0.002101   \n",
       "2157                    0.004386                    0.000178   \n",
       "1                       0.007971                    0.093176   \n",
       "4553                    0.001075                    0.000044   \n",
       "5767                    0.000000                    0.000000   \n",
       "...                          ...                         ...   \n",
       "6651                    0.000000                    0.000008   \n",
       "5958                    0.000000                    0.000000   \n",
       "6877                    0.000000                    0.000000   \n",
       "654                     0.000000                    0.000000   \n",
       "6899                    0.000000                    0.000000   \n",
       "6890                    0.000000                    0.000000   \n",
       "6581                    0.009502                    0.000032   \n",
       "6880                    0.000000                    0.000000   \n",
       "6878                    0.000000                    0.000000   \n",
       "1044                    0.000000                    0.000026   \n",
       "1583                    0.004748                    0.000089   \n",
       "6907                    0.000000                    0.000000   \n",
       "5450                    0.000000                    0.000000   \n",
       "6876                    0.000000                    0.000000   \n",
       "6875                    0.000000                    0.000000   \n",
       "2817                    0.000000                    0.000000   \n",
       "6191                    0.000000                    0.000012   \n",
       "1944                    0.000000                    0.000000   \n",
       "5491                    0.000000                    0.000012   \n",
       "5813                    0.001032                    0.000013   \n",
       "6220                    0.000000                    0.000000   \n",
       "2245                    0.004059                    0.000029   \n",
       "1234                    0.014738                    0.000117   \n",
       "6538                    0.013235                    0.000059   \n",
       "6872                    0.000000                    0.000000   \n",
       "6874                    0.000000                    0.000000   \n",
       "6873                    0.000000                    0.000000   \n",
       "6879                    0.000000                    0.000000   \n",
       "6506                    0.021138                    0.000120   \n",
       "6854                    0.000000                    0.000003   \n",
       "\n",
       "      Normalised_Last2_Month_FQ  Normalised_Last2_Month_max  \\\n",
       "1213                   0.003698                    0.002817   \n",
       "9761                   0.000000                    0.000000   \n",
       "564                    0.000252                    0.002214   \n",
       "3904                   0.000481                    0.003042   \n",
       "310                    0.002004                    0.013232   \n",
       "4141                   0.003803                    0.001900   \n",
       "199                    0.000645                    0.023088   \n",
       "2375                   0.023422                    0.002410   \n",
       "16                     0.090493                    0.100947   \n",
       "3966                   0.003917                    0.001646   \n",
       "9508                   0.000000                    0.000000   \n",
       "1328                   0.000384                    0.004617   \n",
       "1126                   0.000027                    0.005730   \n",
       "5737                   0.000000                    0.000000   \n",
       "3283                   0.000000                    0.000000   \n",
       "3815                   0.000636                    0.001709   \n",
       "856                    0.000096                    0.021811   \n",
       "613                    0.000005                    0.003400   \n",
       "2523                   0.000311                    0.002683   \n",
       "1059                   0.000696                    0.003485   \n",
       "139                    0.000128                    0.042104   \n",
       "4089                   0.002412                    0.001719   \n",
       "5141                   0.000178                    0.001111   \n",
       "5507                   0.000027                    0.002066   \n",
       "3788                   0.001620                    0.001777   \n",
       "9                      0.000073                    0.101102   \n",
       "2157                   0.000137                    0.003462   \n",
       "1                      0.105042                    0.072794   \n",
       "4553                   0.000032                    0.001193   \n",
       "5767                   0.000005                    0.002295   \n",
       "...                         ...                         ...   \n",
       "6651                   0.000000                    0.000000   \n",
       "5958                   0.000000                    0.000000   \n",
       "6877                   0.000000                    0.000000   \n",
       "654                    0.000005                    0.001990   \n",
       "6899                   0.000000                    0.000000   \n",
       "6890                   0.000000                    0.000000   \n",
       "6581                   0.000000                    0.000000   \n",
       "6880                   0.000000                    0.000000   \n",
       "6878                   0.000000                    0.000000   \n",
       "1044                   0.000000                    0.000000   \n",
       "1583                   0.000073                    0.004750   \n",
       "6907                   0.000000                    0.000000   \n",
       "5450                   0.000000                    0.000000   \n",
       "6876                   0.000000                    0.000000   \n",
       "6875                   0.000000                    0.000000   \n",
       "2817                   0.000000                    0.000000   \n",
       "6191                   0.000005                    0.003411   \n",
       "1944                   0.000009                    0.002252   \n",
       "5491                   0.000000                    0.000000   \n",
       "5813                   0.000009                    0.001978   \n",
       "6220                   0.000009                    0.003157   \n",
       "2245                   0.000009                    0.004108   \n",
       "1234                   0.000055                    0.004999   \n",
       "6538                   0.000000                    0.000000   \n",
       "6872                   0.000000                    0.000000   \n",
       "6874                   0.000000                    0.000000   \n",
       "6873                   0.000000                    0.000000   \n",
       "6879                   0.000000                    0.000000   \n",
       "6506                   0.000000                    0.000000   \n",
       "6854                   0.000000                    0.000000   \n",
       "\n",
       "      Normalised_Last2_Month_median  Normalised_Last2_Month_min  \\\n",
       "1213                       0.017270                    0.011458   \n",
       "9761                       0.000000                    0.000000   \n",
       "564                        0.018798                    0.016256   \n",
       "3904                       0.017893                    0.012229   \n",
       "310                        0.019508                    0.011752   \n",
       "4141                       0.017375                    0.008906   \n",
       "199                        0.021345                    0.013879   \n",
       "2375                       0.016982                    0.008848   \n",
       "16                         0.017471                    0.007126   \n",
       "3966                       0.017274                    0.009729   \n",
       "9508                       0.000000                    0.000000   \n",
       "1328                       0.026404                    0.016328   \n",
       "1126                       0.031815                    0.024732   \n",
       "5737                       0.000000                    0.000000   \n",
       "3283                       0.000000                    0.000000   \n",
       "3815                       0.017837                    0.012265   \n",
       "856                        0.039340                    0.022560   \n",
       "613                        0.050216                    0.050216   \n",
       "2523                       0.018503                    0.014170   \n",
       "1059                       0.019286                    0.014039   \n",
       "139                        0.018444                    0.014613   \n",
       "4089                       0.017039                    0.010020   \n",
       "5141                       0.002626                    0.000985   \n",
       "5507                       0.022259                    0.018696   \n",
       "3788                       0.016600                    0.012433   \n",
       "9                          0.672130                    0.022529   \n",
       "2157                       0.020691                    0.015487   \n",
       "1                          0.019159                    0.007963   \n",
       "4553                       0.016732                    0.015867   \n",
       "5767                       0.033898                    0.033898   \n",
       "...                             ...                         ...   \n",
       "6651                       0.000000                    0.000000   \n",
       "5958                       0.000000                    0.000000   \n",
       "6877                       0.000000                    0.000000   \n",
       "654                        0.029390                    0.029390   \n",
       "6899                       0.000000                    0.000000   \n",
       "6890                       0.000000                    0.000000   \n",
       "6581                       0.000000                    0.000000   \n",
       "6880                       0.000000                    0.000000   \n",
       "6878                       0.000000                    0.000000   \n",
       "1044                       0.000000                    0.000000   \n",
       "1583                       0.032060                    0.024017   \n",
       "6907                       0.000000                    0.000000   \n",
       "5450                       0.000000                    0.000000   \n",
       "6876                       0.000000                    0.000000   \n",
       "6875                       0.000000                    0.000000   \n",
       "2817                       0.000000                    0.000000   \n",
       "6191                       0.050383                    0.050383   \n",
       "1944                       0.032271                    0.031272   \n",
       "5491                       0.000000                    0.000000   \n",
       "5813                       0.027845                    0.026480   \n",
       "6220                       0.046145                    0.045652   \n",
       "2245                       0.046237                    0.031790   \n",
       "1234                       0.052068                    0.028556   \n",
       "6538                       0.000000                    0.000000   \n",
       "6872                       0.000000                    0.000000   \n",
       "6874                       0.000000                    0.000000   \n",
       "6873                       0.000000                    0.000000   \n",
       "6879                       0.000000                    0.000000   \n",
       "6506                       0.000000                    0.000000   \n",
       "6854                       0.000000                    0.000000   \n",
       "\n",
       "                     ...                                New_SmartTile_Name2  \\\n",
       "1213                 ...                   Above Average (-1850 to 780)Text   \n",
       "9761                 ...                   Above Average (-1850 to 780)Text   \n",
       "564                  ...                   Above Average (-1850 to 780)Text   \n",
       "3904                 ...                   Above Average (-1850 to 780)Text   \n",
       "310                  ...                   Above Average (-1850 to 780)Text   \n",
       "4141                 ...                   Above Average (-1850 to 780)Text   \n",
       "199                  ...                   Above Average (-1850 to 780)Text   \n",
       "2375                 ...                   Above Average (-1850 to 780)Text   \n",
       "16                   ...                   Above Average (-1850 to 780)Text   \n",
       "3966                 ...                   Above Average (-1850 to 780)Text   \n",
       "9508                 ...                   Above Average (-1850 to 780)Text   \n",
       "1328                 ...                   Above Average (-1850 to 780)Text   \n",
       "1126                 ...                   Above Average (-1850 to 780)Text   \n",
       "5737                 ...                   Above Average (-1850 to 780)Text   \n",
       "3283                 ...                   Above Average (-1850 to 780)Text   \n",
       "3815                 ...                   Above Average (-1850 to 780)Text   \n",
       "856                  ...                   Above Average (-1850 to 780)Text   \n",
       "613                  ...                   Above Average (-1850 to 780)Text   \n",
       "2523                 ...                   Above Average (-1850 to 780)Text   \n",
       "1059                 ...                   Above Average (-1850 to 780)Text   \n",
       "139                  ...                   Above Average (-1850 to 780)Text   \n",
       "4089                 ...                   Above Average (-1850 to 780)Text   \n",
       "5141                 ...                   Above Average (-1850 to 780)Text   \n",
       "5507                 ...                   Above Average (-1850 to 780)Text   \n",
       "3788                 ...                   Above Average (-1850 to 780)Text   \n",
       "9                    ...                   Above Average (-1850 to 780)Text   \n",
       "2157                 ...                   Above Average (-1850 to 780)Text   \n",
       "1                    ...                   Above Average (-1850 to 780)Text   \n",
       "4553                 ...                   Above Average (-1850 to 780)Text   \n",
       "5767                 ...                   Above Average (-1850 to 780)Text   \n",
       "...                  ...                                                ...   \n",
       "6651                 ...                           Low (-9700 to -7100)Text   \n",
       "5958                 ...                           Low (-9700 to -7100)Text   \n",
       "6877                 ...                           Low (-9700 to -7100)Text   \n",
       "654                  ...                           Low (-9700 to -7100)Text   \n",
       "6899                 ...                           Low (-9700 to -7100)Text   \n",
       "6890                 ...                           Low (-9700 to -7100)Text   \n",
       "6581                 ...                           Low (-9700 to -7100)Text   \n",
       "6880                 ...                           Low (-9700 to -7100)Text   \n",
       "6878                 ...                           Low (-9700 to -7100)Text   \n",
       "1044                 ...                           Low (-9700 to -7100)Text   \n",
       "1583                 ...                           Low (-9700 to -7100)Text   \n",
       "6907                 ...                           Low (-9700 to -7100)Text   \n",
       "5450                 ...                           Low (-9700 to -7100)Text   \n",
       "6876                 ...                           Low (-9700 to -7100)Text   \n",
       "6875                 ...                           Low (-9700 to -7100)Text   \n",
       "2817                 ...                           Low (-9700 to -7100)Text   \n",
       "6191                 ...                           Low (-9700 to -7100)Text   \n",
       "1944                 ...                           Low (-9700 to -7100)Text   \n",
       "5491                 ...                           Low (-9700 to -7100)Text   \n",
       "5813                 ...                           Low (-9700 to -7100)Text   \n",
       "6220                 ...                           Low (-9700 to -7100)Text   \n",
       "2245                 ...                           Low (-9700 to -7100)Text   \n",
       "1234                 ...                           Low (-9700 to -7100)Text   \n",
       "6538                 ...                           Low (-9700 to -7100)Text   \n",
       "6872                 ...                           Low (-9700 to -7100)Text   \n",
       "6874                 ...                           Low (-9700 to -7100)Text   \n",
       "6873                 ...                           Low (-9700 to -7100)Text   \n",
       "6879                 ...                           Low (-9700 to -7100)Text   \n",
       "6506                 ...                           Low (-9700 to -7100)Text   \n",
       "6854                 ...                           Low (-9700 to -7100)Text   \n",
       "\n",
       "                   New_SmartTile_Name3                    New_SmartTile_Name4  \\\n",
       "1213  Below Average (-750 to 1900)Text        High (3.3e+06 to 2.275e+07)Text   \n",
       "9761  Below Average (-750 to 1900)Text         Extremely Low (Below 1525)Text   \n",
       "564   Below Average (-750 to 1900)Text  Above Average (485000 to 3.3e+06)Text   \n",
       "3904  Below Average (-750 to 1900)Text  Above Average (485000 to 3.3e+06)Text   \n",
       "310   Below Average (-750 to 1900)Text        High (3.3e+06 to 2.275e+07)Text   \n",
       "4141  Below Average (-750 to 1900)Text        High (3.3e+06 to 2.275e+07)Text   \n",
       "199   Below Average (-750 to 1900)Text  Above Average (485000 to 3.3e+06)Text   \n",
       "2375  Below Average (-750 to 1900)Text   Extremely High (Above 2.275e+07)Text   \n",
       "16    Below Average (-750 to 1900)Text   Extremely High (Above 2.275e+07)Text   \n",
       "3966  Below Average (-750 to 1900)Text        High (3.3e+06 to 2.275e+07)Text   \n",
       "9508  Below Average (-750 to 1900)Text         Extremely Low (Below 1525)Text   \n",
       "1328  Below Average (-750 to 1900)Text  Above Average (485000 to 3.3e+06)Text   \n",
       "1126  Below Average (-750 to 1900)Text          Average (71000 to 485000)Text   \n",
       "5737  Below Average (-750 to 1900)Text         Extremely Low (Below 1525)Text   \n",
       "3283  Below Average (-750 to 1900)Text     Below Average (10375 to 71000)Text   \n",
       "3815  Below Average (-750 to 1900)Text  Above Average (485000 to 3.3e+06)Text   \n",
       "856   Below Average (-750 to 1900)Text  Above Average (485000 to 3.3e+06)Text   \n",
       "613   Below Average (-750 to 1900)Text          Average (71000 to 485000)Text   \n",
       "2523  Below Average (-750 to 1900)Text  Above Average (485000 to 3.3e+06)Text   \n",
       "1059  Below Average (-750 to 1900)Text  Above Average (485000 to 3.3e+06)Text   \n",
       "139   Below Average (-750 to 1900)Text  Above Average (485000 to 3.3e+06)Text   \n",
       "4089  Below Average (-750 to 1900)Text        High (3.3e+06 to 2.275e+07)Text   \n",
       "5141  Below Average (-750 to 1900)Text     Below Average (10375 to 71000)Text   \n",
       "5507  Below Average (-750 to 1900)Text          Average (71000 to 485000)Text   \n",
       "3788  Below Average (-750 to 1900)Text        High (3.3e+06 to 2.275e+07)Text   \n",
       "9     Below Average (-750 to 1900)Text        High (3.3e+06 to 2.275e+07)Text   \n",
       "2157  Below Average (-750 to 1900)Text          Average (71000 to 485000)Text   \n",
       "1     Below Average (-750 to 1900)Text   Extremely High (Above 2.275e+07)Text   \n",
       "4553  Below Average (-750 to 1900)Text          Average (71000 to 485000)Text   \n",
       "5767  Below Average (-750 to 1900)Text         Extremely Low (Below 1525)Text   \n",
       "...                                ...                                    ...   \n",
       "6651           High (7200 to 9800)Text     Below Average (10375 to 71000)Text   \n",
       "5958           High (7200 to 9800)Text         Extremely Low (Below 1525)Text   \n",
       "6877           High (7200 to 9800)Text         Extremely Low (Below 1525)Text   \n",
       "654            High (7200 to 9800)Text         Extremely Low (Below 1525)Text   \n",
       "6899           High (7200 to 9800)Text         Extremely Low (Below 1525)Text   \n",
       "6890           High (7200 to 9800)Text         Extremely Low (Below 1525)Text   \n",
       "6581           High (7200 to 9800)Text          Average (71000 to 485000)Text   \n",
       "6880           High (7200 to 9800)Text         Extremely Low (Below 1525)Text   \n",
       "6878           High (7200 to 9800)Text         Extremely Low (Below 1525)Text   \n",
       "1044           High (7200 to 9800)Text     Below Average (10375 to 71000)Text   \n",
       "1583           High (7200 to 9800)Text          Average (71000 to 485000)Text   \n",
       "6907           High (7200 to 9800)Text         Extremely Low (Below 1525)Text   \n",
       "5450           High (7200 to 9800)Text         Extremely Low (Below 1525)Text   \n",
       "6876           High (7200 to 9800)Text         Extremely Low (Below 1525)Text   \n",
       "6875           High (7200 to 9800)Text         Extremely Low (Below 1525)Text   \n",
       "2817           High (7200 to 9800)Text         Extremely Low (Below 1525)Text   \n",
       "6191           High (7200 to 9800)Text     Below Average (10375 to 71000)Text   \n",
       "1944           High (7200 to 9800)Text         Extremely Low (Below 1525)Text   \n",
       "5491           High (7200 to 9800)Text     Below Average (10375 to 71000)Text   \n",
       "5813           High (7200 to 9800)Text     Below Average (10375 to 71000)Text   \n",
       "6220           High (7200 to 9800)Text         Extremely Low (Below 1525)Text   \n",
       "2245           High (7200 to 9800)Text     Below Average (10375 to 71000)Text   \n",
       "1234           High (7200 to 9800)Text          Average (71000 to 485000)Text   \n",
       "6538           High (7200 to 9800)Text          Average (71000 to 485000)Text   \n",
       "6872           High (7200 to 9800)Text         Extremely Low (Below 1525)Text   \n",
       "6874           High (7200 to 9800)Text         Extremely Low (Below 1525)Text   \n",
       "6873           High (7200 to 9800)Text         Extremely Low (Below 1525)Text   \n",
       "6879           High (7200 to 9800)Text         Extremely Low (Below 1525)Text   \n",
       "6506           High (7200 to 9800)Text          Average (71000 to 485000)Text   \n",
       "6854           High (7200 to 9800)Text                Low (1525 to 10375)Text   \n",
       "\n",
       "                         New_SmartTile_Name5  \\\n",
       "1213          High (3.35e+06 to 2.3e+07)Text   \n",
       "9761          Extremely Low (Below 1500)Text   \n",
       "564   Above Average (485000 to 3.35e+06)Text   \n",
       "3904  Above Average (485000 to 3.35e+06)Text   \n",
       "310           High (3.35e+06 to 2.3e+07)Text   \n",
       "4141          High (3.35e+06 to 2.3e+07)Text   \n",
       "199   Above Average (485000 to 3.35e+06)Text   \n",
       "2375      Extremely High (Above 2.3e+07)Text   \n",
       "16        Extremely High (Above 2.3e+07)Text   \n",
       "3966          High (3.35e+06 to 2.3e+07)Text   \n",
       "9508          Extremely Low (Below 1500)Text   \n",
       "1328  Above Average (485000 to 3.35e+06)Text   \n",
       "1126           Average (71000 to 485000)Text   \n",
       "5737          Extremely Low (Below 1500)Text   \n",
       "3283          Extremely Low (Below 1500)Text   \n",
       "3815  Above Average (485000 to 3.35e+06)Text   \n",
       "856   Above Average (485000 to 3.35e+06)Text   \n",
       "613       Below Average (10250 to 71000)Text   \n",
       "2523  Above Average (485000 to 3.35e+06)Text   \n",
       "1059  Above Average (485000 to 3.35e+06)Text   \n",
       "139   Above Average (485000 to 3.35e+06)Text   \n",
       "4089          High (3.35e+06 to 2.3e+07)Text   \n",
       "5141           Average (71000 to 485000)Text   \n",
       "5507           Average (71000 to 485000)Text   \n",
       "3788          High (3.35e+06 to 2.3e+07)Text   \n",
       "9             High (3.35e+06 to 2.3e+07)Text   \n",
       "2157           Average (71000 to 485000)Text   \n",
       "1         Extremely High (Above 2.3e+07)Text   \n",
       "4553           Average (71000 to 485000)Text   \n",
       "5767      Below Average (10250 to 71000)Text   \n",
       "...                                      ...   \n",
       "6651          Extremely Low (Below 1500)Text   \n",
       "5958          Extremely Low (Below 1500)Text   \n",
       "6877          Extremely Low (Below 1500)Text   \n",
       "654       Below Average (10250 to 71000)Text   \n",
       "6899          Extremely Low (Below 1500)Text   \n",
       "6890          Extremely Low (Below 1500)Text   \n",
       "6581          Extremely Low (Below 1500)Text   \n",
       "6880          Extremely Low (Below 1500)Text   \n",
       "6878          Extremely Low (Below 1500)Text   \n",
       "1044          Extremely Low (Below 1500)Text   \n",
       "1583           Average (71000 to 485000)Text   \n",
       "6907          Extremely Low (Below 1500)Text   \n",
       "5450          Extremely Low (Below 1500)Text   \n",
       "6876          Extremely Low (Below 1500)Text   \n",
       "6875          Extremely Low (Below 1500)Text   \n",
       "2817          Extremely Low (Below 1500)Text   \n",
       "6191      Below Average (10250 to 71000)Text   \n",
       "1944      Below Average (10250 to 71000)Text   \n",
       "5491          Extremely Low (Below 1500)Text   \n",
       "5813      Below Average (10250 to 71000)Text   \n",
       "6220      Below Average (10250 to 71000)Text   \n",
       "2245      Below Average (10250 to 71000)Text   \n",
       "1234           Average (71000 to 485000)Text   \n",
       "6538          Extremely Low (Below 1500)Text   \n",
       "6872          Extremely Low (Below 1500)Text   \n",
       "6874          Extremely Low (Below 1500)Text   \n",
       "6873          Extremely Low (Below 1500)Text   \n",
       "6879          Extremely Low (Below 1500)Text   \n",
       "6506          Extremely Low (Below 1500)Text   \n",
       "6854          Extremely Low (Below 1500)Text   \n",
       "\n",
       "                         New_SmartTile_Name6  \\\n",
       "1213          High (3.35e+06 to 2.2e+07)Text   \n",
       "9761          Extremely Low (Below 1725)Text   \n",
       "564   Above Average (500000 to 3.35e+06)Text   \n",
       "3904  Above Average (500000 to 3.35e+06)Text   \n",
       "310           High (3.35e+06 to 2.2e+07)Text   \n",
       "4141          High (3.35e+06 to 2.2e+07)Text   \n",
       "199   Above Average (500000 to 3.35e+06)Text   \n",
       "2375      Extremely High (Above 2.2e+07)Text   \n",
       "16        Extremely High (Above 2.2e+07)Text   \n",
       "3966          High (3.35e+06 to 2.2e+07)Text   \n",
       "9508          Extremely Low (Below 1725)Text   \n",
       "1328  Above Average (500000 to 3.35e+06)Text   \n",
       "1126           Average (76000 to 500000)Text   \n",
       "5737      Below Average (11500 to 76000)Text   \n",
       "3283      Below Average (11500 to 76000)Text   \n",
       "3815  Above Average (500000 to 3.35e+06)Text   \n",
       "856            Average (76000 to 500000)Text   \n",
       "613           Extremely Low (Below 1725)Text   \n",
       "2523  Above Average (500000 to 3.35e+06)Text   \n",
       "1059  Above Average (500000 to 3.35e+06)Text   \n",
       "139   Above Average (500000 to 3.35e+06)Text   \n",
       "4089          High (3.35e+06 to 2.2e+07)Text   \n",
       "5141           Average (76000 to 500000)Text   \n",
       "5507  Above Average (500000 to 3.35e+06)Text   \n",
       "3788          High (3.35e+06 to 2.2e+07)Text   \n",
       "9             High (3.35e+06 to 2.2e+07)Text   \n",
       "2157  Above Average (500000 to 3.35e+06)Text   \n",
       "1         Extremely High (Above 2.2e+07)Text   \n",
       "4553           Average (76000 to 500000)Text   \n",
       "5767      Below Average (11500 to 76000)Text   \n",
       "...                                      ...   \n",
       "6651          Extremely Low (Below 1725)Text   \n",
       "5958      Below Average (11500 to 76000)Text   \n",
       "6877          Extremely Low (Below 1725)Text   \n",
       "654           Extremely Low (Below 1725)Text   \n",
       "6899          Extremely Low (Below 1725)Text   \n",
       "6890          Extremely Low (Below 1725)Text   \n",
       "6581          Extremely Low (Below 1725)Text   \n",
       "6880          Extremely Low (Below 1725)Text   \n",
       "6878          Extremely Low (Below 1725)Text   \n",
       "1044      Below Average (11500 to 76000)Text   \n",
       "1583           Average (76000 to 500000)Text   \n",
       "6907          Extremely Low (Below 1725)Text   \n",
       "5450      Below Average (11500 to 76000)Text   \n",
       "6876          Extremely Low (Below 1725)Text   \n",
       "6875          Extremely Low (Below 1725)Text   \n",
       "2817          Extremely Low (Below 1725)Text   \n",
       "6191          Extremely Low (Below 1725)Text   \n",
       "1944          Extremely Low (Below 1725)Text   \n",
       "5491      Below Average (11500 to 76000)Text   \n",
       "5813      Below Average (11500 to 76000)Text   \n",
       "6220          Extremely Low (Below 1725)Text   \n",
       "2245           Average (76000 to 500000)Text   \n",
       "1234           Average (76000 to 500000)Text   \n",
       "6538          Extremely Low (Below 1725)Text   \n",
       "6872          Extremely Low (Below 1725)Text   \n",
       "6874          Extremely Low (Below 1725)Text   \n",
       "6873          Extremely Low (Below 1725)Text   \n",
       "6879          Extremely Low (Below 1725)Text   \n",
       "6506          Extremely Low (Below 1725)Text   \n",
       "6854          Extremely Low (Below 1725)Text   \n",
       "\n",
       "                         New_SmartTile_Name7  \\\n",
       "1213          High (3.15e+06 to 2.1e+07)Text   \n",
       "9761          Extremely Low (Below 1625)Text   \n",
       "564   Above Average (475000 to 3.15e+06)Text   \n",
       "3904  Above Average (475000 to 3.15e+06)Text   \n",
       "310           High (3.15e+06 to 2.1e+07)Text   \n",
       "4141          High (3.15e+06 to 2.1e+07)Text   \n",
       "199   Above Average (475000 to 3.15e+06)Text   \n",
       "2375      Extremely High (Above 2.1e+07)Text   \n",
       "16        Extremely High (Above 2.1e+07)Text   \n",
       "3966          High (3.15e+06 to 2.1e+07)Text   \n",
       "9508          Extremely Low (Below 1625)Text   \n",
       "1328  Above Average (475000 to 3.15e+06)Text   \n",
       "1126           Average (71000 to 475000)Text   \n",
       "5737          Extremely Low (Below 1625)Text   \n",
       "3283      Below Average (10750 to 71000)Text   \n",
       "3815  Above Average (475000 to 3.15e+06)Text   \n",
       "856   Above Average (475000 to 3.15e+06)Text   \n",
       "613            Average (71000 to 475000)Text   \n",
       "2523  Above Average (475000 to 3.15e+06)Text   \n",
       "1059  Above Average (475000 to 3.15e+06)Text   \n",
       "139            Average (71000 to 475000)Text   \n",
       "4089          High (3.15e+06 to 2.1e+07)Text   \n",
       "5141      Below Average (10750 to 71000)Text   \n",
       "5507          Extremely Low (Below 1625)Text   \n",
       "3788  Above Average (475000 to 3.15e+06)Text   \n",
       "9             High (3.15e+06 to 2.1e+07)Text   \n",
       "2157           Average (71000 to 475000)Text   \n",
       "1         Extremely High (Above 2.1e+07)Text   \n",
       "4553           Average (71000 to 475000)Text   \n",
       "5767          Extremely Low (Below 1625)Text   \n",
       "...                                      ...   \n",
       "6651          Extremely Low (Below 1625)Text   \n",
       "5958          Extremely Low (Below 1625)Text   \n",
       "6877          Extremely Low (Below 1625)Text   \n",
       "654            Average (71000 to 475000)Text   \n",
       "6899          Extremely Low (Below 1625)Text   \n",
       "6890          Extremely Low (Below 1625)Text   \n",
       "6581          Extremely Low (Below 1625)Text   \n",
       "6880          Extremely Low (Below 1625)Text   \n",
       "6878          Extremely Low (Below 1625)Text   \n",
       "1044      Below Average (10750 to 71000)Text   \n",
       "1583           Average (71000 to 475000)Text   \n",
       "6907          Extremely Low (Below 1625)Text   \n",
       "5450          Extremely Low (Below 1625)Text   \n",
       "6876          Extremely Low (Below 1625)Text   \n",
       "6875          Extremely Low (Below 1625)Text   \n",
       "2817      Below Average (10750 to 71000)Text   \n",
       "6191          Extremely Low (Below 1625)Text   \n",
       "1944      Below Average (10750 to 71000)Text   \n",
       "5491          Extremely Low (Below 1625)Text   \n",
       "5813          Extremely Low (Below 1625)Text   \n",
       "6220          Extremely Low (Below 1625)Text   \n",
       "2245      Below Average (10750 to 71000)Text   \n",
       "1234           Average (71000 to 475000)Text   \n",
       "6538          Extremely Low (Below 1625)Text   \n",
       "6872          Extremely Low (Below 1625)Text   \n",
       "6874          Extremely Low (Below 1625)Text   \n",
       "6873          Extremely Low (Below 1625)Text   \n",
       "6879          Extremely Low (Below 1625)Text   \n",
       "6506          Extremely Low (Below 1625)Text   \n",
       "6854          Extremely Low (Below 1625)Text   \n",
       "\n",
       "                      New_SmartTile_Name8  \\\n",
       "1213  Above Average (41500 to 106250)Text   \n",
       "9761       Extremely Low (Below 2475)Text   \n",
       "564           High (106250 to 270000)Text   \n",
       "3904    Below Average (6300 to 16250)Text   \n",
       "310           High (106250 to 270000)Text   \n",
       "4141    Below Average (6300 to 16250)Text   \n",
       "199           High (106250 to 270000)Text   \n",
       "2375         Average (16250 to 41500)Text   \n",
       "16            High (106250 to 270000)Text   \n",
       "3966    Below Average (6300 to 16250)Text   \n",
       "9508       Extremely Low (Below 2475)Text   \n",
       "1328  Above Average (41500 to 106250)Text   \n",
       "1126  Above Average (41500 to 106250)Text   \n",
       "5737       Extremely Low (Below 2475)Text   \n",
       "3283         Average (16250 to 41500)Text   \n",
       "3815    Below Average (6300 to 16250)Text   \n",
       "856     Extremely High (Above 270000)Text   \n",
       "613   Above Average (41500 to 106250)Text   \n",
       "2523         Average (16250 to 41500)Text   \n",
       "1059  Above Average (41500 to 106250)Text   \n",
       "139           High (106250 to 270000)Text   \n",
       "4089    Below Average (6300 to 16250)Text   \n",
       "5141    Below Average (6300 to 16250)Text   \n",
       "5507         Average (16250 to 41500)Text   \n",
       "3788         Average (16250 to 41500)Text   \n",
       "9       Extremely High (Above 270000)Text   \n",
       "2157         Average (16250 to 41500)Text   \n",
       "1             High (106250 to 270000)Text   \n",
       "4553    Below Average (6300 to 16250)Text   \n",
       "5767       Extremely Low (Below 2475)Text   \n",
       "...                                   ...   \n",
       "6651         Average (16250 to 41500)Text   \n",
       "5958       Extremely Low (Below 2475)Text   \n",
       "6877       Extremely Low (Below 2475)Text   \n",
       "654        Extremely Low (Below 2475)Text   \n",
       "6899       Extremely Low (Below 2475)Text   \n",
       "6890       Extremely Low (Below 2475)Text   \n",
       "6581         Average (16250 to 41500)Text   \n",
       "6880       Extremely Low (Below 2475)Text   \n",
       "6878       Extremely Low (Below 2475)Text   \n",
       "1044  Above Average (41500 to 106250)Text   \n",
       "1583         Average (16250 to 41500)Text   \n",
       "6907       Extremely Low (Below 2475)Text   \n",
       "5450       Extremely Low (Below 2475)Text   \n",
       "6876       Extremely Low (Below 2475)Text   \n",
       "6875       Extremely Low (Below 2475)Text   \n",
       "2817       Extremely Low (Below 2475)Text   \n",
       "6191         Average (16250 to 41500)Text   \n",
       "1944       Extremely Low (Below 2475)Text   \n",
       "5491         Average (16250 to 41500)Text   \n",
       "5813         Average (16250 to 41500)Text   \n",
       "6220       Extremely Low (Below 2475)Text   \n",
       "2245         Average (16250 to 41500)Text   \n",
       "1234  Above Average (41500 to 106250)Text   \n",
       "6538  Above Average (41500 to 106250)Text   \n",
       "6872       Extremely Low (Below 2475)Text   \n",
       "6874       Extremely Low (Below 2475)Text   \n",
       "6873       Extremely Low (Below 2475)Text   \n",
       "6879       Extremely Low (Below 2475)Text   \n",
       "6506  Above Average (41500 to 106250)Text   \n",
       "6854    Below Average (6300 to 16250)Text   \n",
       "\n",
       "                      New_SmartTile_Name9  \\\n",
       "1213         Average (16250 to 42000)Text   \n",
       "9761       Extremely Low (Below 2400)Text   \n",
       "564          Average (16250 to 42000)Text   \n",
       "3904         Average (16250 to 42000)Text   \n",
       "310           High (108750 to 280000)Text   \n",
       "4141         Average (16250 to 42000)Text   \n",
       "199           High (108750 to 280000)Text   \n",
       "2375         Average (16250 to 42000)Text   \n",
       "16      Extremely High (Above 280000)Text   \n",
       "3966    Below Average (6200 to 16250)Text   \n",
       "9508       Extremely Low (Below 2400)Text   \n",
       "1328         Average (16250 to 42000)Text   \n",
       "1126  Above Average (42000 to 108750)Text   \n",
       "5737       Extremely Low (Below 2400)Text   \n",
       "3283       Extremely Low (Below 2400)Text   \n",
       "3815    Below Average (6200 to 16250)Text   \n",
       "856           High (108750 to 280000)Text   \n",
       "613          Average (16250 to 42000)Text   \n",
       "2523         Average (16250 to 42000)Text   \n",
       "1059         Average (16250 to 42000)Text   \n",
       "139     Extremely High (Above 280000)Text   \n",
       "4089    Below Average (6200 to 16250)Text   \n",
       "5141    Below Average (6200 to 16250)Text   \n",
       "5507         Average (16250 to 42000)Text   \n",
       "3788    Below Average (6200 to 16250)Text   \n",
       "9       Extremely High (Above 280000)Text   \n",
       "2157         Average (16250 to 42000)Text   \n",
       "1       Extremely High (Above 280000)Text   \n",
       "4553    Below Average (6200 to 16250)Text   \n",
       "5767         Average (16250 to 42000)Text   \n",
       "...                                   ...   \n",
       "6651       Extremely Low (Below 2400)Text   \n",
       "5958       Extremely Low (Below 2400)Text   \n",
       "6877       Extremely Low (Below 2400)Text   \n",
       "654          Average (16250 to 42000)Text   \n",
       "6899       Extremely Low (Below 2400)Text   \n",
       "6890       Extremely Low (Below 2400)Text   \n",
       "6581       Extremely Low (Below 2400)Text   \n",
       "6880       Extremely Low (Below 2400)Text   \n",
       "6878       Extremely Low (Below 2400)Text   \n",
       "1044       Extremely Low (Below 2400)Text   \n",
       "1583  Above Average (42000 to 108750)Text   \n",
       "6907       Extremely Low (Below 2400)Text   \n",
       "5450       Extremely Low (Below 2400)Text   \n",
       "6876       Extremely Low (Below 2400)Text   \n",
       "6875       Extremely Low (Below 2400)Text   \n",
       "2817       Extremely Low (Below 2400)Text   \n",
       "6191         Average (16250 to 42000)Text   \n",
       "1944         Average (16250 to 42000)Text   \n",
       "5491       Extremely Low (Below 2400)Text   \n",
       "5813         Average (16250 to 42000)Text   \n",
       "6220         Average (16250 to 42000)Text   \n",
       "2245         Average (16250 to 42000)Text   \n",
       "1234  Above Average (42000 to 108750)Text   \n",
       "6538       Extremely Low (Below 2400)Text   \n",
       "6872       Extremely Low (Below 2400)Text   \n",
       "6874       Extremely Low (Below 2400)Text   \n",
       "6873       Extremely Low (Below 2400)Text   \n",
       "6879       Extremely Low (Below 2400)Text   \n",
       "6506       Extremely Low (Below 2400)Text   \n",
       "6854       Extremely Low (Below 2400)Text   \n",
       "\n",
       "                    New_SmartTile_Name9_2                New_SmartTile_Name9_3  \n",
       "1213  Above Average (42000 to 105000)Text  Above Average (42000 to 107500)Text  \n",
       "9761       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "564   Above Average (42000 to 105000)Text  Above Average (42000 to 107500)Text  \n",
       "3904         Average (17000 to 42000)Text    Below Average (6500 to 16500)Text  \n",
       "310           High (105000 to 260000)Text          High (107500 to 275000)Text  \n",
       "4141    Below Average (6800 to 17000)Text    Below Average (6500 to 16500)Text  \n",
       "199   Above Average (42000 to 105000)Text          High (107500 to 275000)Text  \n",
       "2375         Average (17000 to 42000)Text         Average (16500 to 42000)Text  \n",
       "16      Extremely High (Above 260000)Text    Extremely High (Above 275000)Text  \n",
       "3966    Below Average (6800 to 17000)Text    Below Average (6500 to 16500)Text  \n",
       "9508       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "1328  Above Average (42000 to 105000)Text         Average (16500 to 42000)Text  \n",
       "1126  Above Average (42000 to 105000)Text  Above Average (42000 to 107500)Text  \n",
       "5737         Average (17000 to 42000)Text       Extremely Low (Below 2550)Text  \n",
       "3283         Average (17000 to 42000)Text         Average (16500 to 42000)Text  \n",
       "3815         Average (17000 to 42000)Text    Below Average (6500 to 16500)Text  \n",
       "856          Average (17000 to 42000)Text  Above Average (42000 to 107500)Text  \n",
       "613        Extremely Low (Below 2700)Text  Above Average (42000 to 107500)Text  \n",
       "2523         Average (17000 to 42000)Text         Average (16500 to 42000)Text  \n",
       "1059         Average (17000 to 42000)Text  Above Average (42000 to 107500)Text  \n",
       "139           High (105000 to 260000)Text          High (107500 to 275000)Text  \n",
       "4089    Below Average (6800 to 17000)Text    Below Average (6500 to 16500)Text  \n",
       "5141         Average (17000 to 42000)Text    Below Average (6500 to 16500)Text  \n",
       "5507         Average (17000 to 42000)Text       Extremely Low (Below 2550)Text  \n",
       "3788         Average (17000 to 42000)Text    Below Average (6500 to 16500)Text  \n",
       "9       Extremely High (Above 260000)Text    Extremely High (Above 275000)Text  \n",
       "2157         Average (17000 to 42000)Text         Average (16500 to 42000)Text  \n",
       "1       Extremely High (Above 260000)Text    Extremely High (Above 275000)Text  \n",
       "4553    Below Average (6800 to 17000)Text    Below Average (6500 to 16500)Text  \n",
       "5767         Average (17000 to 42000)Text       Extremely Low (Below 2550)Text  \n",
       "...                                   ...                                  ...  \n",
       "6651       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "5958    Below Average (6800 to 17000)Text       Extremely Low (Below 2550)Text  \n",
       "6877       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "654        Extremely Low (Below 2700)Text  Above Average (42000 to 107500)Text  \n",
       "6899       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "6890       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "6581       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "6880       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "6878       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "1044         Average (17000 to 42000)Text  Above Average (42000 to 107500)Text  \n",
       "1583         Average (17000 to 42000)Text         Average (16500 to 42000)Text  \n",
       "6907       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "5450  Above Average (42000 to 105000)Text       Extremely Low (Below 2550)Text  \n",
       "6876       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "6875       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "2817       Extremely Low (Below 2700)Text         Average (16500 to 42000)Text  \n",
       "6191       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "1944       Extremely Low (Below 2700)Text         Average (16500 to 42000)Text  \n",
       "5491         Average (17000 to 42000)Text       Extremely Low (Below 2550)Text  \n",
       "5813    Below Average (6800 to 17000)Text       Extremely Low (Below 2550)Text  \n",
       "6220       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "2245  Above Average (42000 to 105000)Text         Average (16500 to 42000)Text  \n",
       "1234         Average (17000 to 42000)Text  Above Average (42000 to 107500)Text  \n",
       "6538       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "6872       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "6874       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "6873       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "6879       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "6506       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "6854       Extremely Low (Below 2700)Text       Extremely Low (Below 2550)Text  \n",
       "\n",
       "[10000 rows x 83 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.array([2,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 1.])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(np.log(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.69314718, 1.09861229, 0.        ,       -inf])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(np.array([2,3,1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
